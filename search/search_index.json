{
    "docs": [
        {
            "location": "/", 
            "text": "bioprocs\n\n\nA set of processes for bioinformatics using \nPyPPL\n\n\nSee \ndocumentation\n.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#bioprocs", 
            "text": "A set of processes for bioinformatics using  PyPPL  See  documentation .", 
            "title": "bioprocs"
        }, 
        {
            "location": "/processes/", 
            "text": "algorithm\n\n\n\n\npRWR\n\n\n\n\n\n\ndescription\n\n    Do random walk with restart (RWR)\n\n\n\n\n\n\ninput\n  \n\n\n\n\nWfile:file\n: The adjecent matrix  \n\n\nEfile:file\n: The start vector  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output of final probabilities  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nc\n: The restart probability. Default: 0.1  \n\n\neps\n: The convergent cutoff || R(i+1) - R(i) ||. Default: 1e-5  \n\n\nniter\n: Max iterations to stop. Default: 10000  \n\n\nnormW\n: Weather to normalize W or not, default True.   \n\n\nLaplacian normalization is used (more to add).\n\n\n\n\n\n\nnormE\n: Weather to normalize E or not, default True.   \n\n\nE will be normalized as: E = E/sum(E)\n\n\n\n\n\n\n\n\n\n\n\n\nrequires\n\n    if normW = True, R package \nNetPreProc\n is required.\n\n\n\n\n\n\n\n\n\n\npAR\n\n\n\n\n\n\ndescription\n\n    Affinity Regression.\n    Ref: https://www.nature.com/articles/nbt.3343\n    \n        b           c        d          d  \n    _________    _______    ____       ____\n    |       |    |  W  |    |  |       |  |\n  a |   D   |  b |_____|  c |Pt|  =  a |Y |   \n=\n\n    |_______|               |__|       |  |\n                                       |__|\n\nkronecker(P, YtD)*vec(W) = vec(YtY)             \n=\n\nX*vec(W) = vec(YtY)\nWPt:\n       c        d              d  \n    _______    ____          _____\n    |  W  |    |  |          |   |\n  b |_____|  c |Pt|  ---\n  b |___|\n                  |__|\n\nYtDW:\nWtDtY:\n     b           a        d               d    \n  _______    _________   ____           _____  \n  |  Wt |    |       |   |  |           |   |  \nc |_____|  b |   Dt  | a |Y |    ---\n c |___|  \n             |_______|   |  |                 \n                         |__|                  \n\n\n\n\n\n\n\ninput\n  \n\n\n\n\nD:file\n : The D matrix  \n\n\nPt:file\n: The Pt matrix  \n\n\nY:file\n: The Y matrix  \n\n\nAll input files could be gzipped\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\nW:file\n: The interaction matrix  \n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nseed\n: The seed for sampling the training set.  \n\n\ntfrac\n: The fraction of samples used for training.\n\n``\n\n\n\n\n\n\n\n\n\n\nbed\n\n\n\n\npBedSort\n\n\n\n\n\n\ndescription\n\n    Sort bed files\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to sort the file. Default: sort (bedtools, bedops)  \n\n\nbedtools\n: The path to bedtools. Default: bedtools  \n\n\nbedops_sort\n: The path to bedops' sort-bed. Default: sort-bed  \n\n\nmem\n: The memory to use. Default: 8G  \n\n\ntmpdir\n: The tmpdir to use. Default: \n$TMPDIR\n  \n\n\nunique\n: Remove the dupliated records? Default: True  \n\n\nparams\n: Other params for \ntool\n. Default: {}  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n    \nbedops\n\n\n\n\n\n\n\n\n\n\npBedCluster\n\n\n\n\n\n\ndescription\n\n    Assign cluster id to each record\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input bed file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to sort the file. Default: bedtools  \n\n\nbedtools\n: The path to bedtools. Default: bedtools  \n\n\nparams\n: Other params for \ntool\n. Default: ''  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\nbedtools\n\n\n\n\npBedGetfasta\n\n\n\n\n\n\ndescription\n\n\nbedtools getfasta\n extracts sequences from a FASTA file for each of the intervals defined in a BED file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input bed file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The generated fasta file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nref\n     : The fasta file  \n\n\nbedtools\n: The bedtools executable,                  default: \"bedtools\"  \n\n\nparams\n  : Other parameters for \nbedtools getfasta\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedClosest\n\n\n\n\n\n\ndescription\n\n    Similar to intersect, closest searches for overlapping features in A and B. In the event that no feature in B overlaps the current feature in A, closest will report the nearest (that is, least genomic distance from the start or end of A) feature in B. For example, one might want to find which is the closest gene to a significant GWAS polymorphism. Note that closest will report an overlapping feature as the closest that is, it does not restrict to closest non-overlapping feature. The following iconic cheatsheet summarizes the funcitonality available through the various optyions provided by the closest tool.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nafile:file\n: The -a file  \n\n\nbfile:file\n: The -b file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbedtools\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools closest\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedClosest2\n\n\n\n\n\n\ndescription\n\n    Multiple b-file version of pBedClosest\n\n\n\n\n\n\ninput\n  \n\n\n\n\nafile:file\n: The -a file  \n\n\nbfiles:files\n: The -b files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbedtools\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools closest\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedFlank\n\n\n\n\n\n\ndescription\n\n\nbedtools flank\n will create two new flanking intervals for each interval in a BED file. Note that flank will restrict the created flanking intervals to the size of the chromosome (i.e. no start \n 0 and no end \n chromosome size).\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\ngfile:file\n: The genome size file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools flank\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedIntersect\n\n\n\n\n\n\ndescription\n\n    By far, the most common question asked of two sets of genomic features is whether or not any of the features in the two sets overlap with one another. This is known as feature intersection. bedtools intersect allows one to screen for overlaps between two sets of genomic features. Moreover, it allows one to have fine control as to how the intersections are reported. bedtools intersect works with both BED/GFF/VCF and BAM files as input.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nafile:file\n : The a file  \n\n\nbfile:file\n: The b file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbedtools\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools intersect\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedIntersect2\n\n\n\n\n\n\ndescription\n\n    Multiple b-file version of pBedIntersect\n\n\n\n\n\n\ninput\n  \n\n\n\n\nafile:file\n : The a file  \n\n\nbfiles:files\n: The b files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbedtools\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools intersect\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedMakewindows\n\n\n\n\n\n\ndescription\n\n    Makes adjacent or sliding windows across a genome or BED file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The bedtools executable, default: \"bedtools\"  \n\n\ninformat\n: The format of input file, whether is a \"bed\" file or \"genome\" size file. Default: \"bed\"  \n\n\nparams\n: Other parameters for \nbedtools makewindows\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedMerge\n\n\n\n\n\n\ndescription\n\n\nbedtools merge\n combines overlapping or book-ended features in an interval file into a single feature which spans all of the combined features.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbedtools\n: The bedtools executable,               default: \"bedtools\"  \n\n\nparams\n  : Other parameters for \nbedtools merge\n, default: {}  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedMerge2\n\n\n\n\n\n\ndescription\n\n    A multi-input file model of pBedMerge: Merge multiple input files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfiles:files\n: The input files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbedtools\n: The bedtools executable,               default: \"bedtools\"  \n\n\nparams\n  : Other parameters for \nbedtools merge\n, default: {}  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedMultiinter\n\n\n\n\n\n\ndescription\n\n    Identifies common intervals among multiple BED/GFF/VCF files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfiles:files\n: The input files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools multiinter\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedRandom\n\n\n\n\n\n\ndescription\n\n\nbedtools random\n will generate a random set of intervals in BED6 format. One can specify both the number (-n) and the size (-l) of the intervals that should be generated.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ngfile:file\n: The genome size file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbedtools\n: The bedtools executable,    default: \"bedtools\"  \n\n\nseed\n    : The seed for randomization, default: None  \n\n\ngsize\n   : The chromsize file.  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedShift\n\n\n\n\n\n\ndescription\n\n\nbedtools shift\n will move each feature in a feature file by a user-defined number of bases. While something like this could be done with an awk '{OFS=\"\\t\" print $1,$2+\n,$3+\n}', bedtools shift will restrict the resizing to the size of the chromosome (i.e. no features before 0 or past the chromosome end).\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\ngfile:file\n: The genome size file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools shift\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedShuffle\n\n\n\n\n\n\ndescription\n\n\nbedtools shuffle\n will randomly permute the genomic locations of a feature file among a genome defined in a genome file. One can also provide an exclusions BED/GFF/VCF file that lists regions where you do not want the permuted features to be placed. For example, one might want to prevent features from being placed in known genome gaps. shuffle is useful as a null basis against which to test the significance of associations of one feature with another.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\ngfile:file\n: The genome size file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools shuffle\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedSubtract\n\n\n\n\n\n\ndescription\n\n\nbedtools subtract\n searches for features in B that overlap A. If an overlapping feature is found in B, the overlapping portion is removed from A and the remaining portion of A is reported. If a feature in B overlaps all of a feature in A, the A feature will not be reported.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nafile:file\n: The a file  \n\n\nbfile:file\n: The b file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools subtract\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedWindow\n\n\n\n\n\n\ndescription\n\n    Similar to \nbedtools intersect\n, \nwindow\n searches for overlapping features in A and B. However, window adds a specified number (1000, by default) of base pairs upstream and downstream of each feature in A. In effect, this allows features in B that are near features in A to be detected.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nafile:file\n: The a file  \n\n\nbfile:file\n: The b file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools window\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\n\n\npBedGenomecov\n\n\n\n\n\n\ndescription\n\n\nbedtools genomecov\n computes histograms (default), per-base reports (-d) and BEDGRAPH (-bg) summaries of feature coverage (e.g., aligned sequences) for a given genome.\n\n\nNOTE: only bam file input implemented here.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The bedtools executable, default: \"bedtools\"  \n\n\nparams\n: Other parameters for \nbedtools genomecov\n, default: \"-bg\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbedtools\n\n\n\n\n\n\n\n\nchipseq\n\n\n\n\npPeakToRegPotential\n\n\n\n\n\n\ndescription\n\n    Convert peaks to regulatory potential score for each gene\n    The formula is:\n    \n-(0.5 + 4*di/d0)\n    PC = sum (pi * e                  )\n\n    Ref: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4489297/\n\n\n\n\n\n\ninput\n  \n\n\n\n\npeakfile:file\n: The BED/peak file for peaks  \n\n\ngenefile:file\n: The BED file for gene coordinates  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The regulatory potential file for each gene  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nintensity\n: \npi\n in the formula. Boolean value, whether use the peak intensity or not, default: \nTrue\n,  \n\n\ngeneformat\n: The format for \ngenefile\n, default: \nucsc+gz\n. It could be:  \n\n\nucsc or ucsc+gz: typically, you can download from http://hgdownload.cse.ucsc.edu/goldenPath/hg38/database/refGene.txt.gz\n\n\nbed or bed+gz: \nformat\n, 4th column required as gene identity.\n\n\n\n\n\n\npeakformat\n: The format for \npeakfile\n, default: \npeak\n. It could be:  \n\n\npeak or peak+gz: (either \nnarrowPeak\n or \nbroadPeak\n, the 7th column will be used as intensity\n\n\nbed or bed+gz: \nformat\n, 5th column will be used as intensity.\n\n\n\n\n\n\nwindow\n: \n2 * d0\n in the formula. The window where the peaks fall in will be consided, default: \n100000\n. \n\n\n|--------- window ----------|\n    |---- d0 -----|\n    |--- 50K --- TSS --- 50K ---|\n         ^ (peak center)\n         |-- di --|\n\n\n\n\n\n\n\n\n\n\ncluster\n\n\n\n\npDist2Coords\n\n\n\n\n\n\ndescription\n\n    Convert a distance matrix to coordinates, using multidimensional scaling.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The distance matrix, could be a full distance matrix, a triangle matrix or a pair-wise distance file  \n\n\nfull dist matrix (full):\n\n\ts1\ts2\ts3\ns1\t0\t1\t1\ns2\t1\t0\t1\ns3\t1\t1\t0\n\n\n\ntriangle matrix (upper/lower), could be also lower triangle\n\n\ts1\ts2\ts3\ns1\t0\t1\t1\ns2\t\t0\t1\ns3\t\t\t0\n\n\n\npair-wise (pair): (assuming auto-pair-wise distance = 0, that is: \ns1 s1  0\n)\n\ns1\ts2\t1\ns1\ts3\t1\ns2\ts3\t1\n\n\n\nBoth rownames and header are required.\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output coordinate file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninformat\n: The format of the input file: full, triangle or pair. Default: full  \n\n\nCould also be upper, lower, pair\n\n\n\n\n\n\nk\n: How many dimensions? Default: 2 (R^2)  \n\n\n\n\n\n\n\n\n\n\n\n\npCluster\n\n\n\n\n\n\ndescription\n\n    Use \noptCluster\n to select the best number of clusters and cluster method, then perform the clustering\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input matrix file. Clustering will be performed against rows. If not, set \nargs.transpose\n = True  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output cluster file  \n\n\noutdir:dir\n: The output directory containing the figures  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntranspose\n: Transpose the input matrix. Default: False  \n\n\ncnames\n: Whether the input matrix contains header before transposing. Default: False  \n\n\nrnames\n: Which column is the rownames before transposing. Default: 1  \n\n\nplot\n: Whether plot the cluster. Default: True  \n\n\nminc\n: Min number of clusters to test. Default: 2  \n\n\nmaxc\n: Min number of clusters to test. Default: 15  \n\n\nIf number of rows (nrows) \n= 15, then max = nrows - 1\n\n\n\n\n\n\nmethods\n: The methods to test. Default: \"all\"  \n\n\nCould be any of \"agnes\", \"clara\", \"diana\", \"fanny\", \"hierarchical\", \"kmeans\", \"model\", \"pam\", \"som\", \"sota\", \"em.nbinom\", \"da.nbinom\", \"sa.nbinom\", \"em.poisson\", \"da.poisson\", \"sa.poisson\"\n\n\nMultiple methods could be separated by comma (,), or put in a list\n\n\nBy default, fanny, model and sota will be excluded because fanny causes error and the latter two are slow. You can manually include them if you want.\n\n\nImproper methods will be automatically excluded by \nargs.isCount\n\n\n\n\n\n\nisCount\n: Whether the data is count data. Corresponding methods will be tested. Default: False  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-optCluster\n\n    \nr-factoextra\n\n\n\n\n\n\n\n\n\n\npMCluster\n\n\n\n\n\n\ndescription\n\n    Use \nr-mclust\n to do clustering. Current just do simple clustering with the package\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input a coordinate file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output of final results  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntranspose\n: Transpose the input matrix? Default: False  \n\n\nrnames\n: The \nrow.names\n for \nread.table\n to read the input file, default: True.  \n\n\ncnames\n: The \nheader\n argument for \nread.table\n to read the input file, default: True.  \n\n\ncaption\n: The caption for the \nfviz_cluster\n, default: \"CLARA Clustering\".  \n\n\nminc\n: The min # clusters to try, default: 2  \n\n\nmaxc\n: The max # clusters to try, default: 15  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-mclust\n\n    \nr-factoextra\n\n\n\n\n\n\n\n\n\n\npAPCluster\n\n\n\n\n\n\ndescription\n\n    Use \nr-apcluster\n to do clustering. \n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input a coordinate file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output of final results  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntranspose\n: Transpose the input matrix? Default: False  \n\n\nrownames\n: The \nrow.names\n for \nread.table\n to read the input file, default: 1.  \n\n\nheader\n: The \nheader\n argument for \nread.table\n to read the input file, default: True.  \n\n\ncaption\n: The caption for the \nfviz_cluster\n, default: \"APClustering\".  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-apcluster\n\n    \nr-factoextra\n\n\n\n\n\n\n\n\n\n\npHCluster\n\n\n\n\n\n\ndescription\n\n    Do hierarchical clustering.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input files with variants as rows, features as columns.  \n\n\nNOTE: clustering is performed on rows, rownames are the leaf labels.\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The result directory, containing:  \n\n\nhclust.merge.txt\n: including merge and height information\n\n\nhclust.order.txt\n: including order and labels information\n\n\nhclust.png\n:       the dendrogram plot\n\n\n\n\n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nfast\n: whether to use \nfastcluster\n package or not, default: False  \n\n\ngg\n: whether to use \nggdendro\n or not, default: False  \n\n\nrownames\n: The \nrow.names\n for \nread.table\n to read the input file, default: 1.  \n\n\nheader\n: The \nheader\n argument for \nread.table\n to read the input file, default: True.  \n\n\nmethod\n: Which method to use for \nhclust\n. Default: \"complete\" (use \n?hclust\n to check all availables)  \n\n\nrotate\n: Which to rotate the plot or not. Default: False  \n\n\ntranspose\n: Whether to transpose the matrix before cluster. Default: False  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-fastcluster\n if \nargs.fast\n is True\n    \nr-ggdendro\n if \nargs.gg\n is True\n\n\n\n\n\n\n\n\ncnvkit\n\n\n\n\npCNVkitAccess\n\n\n\n\n\n\ndescription\n\n    Calculate the sequence-accessible coordinates in chromosomes from the given reference genome, output as a BED file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nfafile:file\n: The fasta file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nparams\n: Other parameters for \ncnvkit.py access\n  \n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkitTarget\n\n\n\n\n\n\ndescription\n\n    Generate targets file for CNVkit using access file and annotate file (\ncnvkit.py target\n)\n\n\n\n\n\n\ninput\n  \n\n\n\n\nacfile:file\n: The access file  \n\n\nanfile:file\n: The annotate file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The targets file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nparams\n: Other parameters for \ncnvkit.py target\n  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkitCov\n\n\n\n\n\n\ndescription\n\n    Calculate coverage in the given regions from BAM read depths.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output cnn file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntgfile\n: The target file  \n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nnthread\n: The number of threads to use. Default: 1  \n\n\nparams\n: Other parameters for \ncnvkit.py coverage\n  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkitRef\n\n\n\n\n\n\ndescription\n\n    Compile a copy-number reference from the given files or directory (containing normal samples). If given a reference genome (-f option), also calculate the GC content and repeat-masked proportion of each region.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The input directory containing the cnn files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output reference cnn file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nparams\n: Other parameters for \ncnvkit.py reference\n, default: \" --no-edge \"  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkitFix\n\n\n\n\n\n\ndescription\n\n    Combine the uncorrected target and antitarget coverage tables (.cnn) and correct for biases in regional coverage and GC content, according to the given reference. Output a table of copy number ratios (.cnr)\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The cnn file to be fixed  \n\n\nrcfile:file\n: The reference cnn file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The cnr file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nparams\n: Other parameters for \ncnvkit.py fix\n, default: \" --no-edge \"  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkitSeg\n\n\n\n\n\n\ndescription\n\n    Infer discrete copy number segments from the given coverage table\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The cnr file   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The cns file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nnthread\n: The number of threads to use. Default: 1  \n\n\nparams\n: Other parameters for \ncnvkit.py segment\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkitCall\n\n\n\n\n\n\ndescription\n\n    Given segmented log2 ratio estimates (.cns), derive each segment's absolute integer copy number \n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The cns file   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The callcns file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nparams\n: Other parameters for \ncnvkit.py segment\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkitPlot\n\n\n\n\n\n\ndescription\n\n    Plot CNVkit results\n\n\n\n\n\n\ninput\n  \n\n\n\n\ncnrdir:file\n: The directory containing copy number ratio files  \n\n\ncnsdir:file\n: The directory containing copy number segment files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nregion\n: The region for zoom-in plots. Default: '' (don't plot zoom-in view)  \n\n\ngene\n: The genes to be highlighted. Default: ''  \n\n\nscatter\n: Whether to generate the scatter plot. Default: True  \n\n\ndiagram\n: Whether to generate the diagram plot. Default: True  \n\n\nheatmap\n: Whether to generate the heatmap plot. Default: True  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkitRpt\n\n\n\n\n\n\ndescription\n\n    Report CNVkit results\n\n\n\n\n\n\ninput\n  \n\n\n\n\ncnrfile:file\n: The file containing copy number ratio  \n\n\ncnsfile:file\n: The file containing copy number segment  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nbreaks\n: Whether to report breakpoints. Default: True  \n\n\ngainloss\n: Whether to report gainloss. Default: True  \n\n\nmetrics\n: Whether to report metrics. Default: True  \n\n\nsegmetrics\n: Whether to report segmetrics. Default: True  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\n\n\npCNVkit2Vcf\n\n\n\n\n\n\ndescription\n\n    Output vcf file for cnvkit results\n\n\n\n\n\n\ninput\n  \n\n\n\n\ncnsfile:file\n: The cns file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The vcf file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvkit\n: The executable of cnvkit. Default: 'cnvkit.py'  \n\n\nparams\n: Other params for \ncnvkit.py export\n  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVkit\n\n\n\n\n\n\n\n\ncommon\n\n\n\n\npSort\n\n\n\n\n\n\ndescription\n\n    Sort file using linux command \nsort\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nskip\n: To skip first N lines. Default: 0  \n\n\ncase\n: Case-sensitivity. Default: True  \n\n\nIf True, will set $LANG as C\n\n\nOtherwise, $LANG will be set as en_US.UTF-8\n\n\n\n\n\n\nmem\n    : The buffer size. Default: 4G  \n\n\ntmpdir\n : The tmpdir.  \n\n\nunique\n : Just keep the unique lines. Default: False  \n\n\ndelimit\n: The delimit to separate the fields. Default: '\\t'  \n\n\nparams\n : The arguments used by \nsort\n  \n\n\n\n\n\n\n\n\n\n\n\n\npFiles2Dir\n\n\n\n\n\n\ndescription\n\n    A helper process to convert a list of files into a directory, so that some processes can take it as input\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfiles:files\n: The input files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\n\n\n\n\npFile2Proc\n\n\n\n\n\n\ndescription\n\n    Convert a file to a proc so it can be used as dependent\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\n\n\n\n\npStr2File\n\n\n\n\n\n\ndescription\n\n    Save string to a file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nin:var\n: The input string.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file.  \n\n\n\n\n\n\n\n\n\n\n\n\npHead\n\n\n\n\n\n\ndescription\n\n    Get the top N lines from a file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nn\n: Top n lines. You may use '-n' to skip last n lines.  \n\n\n\n\n\n\n\n\n\n\n\n\npTail\n\n\n\n\n\n\ndescription\n\n    Get the bottom N lines from a file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nn\n: Bottom n lines. You may use '+n' to skip first n lines.  \n\n\n\n\n\n\n\n\n\n\n\n\npPrepend\n\n\n\n\n\n\ndescription\n\n    Prepend a string to a file\n\n\n\n\n\n\ninput\n  \n\n\n\n\nin:var\n: The input string.  \n\n\ninfile:file\n: The input file.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file.  \n\n\n\n\n\n\n\n\n\n\n\n\npAddHeader\n\n\n\n\n\n\ndescription\n\n    Add the header of 1st file to 2nd file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile1:file\n: The first file containing the header.  \n\n\ninfile2:file\n: The second file with the body.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file with the header from 1st input file, body from 2nd file.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nn\n: The number of header lines.  \n\n\n\n\n\n\n\n\n\n\n\n\npMergeFiles\n\n\n\n\n\n\ndescription\n\n    Merge files in the input directory\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The input directory  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninopts\n: The options for input file.  \n\n\ndefaults: skip: 0, comment: #, delimit '\\t'\n\n\n\n\n\n\noutopts\n: The options for output file. Defaults:  \n\n\nhead: False (not output head line)\n\n\nheadPrefix: \n#\n (The prefix for head line)\n\n\nheadDelimit: \n\\\\t\n (The delimit for head line)\n\n\nheadTransform: \nNone\n (The callback for head line)\n\n\ndelimit: \n\\\\t\n (The delimit for output line)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npSplitRows\n\n\n\n\n\n\ndescription\n\n    Split a file by rows, specially usefull to split a job into multithreads/multiprocesses.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory including the split files  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nskip\n: The skip first n lines. Default: \n0\n  \n\n\ncnames\n: The column names. If True, the column names will be added to each split file. Default: \nTrue\n  \n\n\nn\n: Number of files to split. Default: \n8\n  \n\n\n\n\n\n\n\n\n\n\neqtl\n\n\n\n\npMatrixeQTL\n\n\n\n\n\n\ndescription\n\n    Call eQTLs using Matrix eQTL\n\n\n\n\n\n\ninput\n  \n\n\n\n\nsnpfile:file\n: The genotype file, rows are snps and columns are samples  \n\n\nexpfile:file\n: The expression file, rows are genes  \n\n\ncovfile:file\n: The covariant file, rows are covariants  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The matrix eqtl output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nmodel\n: The model to use, either modelLINEAR(default) or modelANOVA  \n\n\npval\n : The pvalue cutoff (if \ncisopts.dist\n \n 0, will be used as pval for trans-eQTL)  \n\n\nfdr\n  : Calculate FDR or not (default: True)  \n\n\ncisopts\n: Options for calling cis-, trans-eQTL  \n\n\nsnppos\n : The snp position file (columns are: snp, chr, pos)\n\n\ngenepos\n: The gene position file (columns are: gene, chr, start, end)\n\n\ndist\n   : The distance to define cis-eQTL. (default: 0 (don't do cis-, trans- calling)\n\n\ncispv\n  : The pvalue cutoff for cis-eQTL (\npval\n will not work)\n\n\n\n\n\n\n\n\n\n\n\n\nrequires\n\n\nMatrix-eQTL (R)\n     \n\n\n\n\n\n\n\n\nfastx\n\n\n\n\npFastq2Expr\n\n\n\n\ndescription\n\n    Use Kallisto to get gene expression from pair-end fastq files.\n\n\n\n\n\n\n\n\npFastqSim\n\n\n\n\n\n\ndescription\n\n    Simulate reads\n\n\n\n\n\n\ninput\n  \n\n\n\n\nseed\n: The seed to generate simulation file  \n\n\nNone: use current timestamp.\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\nfq1:file\n: The first pair read file  \n\n\nfq2:file\n: The second pair read file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used for simulation. Default: wgsim (dwgsim)  \n\n\nlen1\n: The length of first pair read. Default: 100  \n\n\nlen2\n: The length of second pair read. Default: 100  \n\n\nnum\n: The number of read PAIRs. Default: 1000000  \n\n\ngz\n: Whether generate gzipped read file. Default: True  \n\n\nwgsim\n: The path of wgsim. Default: wgsim  \n\n\ndwgsim\n: The path of wgsim. Default: dwgsim  \n\n\nref\n: The reference genome. Required  \n\n\nparams\n: Other params for \ntool\n. Default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nwgsim\n\n\n\n\n\n\n\n\n\n\npFastQC\n\n\n\n\n\n\ndescription\n\n    QC report for fastq file\n\n\n\n\n\n\ninput\n  \n\n\n\n\nfq:file\n: The fastq file (also fine with gzipped)  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output direcotry  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used for simulation. Default: fastqc  \n\n\nfastqc\n: The path of fastqc. Default: fastqc  \n\n\nnthread\n: Number of threads to use. Default: 1  \n\n\nparams\n: Other params for \ntool\n. Default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nfastqc\n\n\n\n\n\n\n\n\n\n\npFastMC\n\n\n\n\n\n\ndescription\n\n    Multi-QC based on pFastQC\n\n\n\n\n\n\ninput\n  \n\n\n\n\nqcdir:file\n: The direcotry containing QC files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output direcotry  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used for simulation. Default: multiqc  \n\n\nmultiqc\n: The path of fastqc. Default: multiqc  \n\n\nparams\n: Other params for \ntool\n. Default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nmultiqc\n\n\n\n\n\n\n\n\n\n\npFastqTrim\n\n\n\n\n\n\ndescription\n\n    Trim pair-end FASTQ reads\n\n\n\n\n\n\ninput\n  \n\n\n\n\nfq1:file\n: The input fastq file  \n\n\nfq2:file\n: The input fastq file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfq1:file\n: The trimmed fastq file  \n\n\noutfq2:file\n: The trimmed fastq file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n        : The tools used for trimming. Default: trimmomatic (cutadapt|skewer)  \n\n\ncutadapt\n    : The path of seqtk. Default: cutadapt  \n\n\nskewer\n      : The path of fastx toolkit trimmer. Default: skewer  \n\n\ntrimmomatic\n : The path of trimmomatic. Default: trimmomatic  \n\n\nparams\n      : Other params for \ntool\n. Default: \"\"  \n\n\nnthread\n     : Number of threads to be used. Default: 1  \n\n\nNot for cutadapt\n\n\ngz\n          : Whether gzip output files. Default: True  \n\n\nmem\n         : The memory to be used. Default: 4G  \n\n\nOnly for trimmomatic\n\n\nminlen\n      : Discard trimmed reads that are shorter than \nminlen\n. Default: 18  \n\n\nFor trimmomatic, the number will be \nminlen\n*2 for MINLEN, as it filters before trimming\n\n\nminq\n        : Minimal mean qulity for 4-base window or leading/tailing reads. Default: 3  \n\n\ncut5\n        : Remove the 5'end reads if they are below qulity. Default: 3  \n\n\ncut3\n        : Remove the 3'end reads if they are below qulity. Default: 3  \n\n\nNot for skewer\n\n\nadapter1\n    : The adapter for sequence. Default: AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC  \n\n\nadapter2\n    : The adapter for pair-end sequence. Default: AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA  \n\n\n\n\n\n\n\n\nrequires\n\n\ncutadapt\n\n    \nskewer\n\n    \ntrimmomatic\n\n\n\n\n\n\n\n\n\n\npFastqSETrim\n\n\n\n\n\n\ndescription\n\n    Trim single-end FASTQ reads\n\n\n\n\n\n\ninput\n  \n\n\n\n\nfq:file\n: The input fastq file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfq:file\n: The trimmed fastq file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n        : The tools used for trimming. Default: trimmomatic (cutadapt|skewer)  \n\n\ncutadapt\n    : The path of seqtk. Default: cutadapt  \n\n\nskewer\n      : The path of fastx toolkit trimmer. Default: skewer  \n\n\ntrimmomatic\n : The path of trimmomatic. Default: trimmomatic  \n\n\nparams\n      : Other params for \ntool\n. Default: \"\"  \n\n\nnthread\n     : Number of threads to be used. Default: 1  \n\n\nNot for cutadapt\n\n\ngz\n          : Whether gzip output files. Default: True  \n\n\nmem\n         : The memory to be used. Default: 4G  \n\n\nOnly for trimmomatic\n\n\nminlen\n      : Discard trimmed reads that are shorter than \nminlen\n. Default: 18  \n\n\nFor trimmomatic, the number will be \nminlen\n*2 for MINLEN, as it filters before trimming\n\n\nminq\n        : Minimal mean qulity for 4-base window or leading/tailing reads. Default: 3  \n\n\ncut5\n        : Remove the 5'end reads if they are below qulity. Default: 3  \n\n\ncut3\n        : Remove the 3'end reads if they are below qulity. Default: 3  \n\n\nNot for skewer\n\n\nadapter\n     : The adapter for sequence. Default: AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC  \n\n\n\n\n\n\n\n\nrequires\n\n\ncutadapt\n\n    \nskewer\n\n    \ntrimmomatic\n\n\n\n\n\n\n\n\n\n\npFastqSE2Sam\n\n\n\n\n\n\ndescription\n\n    Cleaned paired fastq (.fq, .fq.gz, .fastq, .fastq.gz file to mapped sam/bam file\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used for alignment. Default: bwa (bowtie2|ngm)  \n\n\nbwa\n: Path of bwa, default: bwa  \n\n\nngm\n: Path of ngm, default: ngm  \n\n\nbowtie2\n: Path of bowtie2, default: bowtie2  \n\n\nrg\n: The read group. Default: {'id': '', 'pl': 'Illumina', 'pu': 'unit1', 'lb': 'lib1', 'sm': ''}  \n\n\nid\n will be parsed from filename with \"\nLX\n\" in it if not given\n\n\nsm\n will be parsed from filename\n\n\nref\n: Path of reference file  \n\n\nparams\n: Other params for tool, default: ''  \n\n\n\n\n\n\n\n\n\n\n\n\npFastq2Sam\n\n\n\n\n\n\ndescription\n\n    Cleaned paired fastq (.fq, .fq.gz, .fastq, .fastq.gz file to mapped sam/bam file\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n   : The tool used for alignment. Default: bwa (bowtie2, ngm, star)  \n\n\nbwa\n    : Path of bwa, default: bwa  \n\n\nngm\n    : Path of ngm, default: ngm  \n\n\nstar\n   : Path of ngm, default: STAR  \n\n\nbowtie2\n: Path of bowtie2, default: bowtie2  \n\n\nrg\n: The read group. Default: {'id': '', 'pl': 'Illumina', 'pu': 'unit1', 'lb': 'lib1', 'sm': ''}  \n\n\nid\n will be parsed from filename with \"\nLX\n\" in it if not given\n\n\nsm\n will be parsed from filename\n\n\nref\n    : Path of reference file  \n\n\nrefgene\n: The GTF file for STAR to build index. It's not neccessary if index is already been built. Default: ''  \n\n\nparams\n : Other params for tool, default: ''  \n\n\n\n\n\n\n\n\n\n\ngatk\n\n\n\n\npRealignerTargetCreator\n\n\n\n\n\n\ndescription\n\n    The local realignment process is designed to consume one or more BAM files and to locally realign reads such that the number of mismatching bases is minimized across all the reads. In general, a large percent of regions requiring local realignment are due to the presence of an insertion or deletion (indels) in the individual's genome with respect to the reference genome. Such alignment artifacts result in many bases mismatching the reference near the misalignment, which are easily mistaken as SNPs. Moreover, since read mapping algorithms operate on each read independently, it is impossible to place reads on the reference genome such that mismatches are minimized across all reads. Consequently, even when some reads are correctly mapped with indels, reads covering the indel near just the start or end of the read are often incorrectly mapped with respect the true indel, also requiring realignment. Local realignment serves to transform regions with misalignments due to indels into clean reads containing a consensus indel suitable for standard variant discovery approaches.\n    Note that indel realignment is no longer necessary for variant discovery if you plan to use a variant caller that performs a haplotype assembly step, such as HaplotypeCaller or MuTect2. However it is still required when using legacy callers such as UnifiedGenotyper or the original MuTect. There are 2 steps to the realignment process:\n\n\n\n\nDetermining (small) suspicious intervals which are likely in need of realignment (RealignerTargetCreator)\n\n\nRunning the realigner over those intervals (see the IndelRealigner tool)\nFor more details, see \nthe indel realignment method documentation\n.\n\n\n\n\n\n\n\n\ninput\n  \n\n\n\n\nbamfile:file\n: The aligned bam file  \n\n\nreffile\n: The reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\nbamfile\n: \n{{bamfile | bn}}.bai\n The index file of input bam file  \n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: A list of target intervals to pass to the IndelRealigner.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n: The gatk executable, default: \"gatk\"  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\nparams\n: Other parameters for RealignerTargetCreator, default: \"\"  \n\n\nsamtools\n: The samtools executable, default: \"samtools\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if \nreffile\n is not indexed or \nbamfile\n is not indexed.\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\n\n\npIndelRealigner\n\n\n\n\n\n\ndescription\n\n    The local realignment process is designed to consume one or more BAM files and to locally realign reads such that the number of mismatching bases is minimized across all the reads. In general, a large percent of regions requiring local realignment are due to the presence of an insertion or deletion (indels) in the individual's genome with respect to the reference genome. Such alignment artifacts result in many bases mismatching the reference near the misalignment, which are easily mistaken as SNPs. Moreover, since read mapping algorithms operate on each read independently, it is impossible to place reads on the reference genome such at mismatches are minimized across all reads. Consequently, even when some reads are correctly mapped with indels, reads covering the indel near just the start or end of the read are often incorrectly mapped with respect the true indel, also requiring realignment. Local realignment serves to transform regions with misalignments due to indels into clean reads containing a consensus indel suitable for standard variant discovery approaches.\n    Note that indel realignment is no longer necessary for variant discovery if you plan to use a variant caller that performs a haplotype assembly step, such as HaplotypeCaller or MuTect2. However it is still required when using legacy callers such as UnifiedGenotyper or the original MuTect.\n    There are 2 steps to the realignment process:\n\n\n\n\nDetermining (small) suspicious intervals which are likely in need of realignment (see the RealignerTargetCreator tool)\n\n\nRunning the realigner over those intervals (IndelRealigner)\nFor more details, see \nthe indel realignment method documentation\n.\n\n\n\n\n\n\n\n\ninput\n  \n\n\n\n\nbamfile:file\n: The aligned bam file  \n\n\nintfile:file\n: Intervals file output from RealignerTargetCreator  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\nbamfile\n: \n{{bamfile | bn}}.bai\n The index file of input bam file  \n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: A realigned version of input BAM file.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n: The gatk executable, default: \"gatk\"  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\nparams\n: Other parameters for IndelRealigner, default: \"\"  \n\n\nsamtools\n: The samtools executable, default: samtools  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if \nreffile\n is not indexed or \nbamfile\n is not indexed.\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\n\n\npBaseRecalibrator\n\n\n\n\n\n\ndescription\n\n    Variant calling algorithms rely heavily on the quality scores assigned to the individual base calls in each sequence read. These scores are per-base estimates of error emitted by the sequencing machines. Unfortunately the scores produced by the machines are subject to various sources of systematic technical error, leading to over- or under-estimated base quality scores in the data. Base quality score recalibration (BQSR) is a process in which we apply machine learning to model these errors empirically and adjust the quality scores accordingly. This allows us to get more accurate base qualities, which in turn improves the accuracy of our variant calls. The base recalibration process involves two key steps: first the program builds a model of covariation based on the data and a set of known variants (which you can bootstrap if there is none available for your organism), then it adjusts the base quality scores in the data based on the model. There is an optional but highly recommended step that involves building a second model and generating before/after plots to visualize the effects of the recalibration process. This is useful for quality control purposes. This tool performs the first step described above: it builds the model of covariation and produces the recalibration table. It operates only at sites that are not in dbSNP; we assume that all reference mismatches we see are therefore errors and indicative of poor base quality. This tool generates tables based on various user-specified covariates (such as read group, reported quality score, cycle, and context). Assuming we are working with a large amount of data, we can then calculate an empirical probability of error given the particular covariates seen at this site, where p(error) = num mismatches / num observations. The output file is a table (of the several covariate values, number of observations, number of mismatches, empirical quality score).\n\n\n\n\n\n\ninput\n  \n\n\n\n\nbamfile:file\n: A BAM file containing data that needs to be recalibrated.  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\nbamfile\n: \n{{bamfile | bn}}.bai\n The index file of input bam file  \n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: A GATKReport file with many tables:  \n\n\nThe list of arguments\n\n\nThe quantized qualities table\n\n\nThe recalibration table by read group\n\n\nThe recalibration table by quality score\n\n\nThe recalibration table for all the optional covariates\n\n\n\n\n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n: The gatk executable, default: \"gatk\"  \n\n\nparams\n: Other parameters for BaseRecalibrator, default: \"\"  \n\n\nknownSites\n: The known polymorphic sites to mask out, required  \n\n\nsamtools\n: The samtools executable, default: samtools  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if \nreffile\n is not indexed or \nbamfile\n is not indexed.\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\n\n\npPrintReads\n\n\n\n\n\n\ndescription\n\n    PrintReads is a generic utility tool for manipulating sequencing data in SAM/BAM format. It can dynamically merge the contents of multiple input BAM files, resulting in merged output sorted in coordinate order. It can also optionally filter reads based on various read properties such as read group tags using the \n--read_filter/-rf\n command line argument (see documentation on read filters for more information).\n    Note that when PrintReads is used as part of the Base Quality Score Recalibration workflow, it takes the \n--BQSR\n engine argument, which is listed under Inherited Arguments \n CommandLineGATK below.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nbamfile:file\n: A BAM file.  \n\n\nrecaltable:file\n: The GATKReport file  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\nbamfile\n: \n{{bamfile | bn}}.bai\n The index file of input bam file  \n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: A single processed bam file.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n: The gatk executable, default: \"gatk\"  \n\n\nparams\n: Other parameters for PrintReads, default: \"\"  \n\n\nsamtools\n: The samtools executable, default: samtools  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if \nreffile\n is not indexed or \ninfile\n is not indexed.\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\n\n\npHaplotypeCaller\n\n\n\n\n\n\ndescription\n\n    PrintReads is a generic utility tool for manipulating sequencing data in SAM/BAM format. It can dynamically merge the contents of multiple input BAM files, resulting in merged output sorted in coordinate order. It can also optionally filter reads based on various read properties such as read group tags using the \n--read_filter/-rf\n command line argument (see documentation on read filters for more information).\n    Note that when PrintReads is used as part of the Base Quality Score Recalibration workflow, it takes the \n--BQSR\n engine argument, which is listed under Inherited Arguments \n CommandLineGATK below.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nbamfile:file\n: A BAM file.  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\nbamfile\n: \n{{bamfile | bn}}.bai\n The index file of input bam file  \n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: Either a VCF or gVCF file with raw, unfiltered SNP and indel calls.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n    : The gatk executable, default: \"gatk\"  \n\n\nparams\n  : Other parameters for HaplotypeCaller, default: \"\"  \n\n\nsamtools\n: The samtools executable, default: samtools  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\nnthread\n: Corresponding to -nct option  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if \nreffile\n is not indexed or \ninfile\n is not indexed.\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\n\n\npSelectVariants\n\n\n\n\n\n\ndescription\n\n    Often, a VCF containing many samples and/or variants will need to be subset in order to facilitate certain analyses (e.g. comparing and contrasting cases vs. controls; extracting variant or non-variant loci that meet certain requirements, displaying just a few samples in a browser like IGV, etc.). SelectVariants can be used for this purpose.\n    There are many different options for selecting subsets of variants from a larger callset:\n\n\n\n\nExtract one or more samples from a callset based on either a complete sample name or a pattern match.\n\n\nSpecify criteria for inclusion that place thresholds on annotation values, e.g. \"DP \n 1000\" (depth of coverage greater than 1000x), \"AF \n 0.25\" (sites with allele frequency less than 0.25). These - criteria are written as \"JEXL expressions\", which are documented in the article about using JEXL expressions.\n\n\nProvide concordance or discordance tracks in order to include or exclude variants that are also present in other given callsets.\n\n\nSelect variants based on criteria like their type (e.g. INDELs only), evidence of mendelian violation, filtering status, allelicity, and so on.\nThere are also several options for recording the original values of certain annotations that are recalculated when a subsetting the new callset, trimming alleles, and so on.\n\n\n\n\n\n\n\n\ninput\n  \n\n\n\n\nvcffile:file\n: A variant call set from which to select a subset.  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: A new VCF file containing the selected subset of variants.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n: The gatk executable, default: \"gatk\"  \n\n\nparams\n: Other parameters for SelectVariants, default: \"\"  \n\n\nsamtools\n: The samtools executable, default: samtools  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if \nreffile\n is not indexed or \ninfile\n is not indexed.\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\n\n\npVariantFiltration\n\n\n\n\n\n\ndescription\n\n    This tool is designed for hard-filtering variant calls based on certain criteria. Records are hard-filtered by changing the value in the FILTER field to something other than PASS. Filtered records will be preserved in the output unless their removal is requested in the command line.\n    The most common way of specifying filtering criteria is by using JEXL queries. See the article on JEXL expressions in the documentation Guide for detailed information and examples.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nvcffile:file\n: A variant call set from which to select a subset.  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: A filtered VCF.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n: The gatk executable, default: \"gatk -T VariantFiltration\"  \n\n\nparams\n: Other parameters for VariantFiltration, default: \"\"  \n\n\nsamtools\n: The samtools executable, default: samtools  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if \nreffile\n is not indexed or \ninfile\n is not indexed.\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\n\n\npMuTect2\n\n\n\n\n\n\ndescription\n\n    MuTect2 is a somatic SNP and indel caller that combines the DREAM challenge-winning somatic genotyping engine of the original MuTect (\nCibulskis et al., 2013\n) with the assembly-based machinery of HaplotypeCaller. The basic operation of MuTect2 proceeds similarly to that of the HaplotypeCaller.\n    NOTE: only Tumor/Normal variant calling implemented in bioprocs\n\n\n\n\n\n\ninput\n  \n\n\n\n\ntumor:file\n: the tumor bam file  \n\n\nnormal:file\n: the normal bam file  \n\n\nreffile:file\n: the reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\ntumor\n: \n{{tumor | bn}}.bai\n the index file of tumor  \n\n\nnormal\n: \n{{normal | bn}}.bai\n the index file of normal  \n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The vcf file containing somatic mutations  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n: The gatk executable, default: \"gatk\"  \n\n\nsamtools\n: The samtools executable, default: samtools  \n\n\nparams\n: Other parameters for MuTect2, default: \"\"  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if index files of input files are not found\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\n\n\npMuTect2Interval\n\n\n\n\n\n\ndescription\n\n    Use interval file model of MuTect2\n\n\n\n\n\n\ninput\n  \n\n\n\n\ntumor:file\n: the tumor bam file  \n\n\nnormal:file\n: the normal bam file  \n\n\nreffile:file\n: the reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\ntumor\n: \n{{tumor | bn}}.bai\n the index file of tumor  \n\n\nnormal\n: \n{{normal | bn}}.bai\n the index file of normal  \n\n\nreffile#fai\n: \n{{reffile | bn}}.fai\n  \n\n\nreffile#dict\n: \n{{reffile | bn}}.dict\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The vcf file containing somatic mutations  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngatk\n: The gatk executable, default: \"gatk\"  \n\n\nsamtools\n: The samtools executable, default: samtools  \n\n\nparams\n: Other parameters for MuTect2, default: \"\"  \n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nGATK\n\n    \nsamtools\n if index files of input files are not found\n    \npicard\n if \nreffile\n is not dicted.\n\n\n\n\n\n\n\n\ngene\n\n\n\n\npGenePromoters\n\n\n\n\ndescription\n\n    Alias of \nseq.pPromoters\n.\n\n\n\n\n\n\n\n\npGeneNameNorm\n\n\n\n\n\n\ndescription\n\n    Normalize gene names using MyGeneinfo.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nnotfound\n: What if a symbol is not found. Default: ignore  \n\n\nskip  : skip the record(don't write it to output file)\n\n\nignore: use the original name;\n\n\nerror : report error\n\n\n\n\n\n\ncol\n: the column index containing the gene names  \n\n\nfrom\n: the original format. Default: 'symbol, alias'  \n\n\nto\n: the output gene name format. Default: 'symbol'  \n\n\ngenome\n: the genome. Default: 'hg19'  \n\n\n\n\n\n\n\n\n\n\n\n\npGeneTss\n\n\n\n\n\n\ndescription\n\n    Get gene TSS in BEd format.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file containing genes  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output BED file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nnotfound\n: What if the gene is not found. Default: skip.  \n\n\nerror: report error\n\n\n\n\n\n\nheader\n: Whether the input file contains header. Default: False  \n\n\nskip\n: Skip N lines of input file. Default: 0  \n\n\nThis has highest priority of header and comment\n\n\n\n\n\n\ncomment\n: The comment line start sign. Default: #  \n\n\ndelimit\n: The delimit of input file if it has multiple column. Default: \n\\\\t\n  \n\n\ncol\n: The column index contains the genes. Default: 0  \n\n\nfrm\n: The format of the genes. Default: \nsymbol, alias\n  \n\n\ntmpdir\n: The tmpdir used to store mygene cache files.  \n\n\ngenome\n: In which genome to fetch the coordinates. Default: hg19  \n\n\n\n\n\n\n\n\n\n\n\n\npGeneBody\n\n\n\n\n\n\ndescription\n\n    Get gene body region in BED format\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file containing genes  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The gene body region  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nnotfound\n: What if a gene is not found when transfer the gene names to gene symbols  \n\n\nerror: report error\n\n\nskip (default): skip it\n\n\n\n\n\n\ninmeta\n: The metadata for input file, mainly to indicate where the GENE column is.  \n\n\ninopts\n: Input options for reading input file.  \n\n\nskip: number of lines to skip. Default: 0\n\n\ncomment: the starting string for comment lines. Default: #\n\n\ndelimit: The delimit for the input file. Default: '\\t'\nfrm: The gene name format in the input file. Default: 'symbol, alias'\ntmpdir: The tmpdir to cache the gene name conversion.\ngenome: The genome used to do the conversion.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngenomeplot\n\n\n\n\npInteractionTrack\n\n\n\n\n\n\ndescription\n\n    Gererate genomic interaction track for Gviz\n\n\n\n\n\n\ninput\n  \n\n\n\n\nname\n: The name of the track  \n\n\ninfile:file\n: The input file.   \n\n\nSee the \ntype\n argument for \nmakeGenomicInteractionsFromFile\n from \nGenomicInteractions\n r-package\n\n\n\n\n\n\nregion\n: the region, just chromosome!  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The dumped track data  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nintype\n: Input file type. Default: auto  \n\n\nIdentified by extension\n\n\nOne of \"chiapet.tool\", \"bed12\", \"bedpe\", \"hiclib\", \"homer\", \"bam\", \"two.bams\".\n\n\n\n\n\n\nparams\n: The display params  \n\n\n\n\n\n\n\n\n\n\n\n\npGeneTrack\n\n\n\n\n\n\ndescription\n\n    Generate gene track using ucsc data source\n\n\n\n\n\n\ninput\n  \n\n\n\n\nname\n: The name of the track  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The file to save the track  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngenome\n: The genome  \n\n\nparams\n: use \ndisplayPars(UcscTrack(genome=\"mm9\", chromosome=\"chrM\", track=\"knownGene\"))\n to see all available args  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-Gviz\n\n\n\n\n\n\n\n\n\n\npAnnoTrack\n\n\n\n\n\n\ndescription\n\n    The annotation track of Gviz\n\n\n\n\n\n\ninput\n  \n\n\n\n\nname\n: the name of the track  \n\n\ninfile:file\n: the file for the track. (wig, bigWig or bedGraph, bam, need to be indexed!)  \n\n\nchrom\n: the chrom  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the rds file for the track  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngenome\n: The genome  \n\n\nparams\n: See \ndisplayPars(DataTrack())\n for all available display params  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-Gviz\n\n\n\n\n\n\n\n\n\n\npDataTrack\n\n\n\n\n\n\ndescription\n\n    The data track of Gviz\n\n\n\n\n\n\ninput\n  \n\n\n\n\nname\n: the name of the track  \n\n\ninfile:file\n: the file for the track. (wig, bigWig or bedGraph, bam, need to be indexed!)  \n\n\nchrom\n: the chrom  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the rds file for the track  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngenome\n: The genome  \n\n\nparams\n: See \ndisplayPars(DataTrack())\n for all available display params  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-Gviz\n\n\n\n\n\n\n\n\n\n\npUcscTrack\n\n\n\n\n\n\ndescription\n\n    Generate track from ucsc\n\n\n\n\n\n\ninput\n  \n\n\n\n\nname\n     : the name of the track  \n\n\ntrack\n    : the UCSC track  \n\n\ntrackType\n: the Gviz track  \n\n\nregion\n   : the region  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the dumped track  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nparams\n: use \ndisplayPars(UcscTrack(genome=\"mm9\", chromosome=\"chrM\", track=\"knownGene\"))\n to see all available args.  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-Gviz\n\n\n\n\n\n\n\n\n\n\npGenomePlot\n\n\n\n\n\n\ndescription\n\n    plot the genomic features\n\n\n\n\n\n\ninput\n  \n\n\n\n\ntrkfiles:files\n: the list of track dumped files  \n\n\nregion\n: the region, in format of \nchr1:1-1000\n  \n\n\nhighlight\n: the highlight regions, informat of start1-end1; start2-end2; ...  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the figure  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngenome\n  : The genome  \n\n\nshowIdeo\n: Show ideogram track? Default: True  \n\n\nshowAxis\n: Show axis? Default: True  \n\n\nshowGenes\n: Show geneTrack? Default: True  \n\n\nparams\n: The params  \n\n\ngenneral\n:  General params for plotTracks\n\n\ngeneTrack\n: The params for geneTrack\n\n\n\n\n\n\n\n\n\n\n\n\nrequires\n\n\nr-Gviz\n\n\n\n\n\n\n\n\ngsea\n\n\n\n\npGMT2Mat\n\n\n\n\n\n\ndescription\n\n    Convert a GMT file to a matrix.\n    Rownames of GMT file will be the column names of output matrix.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file in GMT format.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: output matrix file  \n\n\n\n\n\n\n\n\n\n\n\n\npExpmat2Gct\n\n\n\n\n\n\ndescription\n\n    Convert expression matrix to GCT file.\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GCT for file format\n\n\n\n\n\n\ninput\n  \n\n\n\n\nexpfile:file\n: the input expression matrix file. Samples as columns, genes as rows.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the gct file  \n\n\n\n\n\n\n\n\n\n\n\n\npSampleinfo2Cls\n\n\n\n\n\n\ndescription\n\n    Convert sample infomation to cls file.\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#CLS for file format\n    NOTE that the order of samples must be the same as in GMT file in further analysis.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nsifile:file\n: the sample information file.  \n\n\nHeaders are: [Sample, ]Patient, Group, Batch\n\n\nRows are samples\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the cls file  \n\n\n\n\n\n\n\n\n\n\n\n\npSSGSEA\n\n\n\n\n\n\ndescription\n\n    Single sample GSEA\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GCT for GCT file format\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GMT for GMT file format\n\n\n\n\n\n\ninput\n  \n\n\n\n\ngctfile:file\n: the expression file  \n\n\ngmtfile:file\n: the gmtfile for gene sets  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:file\n: the output directory  \n\n\nreport.txt\n: the enrichment report for each Gene set.\n\n\nRES_\nGeneSet\n.png\n: the running ES plot for \n\n\nnormP_\nGeneSet\n.png\n: the norminal P value plot for \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nweightexp\n: Exponential weight employed in calculation of enrichment scores. Default: 0.75  \n\n\nnperm\n: Number of permutations. Default: 10000  \n\n\n\n\n\n\n\n\n\n\n\n\npGSEA\n\n\n\n\n\n\ndescription\n\n    GSEA\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GCT for GCT file format\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GMT for GMT file format\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#CLS for CLS file format\n\n\n\n\n\n\ninput\n  \n\n\n\n\ngctfile:file\n: the expression file  \n\n\nclsfile:file\n: the class file  \n\n\ngmtfile:file\n: the gmtfile for gene sets  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:file\n: the output directory  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nweightexp\n: Exponential weight employed in calculation of enrichment scores. Default: 0.75  \n\n\nnperm\n: Number of permutations. Default: 10000  \n\n\n\n\n\n\n\n\n\n\n\n\npEnrichr\n\n\n\n\n\n\ndescription\n\n    Use APIs from http://amp.pharm.mssm.edu/Enrichr/help#api\nq=1 to analyze a gene list\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The gene list, each per line  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory, containing the tables and figures.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntopn\n: Top N pathways used to plot. Default: 10  \n\n\ncol\n: The columns index containing the genes. Default: 0  \n\n\ndelimit\n: The delimit of input file. Default: '\\t'  \n\n\ndbs\n: The databases to do enrichment against. Default: KEGG_2016  \n\n\nA full list can be found here: http://amp.pharm.mssm.edu/Enrichr/#stats\n\n\nMultiple dbs separated by comma (,)\n\n\nnorm\n: Normalize the gene list use \npython-mygene\n  \n\n\nrmtags\n: Remove pathway tags in the plot. Default: True  \n\n\nFor example: change \"Lysine degradation_Homo sapiens_hsa00310\" to \"Lysine degradation\".\n\n\nplot\n: Whether to plot the result. Default: True  \n\n\ntitle\n: The title for the plot. Default: \"Gene enrichment: {db}\"  \n\n\n\n\n\n\n\n\nrequires\n\n\npython-mygene\n if \nargs.norm\n is \nTrue\n\n\n\n\n\n\n\n\n\n\npTargetEnrichr\n\n\n\n\n\n\ndescription\n\n    Use APIs from http://amp.pharm.mssm.edu/Enrichr/help#api\nq=1 to analyze a gene list\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The target genes with regulators  \n\n\nFormat:\n\n\nHeader is not required, but may specified in first line starting with \n#\n\n\nIf only 3 columns are there, the 3rd column is anyway the relation!\n\n\nIf only 4 columns are there, 3rd is target status, 4th is relation!\n  \n#Regulator\tTarget\tRegulator status\tTarget status\tRelation\nhas-mir-22\tGene\t+\t+\t+\n\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory, containing the tables and figures.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ndbs\n       : The databases to do enrichment against. Default: KEGG_2016  \n\n\nA full list can be found here: http://amp.pharm.mssm.edu/Enrichr/#stats\n\n\nMultiple dbs separated by comma (,)\n\n\nrmtags\n    : Remove pathway tags in the plot. Default: True  \n\n\nFor example: change \"Lysine degradation_Homo sapiens_hsa00310\" to \"Lysine degradation\".\n\n\nenrplot\n   : Whether to plot the result. Default: True  \n\n\nenrn\n      : Top N pathways used to plot. Default: 10  \n\n\nnetplot\n   : Whether to plot the network. Default: True  \n\n\nnetn\n      : Top N pathways used to plot the network. Default: 5  \n\n\nMust \n= \nenrn\n. If \nnetn\n \n= \nenrn\n, \nnetn\n = \nenrn\n\n\n\n\n\n\ntitle\n     : The title for the plot. Default: \"Gene enrichment: {db}\"  \n\n\n\n\n\n\n\n\nrequires\n\n\npython-mygene\n\n    \ngraphviz\n\n\n\n\n\n\n\n\nhic\n\n\nmarray\n\n\n\n\npCELdir2Matrix\n\n\n\n\n\n\ndescription\n\n    Convert CEL files to expression matrix\n    File names will be used as sample names (colnames)\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: the directory containing the CEL files, could be gzipped  \n\n\nIf you have files, then use \npFiles2Dir\n first\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the expression matrix file  \n\n\noutdir:dir\n: the directory containing expr file and plots  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npattern\n  : The pattern to filter files. Default \n'*'\n  \n\n\nnorm\n     : The normalization method. Default: rma (mas5)  \n\n\ngfile\n    : The group file. Default: ''  \n\n\ncdffile\n  : The cdffile. Default: ''  \n\n\nannofile\n : The annotation file. Default: ''  \n\n\nhmrows\n   : How many rows to be used to plot heatmap  \n\n\nplot\n: Whether to plot  \n\n\nboxplot\n   : Whether to plot a boxplot. Default: False\n\n\nheatmap\n   : Whether to plot a heatmap. Default: False\n\n\nhistogram\n : Whether to plot a histgram. Default: False\n\n\n\n\n\n\ndevpars\n    : Parameters for png. Default: \n{'res': 300, 'width': 2000, 'height': 2000}\n  \n\n\nggs\n: The ggplot parameters  \n\n\nboxplot\n  : The ggplot parameters for boxplot. Default: \nBox(ylab = {0: \"Log2 Intensity\"})\n\n\nheatmap\n  : The ggplot parameters for heatmap. Default: \nBox(theme = {'axis.text.y': 'r:element_blank()'})\n\n\nhistogram\n: The ggplot parameters for histgram. Default: \nBox(labs = {'x': \"Log2 Intensity\", \"y\": \"Density\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmisc\n\n\n\n\npGEP70\n\n\n\n\n\n\ndescription\n\n    Calculate GEP70 scores for multiple mylenoma 70-gene-signatures\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file with expression matrix  \n\n\nColumns are samples, rows are genes\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output files with gep70 scores for each sample.  \n\n\nSamples become rows, just one column is in the file.\n\n\n\n\n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninopts\n: The input options.  \n\n\ncnames\n: Whether the input file has column names. Default: \nTrue\n\n\n\n\n\n\ngep70\n: The GEP70 genes.   \n\n\nColumn 1: up-regulated genes (51)\n\n\nColumn 2: down-regulated genes (19)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npca\n\n\n\n\npPCA\n\n\n\n\n\n\ndescription\n\n    Perform PCA analysis\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The matrix to do the analysis  \n\n\nNote that rows are samples, columns are features, if not, use \nargs.transpose = True\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output coordinate file  \n\n\nColumns are PCs, rows are samples\n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntranspose\n: Whether to transpose the input matrix from infile. Default: False  \n\n\nrownames\n: The \nrow.names\n argument for \nread.table\n, default: 1  \n\n\nheader\n: The \nheader\n argument for \nread.table\n to read the input file, default: True.  \n\n\nscreeplot\n: Whether to generate the screeplot or not. Default: True  \n\n\nsp_ncp\n: Number of components in screeplot. Default: 0 (auto detect)  \n\n\nif total # components (tcp) \n 20: use all\n\n\nelse if tcp \n 20, use 20\n\n\nvarplot\n: Whether to generate the variable plot or not. Default: False  \n\n\nbiplot\n: Whether to generate the variable plot or not. Default: True  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-factoextra\n for plots\n\n\n\n\n\n\n\n\n\n\npSelectPCs\n\n\n\n\n\n\ndescription\n\n    Select a subset of PCs from pPCA results\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The directory generated from pPCA  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The file containing selected PCs  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nn\n: The number of PCs to select. Default: 0.9  \n\n\nIf it is \n 1, used as the % variation explained from stdev.txt\n\n\n\n\n\n\n\n\n\n\npicard\n\n\n\n\npMarkDuplicates\n\n\n\n\n\n\ndescription\n\n    Identifies duplicate reads.\n\n\nThis tool locates and tags duplicate reads in a BAM or SAM file, where duplicate reads are defined as originating from a single fragment of DNA. Duplicates can arise during sample preparation e.g. library construction using PCR. See also EstimateLibraryComplexity for additional notes on PCR duplication artifacts. Duplicate reads can also result from a single amplification cluster, incorrectly detected as multiple clusters by the optical sensor of the sequencing instrument. These duplication artifacts are referred to as optical duplicates.\n\n\nThe MarkDuplicates tool works by comparing sequences in the 5 prime positions of both reads and read-pairs in a SAM/BAM file. An BARCODE_TAG option is available to facilitate duplicate marking using molecular barcodes. After duplicate reads are collected, the tool differentiates the primary and duplicate reads using an algorithm that ranks reads by the sums of their base-quality scores (default method).\n\n\nThe tool's main output is a new SAM or BAM file, in which duplicates have been identified in the SAM flags field for each read. Duplicates are marked with the hexadecimal value of 0x0400, which corresponds to a decimal value of 1024. If you are not familiar with this type of annotation, please see the following \nblog post\n for additional information.\n\n\nAlthough the bitwise flag annotation indicates whether a read was marked as a duplicate, it does not identify the type of duplicate. To do this, a new tag called the duplicate type (DT) tag was recently added as an optional output in the 'optional field' section of a SAM/BAM file. Invoking the TAGGING_POLICY option, you can instruct the program to mark all the duplicates (All), only the optical duplicates (OpticalOnly), or no duplicates (DontTag). The records within the output of a SAM/BAM file will have values for the 'DT' tag (depending on the invoked TAGGING_POLICY), as either library/PCR-generated duplicates (LB), or sequencing-platform artifact duplicates (SQ). This tool uses the READ_NAME_REGEX and the OPTICAL_DUPLICATE_PIXEL_DISTANCE options as the primary methods to identify and differentiate duplicate types. Set READ_NAME_REGEX to null to skip optical duplicate detection, e.g. for RNA-seq or other data where duplicate sets are extremely large and estimating library complexity is not an aim. Note that without optical duplicate counts, library size estimation will be inaccurate.\n\n\nMarkDuplicates also produces a metrics file indicating the numbers of duplicates for both single- and paired-end reads.\n\n\nThe program can take either coordinate-sorted or query-sorted inputs, however the behavior is slightly different. When the input is coordinate-sorted, unmapped mates of mapped records and supplementary/secondary alignments are not marked as duplicates. However, when the input is query-sorted (actually query-grouped), then unmapped mates and secondary/supplementary reads are not excluded from the duplication test and can be marked as duplicate reads.\n\n\nIf desired, duplicates can be removed using the REMOVE_DUPLICATE and REMOVE_SEQUENCING_DUPLICATES options.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The marked bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\nparams\n: Other parameters for picard MarkDuplicates, default: \"\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n\n\n\n\n\n\n\n\n\npAddOrReplaceReadGroups\n\n\n\n\n\n\ndescription\n\n    Replace read groups in a BAM file.This tool enables the user to replace all read groups in the INPUT file with a single new read group and assign all reads to this read group in the OUTPUT BAM file.\n\n\nFor more information about read groups, see the \nGATK Dictionary entry\n. \n\n\nThis tool accepts INPUT BAM and SAM files or URLs from the Global Alliance for Genomics and Health (GA4GH) (see http://ga4gh.org/#/documentation).\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file  \n\n\nrg\n: The read group information. For example:  \n\n\n\"RGID=4 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM=20\"\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The bam file with read group added  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npicard\n: The picard executable, default: \"picard \"  \n\n\nparams\n: Other parameters for picard AddOrReplaceReadGroups, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n\n\n\n\n\n\n\n\n\npCreateSequenceDictionary\n\n\n\n\n\n\ndescription\n\n    Creates a sequence dictionary for a reference sequence. This tool creates a sequence dictionary file (with \".dict\" extension) from a reference sequence provided in FASTA format, which is required by many processing and analysis tools. The output file contains a header but no SAMRecords, and the header contains only sequence records.\n\n\nThe reference sequence can be gzipped (both .fasta and .fasta.gz are supported).\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The fasta file   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The same fasta file, but with dict file created  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\nparams\n: Other parameters for picard CreateSequenceDictionary, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n\n\n\n\n\n\n\n\n\npCollectWgsMetrics\n\n\n\n\n\n\ndescription\n\n    Collect metrics about coverage and performance of whole genome sequencing (WGS) experiments.\n\n\nThis tool collects metrics about the fractions of reads that pass base- and mapping-quality filters as well as coverage (read-depth) levels for WGS analyses. Both minimum base- and mapping-quality values as well as the maximum read depths (coverage cap) are user defined.\n\n\nNote: Metrics labeled as percentages are actually expressed as fractions!\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The metrics file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\nparams\n: Other parameters for \npicard CollectWgsMetrics\n, default: \"\"  \n\n\nreffile\n: The reference file, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n\n\n\n\n\n\n\n\n\npSortSam\n\n\n\n\n\n\ndescription\n\n    Use \npicard SortSam\n to sort sam or bam file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The sam or bam file to be sorted  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The sorted sam or bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\norder\n: The sort order, default: coordinate. Possible: unsorted, queryname, coordinate, duplicate  \n\n\nouttype\n: The type of output file, sam or bam. Default: bam  \n\n\nparams\n: Other parameters for \npicard SortSam\n, default: \"\"  \n\n\ntmpdir\n: The tmpdir to use. Default: /tmp  \n\n\njavamem\n: The memory for java vm. Default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n\n\n\n\n\n\n\n\n\npIndexBam\n\n\n\n\n\n\ndescription\n\n    Use \npicard BuildBamIndex\n to index bam file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The same bam file (link) but with .bai file in \nproc.outdir\n  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npicard\n: The picard executable, default: \"picard\"  \n\n\nparams\n: Other parameters for \npicard BuildBamIndex\n, default: \"-Xms1g -Xmx8g\"  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n\n\n\n\n\n\n\nplot\n\n\n\n\npPlot\n\n\n\n\n\n\ndescription\n\n    Use ggplot2 to generate plots\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input data file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n : Whether the input file has colnames. Default: True  \n\n\nrnames\n : Whether the input file has rownames. Default: False  \n\n\naes\n    : The default aes. Default: {'x':1, 'y':2} (corresponding to colnames)  \n\n\nhelper\n : Some helper codes to generate \nparams\n and \nggs\n  \n\n\ndevpars\n: The device parameters. Default: \nBox(res = 300, height = 2000, width = 2000)\n  \n\n\nggs\n    : The extra ggplot elements.  \n\n\n\n\n\n\n\n\n\n\n\n\npScatter\n\n\n\n\n\n\ndescription\n\n    Use ggplot2 geom_point to generate plots\n\n\n\n\n\n\ninfile\n  \n\n\n\n\ninfile:file\n: The input data file  \n\n\n\n\n\n\n\n\noutfile\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n : Whether the input file has colnames. Default: True  \n\n\nrnames\n : Whether the input file has rownames. Default: False  \n\n\nx\n      : The x aes. Default: 1 (corresponding to colnames)  \n\n\ny\n      : The y aes. Default: 2 (corresponding to colnames)  \n\n\nhelper\n : Some helper codes to generate \nparams\n and \nggs\n  \n\n\ndevpars\n: The device parameters. Default: \nBox(res = 300, height = 2000, width = 2000)\n  \n\n\nparams\n : The extra params for \ngeom_point\n  \n\n\nggs\n    : The extra ggplot elements.  \n\n\n\n\n\n\n\n\n\n\n\n\npPoints\n\n\n\n\ndescription\n\n    Alias for pScatter\n\n\n\n\n\n\n\n\npHisto\n\n\n\n\n\n\ndescription\n\n    Use ggplot2 geom_histogram to generate histograms\n\n\n\n\n\n\ninfile\n  \n\n\n\n\ninfile:file\n: The input data file  \n\n\n\n\n\n\n\n\noutfile\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n : Whether the input file has colnames. Default: True  \n\n\nrnames\n : Whether the input file has rownames. Default: False  \n\n\nx\n      : The x aes. Default: 1 (corresponding to colnames)  \n\n\nhelper\n : Some helper codes to generate \nparams\n and \nggs\n  \n\n\ndevpars\n: The device parameters. Default: \nBox(res = 300, height = 2000, width = 2000)\n  \n\n\nparams\n : The extra params for \ngeom_point\n  \n\n\nggs\n    : The extra ggplot elements.  \n\n\n\n\n\n\n\n\n\n\n\n\npFreqpoly\n\n\n\n\n\n\ndescription\n\n    Use ggplot2 geom_freqpoly to generate frequency polygon plot.\n\n\n\n\n\n\ninfile\n  \n\n\n\n\ninfile:file\n: The input data file  \n\n\n\n\n\n\n\n\noutfile\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n : Whether the input file has colnames. Default: True  \n\n\nrnames\n : Whether the input file has rownames. Default: False  \n\n\nx\n      : The x aes. Default: 1 (corresponding to colnames)  \n\n\nhelper\n : Some helper codes to generate \nparams\n and \nggs\n  \n\n\ndevpars\n: The device parameters. Default: \nBox(res = 300, height = 2000, width = 2000)\n  \n\n\nparams\n : The extra params for \ngeom_point\n  \n\n\nggs\n    : The extra ggplot elements.  \n\n\n\n\n\n\n\n\n\n\n\n\npBoxplot\n\n\n\n\n\n\ndescription\n\n    Generate box plot\n\n\n\n\n\n\ninput\n  \n\n\n\n\ndatafile:file\n: The data file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutpng:file\n: The output figure  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninopts\n : Input options to read the input file  \n\n\ncnames\n :   Whether the input file has header. Default: \nTrue\n\n\nrnames\n :   Whether the input file has row names. Default: \nFalse\n\n\ndelimit\n:   The seperator. Defualt: \n\\\\t\n\n\n\n\n\n\nx\n      : The \nind\n (index) column. Only for \nargs.stacked = True\n. Default: \n2\n  \n\n\ny\n      : The \nvalues\n column. Only for \nargs.stacked = True\n. Default: \n1\n  \n\n\nhelper\n : Some raw codes to help to construct the matrix and arguments.  \n\n\nstacked\n: Whether the input file is stacked  \n\n\nStacked file looks like:\n  \nvalues\tind\n1.1\tcol1\n1.2\tcol1\n...\n.8\tcol2\n.9\tcol2\n...\n3.2\tcol3\n...\n\n\n\nUnstacked file looks like:\n  \ncol1\tcol2\tcol3\n1.1\t.8\t3.2\n1.2\t.9\t2.2\n\n\n\n\n\n\n\nparams\n: Other parameters for \nboxplot\n, default: \n\"\"\n  \n\n\nggs\n   : Extra ggplot2 statements  \n\n\n\n\n\n\n\n\n\n\n\n\npHeatmap\n\n\n\n\n\n\ndescription\n\n    Plot heatmaps.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input matrix file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The heatmap  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nggs\n: The ggplot items for heatmap  \n\n\ndevpars\n: The parameters for device. Default: \n{'res': 300, 'height': 2000, 'width': 2000}\n  \n\n\ndendro\n: The parameters for control of the dendrogram. Default: \n{'dendro': True}\n  \n\n\ndendro\n: \nTrue\n: plot dendros for both rows and cols; \ncol\n: only plot dendro for cols; \nrow\n: only plot dendro for rows\n\n\nrows\n: The rownames to subset the rows and control the order of rows. Must a list. Only works when not plotting dendro for rows.\n\n\ncols\n: The colnames to subset the cols and control the order of cols. Must a list. Only works when not plotting dendro for cols.\n\n\n\n\n\n\nheader\n: The input file has header? Default: True  \n\n\nrownames\n: The input file has rownames? Default: 1  \n\n\nrows\n: Row selector  \n\n\nall\n: All rows\n\n\ntop:N\n: Top N rows (original data ordered in descending order). N defaults to 100\n\n\nbottom:N\n: Bottom N rows. N defaults to 100\n\n\nboth:N\n: Top N rows and bottom N rows. N defaults to 50\n\n\nrandom:N\n: Random N rows. N defaults to 50\n\n\nrandom-both:N\n: Random N rows from top part and N rows from bottom part. N defaults to 50\n\n\n\n\n\n\ncols\n: Col selector (see \nrows\n).  \n\n\n\n\n\n\n\n\n\n\n\n\npScatterCompare\n\n\n\n\n\n\ndescription\n\n    Plot scatter plot to compare values of first 2 columns of input data\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file containing a matrix with at least 2 columns  \n\n\nOther columns are groups used to group the scatter points\n\n\nData must be normalized to [0, 1]\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output plot  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nggs\n: Extra expressions for ggplot. Note if geom_point is included, original geom_point will be ignored.  \n\n\ndevpars\n: The parameters for plot device. Default: \n{'res': 300, 'height': 2000, 'width': 2000}\n  \n\n\nrownames\n: Whether the input file has row names. Default: True  \n\n\nregr\n: Whether draw the regression line. Default: False  \n\n\ncorr\n: The method to calculate the correlation. Default: \npearson\n  \n\n\nCould be: \npearson\n, \nspearman\n or \nkendall\n\n\nIf it's neither of the three, no correlations will show.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npROC\n\n\n\n\n\n\ndescription\n\n    Generate ROC curves and output AUC.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input matrix file.  \n\n\nCol1: rownames if args.rnames is True else label (0, 1 class)\n\n\nCol2: prediction values from model1\n\n\n...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npVenn\n\n\n\n\n\n\ndescription\n\n    Venn/UpsetR plots.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input matrix  \n\n\nformat:\n\n\tcategory1\tcategory2\tcategory3\n[e1]\t0\t1\t1\n[e2]\t0\t0\t1\n...\n[eN]\t1\t0\t0\n\n\nrownames are not necessary but colnames are.\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The plot  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n    : Which tools to use. Default: auto (venn, upsetr, auto(n\n=3: venn, otherwise upsetr))  \n\n\nrnames\n  : Whether input file has rownames. Default: False  \n\n\nparams\n  : Other params for \nvenn.diagram\n or \nupset\n. Default: {}  \n\n\ndevpars\n : The parameters for plot device. Default: \n{'res': 300, 'height': 2000, 'width': 2000}\n  \n\n\n\n\n\n\n\n\nrequires\n\n\nr-VennDiagram\n\n    \nr-UpSetR\n\n\n\n\n\n\n\n\n\n\npPie\n\n\n\n\n\n\ndescription\n\n    Plot piechart\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file. Could be either:  \n\n\nDirect numbers of each category.\n\nGroup1\tGroup2\n50\t50\n\n\n\nPresence of each items in the category.\n\n\tGroup1\tGroup2\nItem1\t1\t0\nItem2\t0\t1\n...\n\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the output plot  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nrnames\n : Whether the input file has row names. Default: \nFalse\n  \n\n\nggs\n    : Extra expressions for ggplot.  \n\n\ndevpars\n: The parameters for plot device. Default: \n{'res': 300, 'height': 2000, 'width': 2000}\n  \n\n\n\n\n\n\n\n\n\n\npower\n\n\n\n\npSurvivalPower\n\n\n\n\n\n\ndescription\n\n    Do power analysis for survival analysis.\n    See http://www.sample-size.net/sample-size-survival-analysis/\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file, could be either:  \n\n\ndetailed suvival data with [\npatient\n, ]\ntime\n, \nstatus\n, \nvariable1\n, \nvariable2\n, ...; or\n\n\nratios with \nvariable\n, \nsurvrate1\n, \nsurvrate2\n, \nssratio\n, where \nsurvrate1\n and\n    \nsurvrate2\n are survival rates in group1 and group2, respectively,\n    and \nssratio\n is sample size ratio in group1/group2\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file with columns:  \n\n\nVariable: the variable (including paired groups)\n\n\nAlpha: the alpha value\n\n\nBeta: the beta value (1-power)\n\n\nSSize1: the sample size for group1\n\n\nSSize2: the sample size for group2\n\n\nTotal: the total sample size\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrank\n\n\n\n\npRankProduct\n\n\n\n\n\n\ndescription\n\n    Calculate the rank product of a set of ranks. Refer to \nhere\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\nFormat:\n\n\t\t\tCase1\tCase2\t...\nFeature1\t8.2  \t10.1 \t...\nFeature2\t2.3  \t8.0  \t...\n...\n\n\n\nOr instead of values, you can also have ranks in the input file:\n\n\t\t\tRank1\tRank2\t...\nFeature1\t2    \t1    \t...\nFeature2\t3    \t2    \t...\n...\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file with original ranks, rank products and p-value if required  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninformat\n: The input format of the values. Whether they are real values (value) or ranks (rank). Default: value  \n\n\npval\n: Whether to calculate the p-value or not. Default: True  \n\n\nheader\n: Whether the input file has headers (rownames are required!). Default: True  \n\n\nplot\n: Number of rows to plot. Default: 0 (Don't plot)  \n\n\ncex\n: Font size for plotting. Default: 0.9  \n\n\ncnheight\n: Colname height. Default: 80  \n\n\nrnwidth\n: Rowname width. Default: 50  \n\n\nwidth\n: Width of the png file. Default: 2000  \n\n\nheight\n: height of the png file. Default: 2000  \n\n\n\n\n\n\n\n\n\n\nresource\n\n\n\n\npTxt\n\n\n\n\n\n\ndescription\n\n    Download CSV format files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nin\n: The name of the resource  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncols\n: Select the columns to keep. Default: '' (all cols)  \n\n\nrowfilter\n: Filter rows. For example, to filter out rows not start with 'Chr':  \n\n\n\"lambda x: not x[0].startswith('Chr')\"\n\n\nNote that rowfilter applied before cols filter.\n\n\n\n\n\n\nurls\n: Available resources and their urls.  \n\n\ngz\n: Whether to gzip the output file.  \n\n\n\n\n\n\n\n\nrequires\n\n\ncurl\n\n\n\n\n\n\n\n\nrnaseq\n\n\n\n\npEXPRdir2Matrix\n\n\n\n\n\n\ndescription\n\n    Convert expression files to expression matrix\n    File names will be used as sample names (colnames)\n    Each gene and its expression per line.\n    Suppose each expression file has the same rownames and in the same order.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: the directory containing the expression files, could be gzipped  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the expression matrix file  \n\n\noutdir:dir\n: the directory containing expr file and plots  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npattern\n : The pattern to filter files. Default \n'*'\n  \n\n\nnamefunc\n: Transform filename (no extension) as column name. Default: \"function(fn) fn\"  \n\n\nheader\n  : Whether each expression file contains header. Default: \nFalse\n  \n\n\nexrows\n  : Rows to be excluded, regular expression applied. Default: \n[\"^Sample\", \"^Composite\", \"^__\"]\n  \n\n\nboxplot\n : Whether to plot a boxplot. Default: False  \n\n\nheatmap\n : Whether to plot a heatmap. Default: False  \n\n\nhistplot\n: Whether to plot a histgram. Default: False  \n\n\ndevpars\n : Parameters for png. Default: \n{'res': 300, 'width': 2000, 'height': 2000}\n  \n\n\nboxplotggs\n: The ggplot parameters for boxplot. Default: \n['r:ylab(\"Expression\")']\n  \n\n\nSee ggplot2 documentation.\n\n\n\n\n\n\nheatmapggs\n: The ggplot parameters for heatmap. Default: \n['r:theme(axis.text.y = element_blank())']\n  \n\n\nhistplotggs\n: The ggplot parameters for histgram. Default: \n['r:labs(x = \"Expression\", y = \"# Samples\")']\n  \n\n\n\n\n\n\n\n\n\n\n\n\npBatchEffect\n\n\n\n\n\n\ndescription\n\n    Remove batch effect with sva-combat.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nexpr:file\n: The expression file, generated by pEXPRdir2Matrix  \n\n\nbatch:file\n: The batch file defines samples and batches.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the expression matrix file  \n\n\noutdir:dir\n: the directory containing expr file and plots  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n    : The tool used to remove batch effect. Default \n'combat'\n  \n\n\nhmrows\n  : How many rows to be used to plot heatmap  \n\n\nplot\n: Whether to plot  \n\n\nboxplot\n   : Whether to plot a boxplot. Default: False\n\n\nheatmap\n   : Whether to plot a heatmap. Default: False\n\n\nhistogram\n : Whether to plot a histgram. Default: False\n\n\n\n\n\n\ndevpars\n    : Parameters for png. Default: \n{'res': 300, 'width': 2000, 'height': 2000}\n  \n\n\nggs\n: The ggplot parameters  \n\n\nboxplot\n  : The ggplot parameters for boxplot. Default: \nBox(ylab = {0: \"Log2 Intensity\"})\n\n\nheatmap\n  : The ggplot parameters for heatmap. Default: \nBox(theme = {'axis.text.y': 'r:element_blank()'})\n\n\nhistogram\n: The ggplot parameters for histgram. Default: \nBox(labs = {'x': \"Log2 Intensity\", \"y\": \"Density\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npRawCounts2\n\n\n\n\n\n\ndescription\n\n    Convert raw counts to another unit\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: the expression matrix  \n\n\nrows are genes, columns are samples\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the converted expression matrix  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntranspose\n: transpose the input matrix? default: False  \n\n\nlog2\n: whether to take log2? default: False  \n\n\nunit\n: convert to which unit? default: cpm (or rpkm, tmm)  \n\n\nheader\n: whether input file has header? default: True  \n\n\nrownames\n: the index of the column as rownames. default: 1  \n\n\nglenfile\n: the gene length file, for RPKM  \n\n\nno head, row names are genes, have to be exact the same order and length as the rownames of infile\n\n\n\n\n\n\nboxplot\n : Whether to plot a boxplot. Default: False  \n\n\nheatmap\n : Whether to plot a heatmap. Default: False  \n\n\nhistplot\n: Whether to plot a histgram. Default: False  \n\n\ndevpars\n : Parameters for png. Default: \n{'res': 300, 'width': 2000, 'height': 2000}\n  \n\n\nboxplotggs\n: The ggplot parameters for boxplot. Default: \n['r:ylab(\"Expression\")']\n  \n\n\nSee ggplot2 documentation.\n\n\n\n\n\n\nheatmapggs\n: The ggplot parameters for heatmap. Default: \n['r:theme(axis.text.y = element_blank())']\n  \n\n\nhistplotggs\n: The ggplot parameters for histgram. Default: \n['r:labs(x = \"Expression\", y = \"# Samples\")']\n  \n\n\n\n\n\n\n\n\nrequires\n\n\nedgeR\n if cpm or rpkm is chosen\n    \ncoseq\n if tmm is chosen\n\n\n\n\n\n\n\n\n\n\np2RawCounts\n\n\n\n\n\n\ndescription\n\n    Convert gene expression to raw counts.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The expression matrix file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\noutdir:dir\n: The output directory, may contain the figures.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nunit\n: The unit of input gene expression. Default: fpkm  \n\n\nCould also be rpkm, tpm\n\n\n\n\n\n\nnreads\n     : Total reads approximately. Default: 30, 000, 000  \n\n\nrefgene\n    : The refgene file for gene length.  \n\n\nboxplot\n    : Whether to plot boxplot after transformation. Default: False  \n\n\nheatmap\n    : Whether to plot heatmap after transformation. Default: False  \n\n\nheatmapn\n   : How many genes used to plot heatmap. Default: 500  \n\n\nhistplot\n   : Whether to plot histgram after transformation. Default: False  \n\n\ndevpars\n    : The device parameters for plotting. Default: \n{'res': 300, 'width': 2000, 'height': 2000}\n  \n\n\nboxplotggs\n : The ggplot statement for boxplot.  \n\n\nheatmapggs\n : The ggplot statement for heatmap.  \n\n\nhistplotggs\n: The ggplot statement for histgram.  \n\n\n\n\n\n\n\n\n\n\n\n\npRNAseqDEG\n\n\n\n\n\n\ndescription\n\n    Detect DEGs for RNA-seq data\n\n\n\n\n\n\ninput\n  \n\n\n\n\nefile:file\n: The expression matrix  \n\n\ngfile:file\n: The group information  \n\n\nLike:\n\nSample1\tGroup1\nSample2\tGroup1\nSample3\tGroup1\nSample4\tgroup2\nSample5\tgroup2\nSample6\tgroup2\n\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The DEG list  \n\n\noutdir:file\n: The output directory containing deg list and plots  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n      : the tool used to detect DEGs. Default: 'edger' (deseq2)  \n\n\nfilter\n    : filter out low count records. Default: \n\"1,2\"\n (At least 2 samples have at least 2 reads)  \n\n\nmdsplot\n   : whether to plot the MDS plot, default : True  \n\n\nvolplot\n   : whether to plot the volcano plot, default : True  \n\n\nmaplot\n    : whether to plot MA plots within each group, default : False  \n\n\nheatmap\n   : whether to plot the heatmap using DEGs. Default : False  \n\n\nheatmapn\n  : How many genes to be used for heatmap. If \nheatmapn\n, the number will be \nheatmapn * # DEGs\n. Default: 100  \n\n\nheatmapggs\n: The ggplots options for heatmap. Default : []  \n\n\nmaplotggs\n : The ggplots options for maplot. Default : []  \n\n\nvolplotggs\n: The ggplots options for volplot. Default : []  \n\n\ndevpars\n   : Parameters for png. Default: \n{'res': 300, 'width': 2000, 'height': 2000}\n  \n\n\n\n\n\n\n\n\n\n\n\n\npCoexp\n\n\n\n\ndescription\n\n    Get co-expression of gene pairs in the expression matrix.\n\n\n\n\n\n\nsambam\n\n\n\n\npSam2Bam\n\n\n\n\n\n\ndescription\n\n    Deal with mapped sam/bam files, including sort, markdup, and/or index\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output bam file  \n\n\nidxfile:file\n: The index of the output bam file  \n\n\nIf args.index == False, it'll a link to outfile and should be never used\n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n             : The tool used to do the sort. Default: sambamba (picard|sambamba|biobambam|samtools)  \n\n\nsambamba\n         : The path of the sambamba. Default: sambamba  \n\n\npicard\n           : The path of the picard. Default: picard  \n\n\nbiobambam_bamsort\n: The path of the biobambam's bamsort. Default: bamsort  \n\n\nsamtools\n         : The path of the samtools. Default: samtools  \n\n\nsort\n             : Do sorting? Default: True  \n\n\nIf input is sam, tool is biobambam, this should be True\n\n\nindex\n            : Do indexing? Default: True  \n\n\nmarkdup\n          : Do duplicates marking? Default: False  \n\n\nrmdup\n for samtools will be called\n\n\nrmdup\n            : Do duplicates removing? Default: False  \n\n\ntmpdir\n           : The tmp dir used to store tmp files. Default: \n  \n\n\nsortby\n           : Sort by coordinate or queryname. Default: coordinate  \n\n\nnthread\n          : Default: 1  \n\n\ninformat\n         : The format of input file. Default: \n (sam|bam)  \n\n\nparams\n           : Other parameters for \ntool\n. Defaut: \"\"  \n\n\nmem\n              : The max memory to use. Default: \"16G\"  \n\n\nUnit could be G/g/M/m\n\n\nWill be converted to -Xmx4G, and -Xms will be 1/8 of it\n\n\n\n\n\n\n\n\nrequires\n\n\nsambamba\n if \nargs.tool\n == samtools or reference used but not indexed.\n    \npicard\n\n    \nbiobambam\n\n    \nsamtools\n\n\n\n\n\n\n\n\n\n\npBamMarkdup\n\n\n\n\n\n\ndescription\n\n    Mark/remove duplicates for bam files\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n             : The tool used to do the sort. Default: sambamba (picard|sambamba|biobambam|samtools|bamutil)  \n\n\nsambamba\n         : The path of sambamba. Default: sambamba  \n\n\npicard\n           : The path of picard. Default: picard  \n\n\nbiobambam_bamsort\n: The path of biobambam's bamsort. Default: bamsort  \n\n\nsamtools\n         : The path of samtools. Default: samtools  \n\n\nbamutil\n          : The path of bamutil. Default: bam  \n\n\nrmdup\n            : Do duplicates removing? Default: False  \n\n\nSamtools will anyway remove the duplicates\n\n\ntmpdir\n           : The tmp dir used to store tmp files. Default: \n  \n\n\nnthread\n          : Default: 1  \n\n\nNot available for samtools and picard\n\n\nparams\n           : Other parameters for \ntool\n. Defaut: \"\"  \n\n\nmem\n              : The max memory to use. Default: \"16G\"  \n\n\nUnit could be G/g/M/m\n\n\nWill be converted to -Xmx4G, and -Xms will be 1/8 of it\n\n\n\n\n\n\n\n\nrequires\n\n\nsambamba\n\n    \npicard\n\n    \nbiobambam\n\n    \nsamtools\n\n    \nbamutil\n\n\n\n\n\n\n\n\n\n\npBamRecal\n\n\n\n\n\n\ndescription\n\n    Recalibrate a bam file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n                         : The tool used to recalibrate the bam file. Default: \ngatk\n (gatk|bamutil)  \n\n\ngatk\n                         : The path of gatk, including java path. Default: \ngatk\n  \n\n\nsamtools\n                     : The path of samtools. Default: \nsamtools\n  \n\n\nbamutil\n                      : The path of bamutil. Default: \nbam\n  \n\n\npicard\n                       : The path of picard. Default: \npicard\n  \n\n\nparamsRealignerTargetCreator\n : Other parameters for \ngatk RealignerTargetCreator\n. Defaut: \"\"  \n\n\nparamsIndelRealigner\n         : Other parameters for \ngatk IndelRealigner\n. Defaut: \"\"  \n\n\nparamsBaseRecalibrator\n       : Other parameters for \ngatk BaseRecalibrator\n. Defaut: \"\"  \n\n\nparamsPrintReads\n             : Other parameters for \ngatk PrintReads\n. Defaut: \"\"  \n\n\nparams\n                       : Other parameters for \nbam recab\n. Default: \"\"  \n\n\nmem\n                          : The max memory to use. Default: \"32G\"  \n\n\nknownSites\n                   : The known polymorphic sites to mask out. Default: \"\" (Required for GATK)  \n\n\nref\n                          : The reference file. Required.  \n\n\nWill be converted to -Xmx4G, and -Xms will be 1/8 of it\n\n\n\n\n\n\n\n\nrequires\n\n\ngatk\n\n    \nsamtools\n if \nargs.ref\n is not indexed, or bamutil is used for bam index file generation.\n    \npicard\n if \nargs.ref is not dicted.\n\n\n\n\n\n\n\n\n\n\npBamReadGroup\n\n\n\n\n\n\ndescription\n\n    Add or replace read groups of a bam file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n                         : The tool used. Default: \npicard\n (picard|bamutil)  \n\n\npicard\n                       : The path of picard. Default: \npicard\n  \n\n\nbamutil\n                      : The path of bamutil. Default: \nbam\n  \n\n\nrg\n                           : The read group. Default: {'id': '', 'pl': 'Illumina', 'pu': 'unit1', 'lb': 'lib1', 'sm': ''}  \n\n\nid\n will be parsed from filename with \"\nLX\n\" in it if not given\n\n\nsm\n will be parsed from filename\n\n\nparams\n                       : Other parameters for \ntool\n. Defaut: \"\"  \n\n\nmem\n                          : The max memory to use. Default: \"4G\"  \n\n\nWill be converted to -Xmx4G, and -Xms will be 1/8 of it\n\n\ntmpdir\n                       : The temporary directory. Default: \n  \n\n\n\n\n\n\n\n\nrequires\n\n\ngatk\n\n    \nsamtools\n if \nargs.ref\n is not indexed.\n    \npicard\n if \nargs.ref is not dicted.\n\n\n\n\n\n\n\n\n\n\npBamReorder\n\n\n\n\n\n\ndescription\n\n    Reorder a sam/bam file by a given reference file using \npicard ReorderSam\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The sam/bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\npicard\n                       : The path of picard. Default: \npicard\n  \n\n\nref\n                          : The reference file. Required  \n\n\nparams\n                       : Other parameters for \npicard ReorderSam\n. Defaut: \"\"  \n\n\nmem\n                          : The max memory to use. Default: \"4G\"  \n\n\nWill be converted to -Xmx4G, and -Xms will be 1/8 of it\n\n\ntmpdir\n                       : The temporary directory. Default: \n  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n\n\n\n\n\n\n\n\n\npBamMerge\n\n\n\n\n\n\ndescription\n\n    Merges multiple SAM and/or BAM files (must be sorted by coordinate) into a single file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfiles:file\n: Input sam/bam files to be merged  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The merged bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n     : The tool used to merge. Default: bamutil (picard|samtools|sambamba)  \n\n\npicard\n   : The path of picard. Default: \npicard\n  \n\n\nbamutil\n  : The path of bamutil. Default: \nbam\n  \n\n\nsamtools\n : The path of samtools. Default: \nsamtools\n  \n\n\nsambamba\n : The path of sambamba. Default: \nsambamba\n  \n\n\nparams\n   : Other parameters for \ntool\n. Defaut: \"\"  \n\n\nmem\n      : The max memory to use. Default: \"4G\"  \n\n\nWill be converted to -Xmx4G, and -Xms will be 1/8 of it, just for picard\n\n\ntmpdir\n   : The temporary directory. Default: \n  \n\n\nnthread\n  : # threads to use. Default: 1  \n\n\nFor picard, if nthread\n1, USE_THREADING=true, otherwise USE_THREADING=false\n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n\n\n\n\n\n\n\n\n\npBam2Gmut\n\n\n\n\n\n\ndescription\n\n    Call germline (snps and indels) from a call-ready bam file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The vcf file containing the mutations  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to call mutations. Default: gatk (vardict, snvsniffer, platypus, strelka)  \n\n\ngatk\n: The path of gatk. Default: gatk  \n\n\nvardict\n: The path of vardict. Default: vardict  \n\n\nsnvsniffer\n: The path of snvsniffer. Default: SNVSniffer  \n\n\nsamtools\n: The path of samtools. Default: samtools (used to generate reference index)  \n\n\nplatypus\n: The path of platypus. Default: platypus  \n\n\nstrelka\n: The path of strelka. Default: configureStrelkaGermlineWorkflow.py  \n\n\nconfigParams\n: The params for \nstrelka\n configuration. Default: \"\"  \n\n\npicard\n: The path of picard. Default: picard  \n\n\nmem\n: The memory to be used. Default: 32G  \n\n\nwill be converted to -Xms4G -Xmx32G for java programs\n\n\nref\n: The reference file. Required.  \n\n\ngz\n: Gzip output file? Default: False  \n\n\ntmpdir\n: The temporary directory. Default: \n  \n\n\nparams\n: Other params for \ntool\n. Default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\ngatk\n\n    \nsamtools\n if \nargs.ref\n is not indexed.\n    \npicard\n if \nargs.ref is not dicted.\n\n    \nvardict\n\n    \nsnvsniffer\n\n    \nplatypus\n\n    \nstrelka@2.7.1+\n\n\n\n\n\n\n\n\n\n\npBamPair2Smut\n\n\n\n\n\n\ndescription\n\n    Call somatic mutations from tumor-normal bam pair.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ntumor:file\n: The tumor bam file  \n\n\nnormal:file\n: The normal bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The vcf file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to call mutations. Default: gatk (somaticsniper, strelka, snvsniffer, virmid, varidct)  \n\n\ngatk\n: The path to gatk. Default: gatk  \n\n\nsomaticsniper\n: The path to gatk. Default: bam-somaticsniper  \n\n\nstrelka\n: The path to gatk. Default: configureStrelkaSomaticWorkflow.py  \n\n\nsnvsniffer\n: The path to gatk. Default: SNVSniffer  \n\n\nvirmid\n: The path to gatk. Default: virmid  \n\n\nvardict\n: The path to gatk. Default: vardict  \n\n\nsamtools\n: The path to gatk. Default: samtools  \n\n\npicard\n: The path to gatk. Default: picard  \n\n\nconfigParams\n: The configuration parameters for \nconfigureStrelkaSomaticWorkflow.py\n. Default: \n{}\n  \n\n\nparams\n: The parameters for main programs. Default: \n{}\n  \n\n\nmeme\n: The memory. Default: 24G  \n\n\nref\n: The reference genom. Default: \nparams.ref.value\n  \n\n\ngz\n: Whether gzip the output vcf file. Default: False  \n\n\nnthread\n: The number of threads to use. Default: 1  \n\n\ntmpdir\n: The temporary directory. Default: \nparams.tmpdir.value\n  \n\n\n\n\n\n\n\n\nrequires\n\n\ngatk\n\n    \nsamtools\n if \nargs.ref\n is not indexed.\n    \npicard\n if \nargs.ref is not dicted.\n\n    \nvardict\n\n    \nsnvsniffer\n\n    \nplatypus\n\n    \nstrelka@2.7.1+\n\n\n\n\n\n\n\n\n\n\npBam2Cnv\n\n\n\n\n\n\ndescription\n\n    Detect copy number variation from bam files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninput:file\n: The bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output vcf file  \n\n\noutdir\n: The output directory containing other result files  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngz\n                    : Whether to gzip the output vcf file. Default: False  \n\n\ntool\n                  : The tool used to call cnv. Default: 'cnvkit'  \n\n\ncnvnator\n              : The path of cnvnator. Default: 'cnvnator'  \n\n\ncnvnator2vcf\n          : The path of cnvnator2VCF. Default: 'cnvnator2VCF.pl'  \n\n\ncnvkit\n                : The path of cnvkit. Default: 'cnvkit.py'  \n\n\nwandy\n                 : Tha path of Wandy. Default: 'Wandy'. A \ntool.info\n file should be with the executable file.  \n\n\nref\n                   : The reference file. Required by cnvkit to generate access file. Default: ''  \n\n\ncnvkitAccessParams\n    : The params for cnvkit access command. Default: '-s 5000'  \n\n\ncnvkitTargetParams\n    : The params for cnvkit target command. Default: '--split --short-names'  \n\n\ncnvkitCoverageParams\n  : The params for cnvkit coverage command. Default: ''  \n\n\ncnvkitReferenceParams\n : The params for cnvkit reference command. Default: '--no-edge'  \n\n\ncnvkitFixParams\n       : The params for cnvkit fix command. Default: '--no-edge'  \n\n\ncnvkitSegmentParams\n   : The params for cnvkit segment command. Default: ''  \n\n\ncnvkitCallParams\n      : The params for cnvkit call command. Default: ''  \n\n\ncnvkitPlotParams\n      : The params for cnvkit plot command. Default: ''  \n\n\ncnvkitBreaksParams\n    : The params for cnvkit breaks command. Default: ''  \n\n\ncnvkitGainlossParams\n  : The params for cnvkit gainloss command. Default: ''  \n\n\ncnvkitMetricsParams\n   : The params for cnvkit metrics command. Default: ''  \n\n\ncnvkitSegmetricsParams\n: The params for cnvkit segmetrics command. Default: '--iqr'  \n\n\ncnvkitExportParams\n    : The params for cnvkit export command. Default: ''  \n\n\ncnvkitScatterParams\n   : The params for cnvkit scatter command. Default: [''] # multiple scatter plots  \n\n\ncnvkitHeatmapParams\n   : The params for cnvkit heatmap command. Default: [''] # multiple heatmap plots  \n\n\ncnvkitDiagramParams\n   : The params for cnvkit diagram command. Default: ''  \n\n\ncnvkitReport\n          : Generate cnvkit reports? Default: True  \n\n\ncnvkitPlot\n            : Generate cnvkit plots? Default: True  \n\n\ncnvnatorBinsize\n       : Bin size for cnvnator. Default: 100  \n\n\ncnvnatorGenome\n        : Genome for cnvnator. Default: 'hg19'. (NCBI36, hg18, GRCh37, hg19)  \n\n\nparams\n                : The params for \ntool\n. Default: '-t 1' # wandy 1:hg19 solid cell/blood, 2:hg19 cell free/plamsa, 3:hg38 solid cell/blood, 4:hg38 cell free/plamsa  \n\n\nmem\n                   : The memory used. Default: '20G' # only for wandy  \n\n\nnthread\n               : The # threads to use. Default: 1     # only for cnvkit  \n\n\n\n\n\n\n\n\nrequires\n\n\ncnvkit\n\n    \ncnvnator\n\n\n\n\nwandy\n: Inside cnv caller  \n\n\n\n\n\n\n\n\n\n\n\n\npBamStats\n\n\n\n\n\n\ndescription\n\n    Get read depth from bam files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output statistic file  \n\n\noutdir:dir\n: The directory containing result files and figures.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to do the job. Default: bamstats  \n\n\nbamstats\n: The path to bamstats. Default: bamstats  \n\n\nparams\n: Other params to main program. Default: \n{}\n  \n\n\nmem\n: The memory to be used. Default: 16G  \n\n\nplot\n: Whether plot the result. Default: True  \n\n\n\n\n\n\n\n\n\n\n\n\npBam2Fastq\n\n\n\n\n\n\ndescription\n\n    Convert sam/bam files to pair-end fastq files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The sam/bam file.  \n\n\nSam files only available for biobambam, picard\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\nfqfile1:file\n: The 1st match of paired reads  \n\n\nfqfile2:file\n: The 2nd match of paired reads  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n     : The tool to use. Default: biobambam (bedtools, samtools, picard)  \n\n\nbiobambam\n: The path of bamtofastq of biobambam. Default: bamtofastq  \n\n\nbedtools\n : The path of bedtools. Default: bedtools  \n\n\nsamtools\n : The path of samtools. Default: samtools  \n\n\npicard\n   : The path of picard. Default: picard  \n\n\nmem\n      : The memory to be used by picard. Default: 8G  \n\n\ngz\n       : Whether gzip the output files. Default: True  \n\n\nparams\n: : Other params for \ntool\n. Default: ''  \n\n\ntmpdir\n   : The tmpdir. Default: \n__import__('tempfile').gettempdir()\n  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n    \nbiobambam\n\n    \nsamtools\n\n    \nbedtools\n\n\n\n\n\n\n\n\n\n\npBam2FastqSE\n\n\n\n\n\n\ndescription\n\n    Convert sam/bam files to single-end fastq files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The sam/bam file.  \n\n\nSam files only available for biobambam, picard\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\nfqfile:file\n: The fastq file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n     : The tool to use. Default: biobambam (bedtools, samtools, picard)  \n\n\nbiobambam\n: The path of bamtofastq of biobambam. Default: bamtofastq  \n\n\nbedtools\n : The path of bedtools. Default: bedtools  \n\n\nsamtools\n : The path of samtools. Default: samtools  \n\n\npicard\n   : The path of picard. Default: picard  \n\n\nmem\n      : The memory to be used by picard. Default: 8G  \n\n\ngz\n       : Whether gzip the output files. Default: True  \n\n\nparams\n: : Other params for \ntool\n. Default: ''  \n\n\ntmpdir\n   : The tmpdir. Default: \n__import__('tempfile').gettempdir()\n  \n\n\n\n\n\n\n\n\nrequires\n\n\npicard\n\n    \nbiobambam\n\n    \nsamtools\n\n    \nbedtools\n\n\n\n\n\n\n\n\n\n\npBam2Counts\n\n\n\n\n\n\ndescription\n\n    Extract read counts from RNA-seq bam files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input bam files  \n\n\n\n\n\n\n\n\noutfile\n  \n\n\n\n\noutfile:file\n: The count file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to extract counts. Default: ht-seq  \n\n\nhtseq\n: The path of htseq-count.  \n\n\nparams\n: Other params for main program.  \n\n\nrefgene\n: The reference gene in GTF format.  \n\n\n\n\n\n\n\n\nrequires\n\n\nhtseq\n\n\n\n\n\n\n\n\nseq\n\n\n\n\npConsvPerm\n\n\n\n\n\n\ndescription\n\n    Generate a null distribution of conservation scores.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nseed\n: The seed to generate the random regions. Default: None  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: A file with mean conservation scores sorted descendingly.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nlen\n: The length of a random region. Default: 50  \n\n\nnperm\n: Number of permutations. Default: 1000  \n\n\ngsize\n: The chrom size file.  \n\n\nbedtools\n: The path of bedtools.  \n\n\nbwtool\n: The path of bwtool.  \n\n\nconsvdir\n: The directory containing bigwig files of conservation scores  \n\n\nThe bigwig file should start with chr name: chrN.*\n\n\n\n\n\n\n\n\n\n\n\n\nrequires\n\n\nbwtool\n\n    \nbedtools\n\n\n\n\n\n\n\n\n\n\npConsv\n\n\n\n\n\n\ndescription\n\n    Get the conservation scores of regions.\n    It uses wigFix to find the conservation scores.\n    But first you have to convert those wigFix.gz files to bigWig files using ucsc-wigToBigWig\n\n\n\n\n\n\ninput\n  \n\n\n\n\nbedfile:file\n: The bedfile with regions in the same chromosome  \n\n\npermfile:file\n: The permutaiton file generated by \npConsvPerm\n, used to calculate p-values  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nconsvdir\n: The bigwig directory, the bigwig files must be named as \"chrN.*.bw\"  \n\n\nFor example: \nchr1.phyloP30way.bw\n\n\n\n\n\n\nbwtool\n: The path of bwtool executable. Default: \nbwtool\n  \n\n\nbedtools\n: The path of bedtools executable. Default: \nbedtools\n  \n\n\npval\n: Whether calculate pvalue of each region. Default: False  \n\n\nIn this case, the \nin.permfile\n can be ignored.\n\n\n\n\n\n\n\n\n\n\n\n\nrequires\n\n\nbwtool\n\n    \nbedtools\n\n\n\n\n\n\n\n\n\n\npPromoters\n\n\n\n\n\n\ndescription\n\n    Get the promoter regions in bed format of a gene list give in infile.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: the gene list file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the bed file containing the promoter region  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nup\n: the upstream to the tss, default: 2000  \n\n\ndown\n: the downstream to the tss, default: 2000  \n\n\ngenome\n: the genome, default: hg19  \n\n\n\n\n\n\n\n\nrequire\n\n\npython-mygene\n\n\n\n\n\n\n\n\nsnp\n\n\n\n\npSnp2Bedx\n\n\n\n\n\n\ndescription\n\n    Find coordinates for SNPs in BEDX format.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nsnpfile:file\n: the snp file, each snp per line  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the result file, columns are:  \n\n\nchrom, start(0-based), end, name, score, strand, ref, allele\n\n\n\n\n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngenome\n: default: hg19  \n\n\nsnpver\n: default: snp147  \n\n\nnotfound\n: What to do if the snp is not found. Default: skip  \n\n\ninmeta\n: The metadata for input file to determine which column is rsID  \n\n\nxcols\n: The extra columns to extract and output to extra columns in output file.  \n\n\nindem\n: The input delimit. Default: '\\t'  \n\n\nincom\n: The input comment. Default: '#'  \n\n\nskip\n: The lines to skip for input file. Default: 0  \n\n\n\n\n\n\n\n\nrequires\n\n\npython-cruzdb\n\n\n\n\n\n\n\n\n\n\npSnp2Avinput\n\n\n\n\n\n\ndescription\n\n    Convert SNP list to avinput to ANNOVAR.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nsnpfile:file\n: the snp file, each snp per line  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the result avinput file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngenome\n: default: hg19  \n\n\nsnpver\n: default: snp147  \n\n\n\n\n\n\n\n\nrequires\n\n\npython-cruzdb\n\n\n\n\n\n\n\n\nsnparray\n\n\n\n\npGistic\n\n\n\n\n\n\ndescription\n\n    Runing GISTIC to get CNV results.\n    see: ftp://ftp.broadinstitute.org/pub/GISTIC2.0/GISTICDocumentation_standalone.htm\n\n\n\n\n\n\ninput\n  \n\n\n\n\nsegfile:file\n: Segmentation File  \n\n\nmkfile:file\n : Markers File  \n\n\nalfile:file\n : Array List File  \n\n\ncnvfile:file\n: CNV File  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\nAll Lesions File (all_lesions.conf_XX.txt, where XX is the confidence level)\n\n\nAmplification Genes File (amp_genes.conf_XX.txt, where XX is the confidence level)\n\n\nDeletion Genes File (del_genes.conf_XX.txt, where XX is the confidence level)\n\n\nGistic Scores File (scores.gistic)\n\n\nSegmented Copy Number (raw_copy_number.pdf)\n\n\n\n\n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ngistic\n: The path to gistic.  \n\n\ngenome\n: The genome used to select refgene file from refgenefiles.  \n\n\nmcr\n: The mcr path  \n\n\nparams\n: Other params for gistic  \n\n\n\n\n\n\n\n\n\n\n\n\npSNP6Genotype\n\n\n\n\n\n\ndescription\n\n    Call genotypes from GenomeWideSNP_6 CEL file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ncelfile:file\n: the CEL file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the outfile containing probe name and genotypes  \n\n\nformat: \nProbe name\n\\t\ngenotype\n\n\ngenotype\n = 0: AA, 1: AB, 2: BB\n\n\n\n\n\n\n\n\nrequires\n\n\nbioconductor-crlmm\n\n\n\n\n\n\n\n\n\n\npGenoToAvInput\n\n\n\n\n\n\ndescription\n\n    Convert the genotype called by pSNP6Genotype to \nANNOVAR input file\n using dbSNP identifiers. \n\n\n\n\n\n\ninput\n  \n\n\n\n\ngenofile:file\n: the genofile generated by pSNP6Genotype, must be sorted by probe names  \n\n\nannofile:flie\n: the annotation file downloaded from http://www.affymetrix.com/support/technical/annotationfilesmain.affx  \n\n\nCould be in .gz format\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the avinput file  \n\n\n\n\n\n\n\n\nrequires\n\n\npython-read2\n\n\n\n\n\n\n\n\nsql\n\n\n\n\npCreateTable\n\n\n\n\n\n\ndescription\n\n    Create tables in the database\n\n\n\n\n\n\ninput\n  \n\n\n\n\ndsn\n: The dsn to connect to the database  \n\n\ncurrently support \nsqlite:file=...\n\n\n\n\n\n\nschema:file\n: The schema file  \n\n\ncould be a pure schema file:\n\nField\tType\tStatement\nID\tINT\tPRIMARY KEY\n...\n\n\n\nor a data file with header\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\ndsn\n: The dsn  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nintype\n: The input file schema file or a data file. Default: \nschema\n  \n\n\ndrop\n: Force creating the table (drop the pre-existing table)  \n\n\ndelimit\n: The delimit of input file. Default: \n\\\\t\n  \n\n\n\n\n\n\n\n\n\n\n\n\npImportData\n\n\n\n\n\n\ndescription\n\n    Create tables and import the data\n\n\n\n\n\n\ninput\n  \n\n\n\n\ndsn\n: The dsn to connect to the database  \n\n\ncurrently support \nsqlite:file=...\n\n\n\n\n\n\ndatafile:file\n: The schema file  \n\n\nmust have header\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\ndsn\n: The dsn  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ndelimit\n: The delimit of input file. Default: \n\\\\t\n  \n\n\n\n\n\n\n\n\n\n\n\n\npUpdateTable\n\n\n\n\n\n\ndescription\n\n    Update table using sql.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ndsn\n: The dsn to connect to the database  \n\n\ncurrently support \nsqlite:file=...\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\ndsn\n: The dsn  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nsql\n: The sql to update the table (list)  \n\n\n\n\n\n\n\n\n\n\n\n\npSelectTable\n\n\n\n\n\n\ndescription\n\n    Select data from table and dump it.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ndsn\n: The dsn to connect to the database  \n\n\ncurrently support \nsqlite:file=...\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The dumped file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nsql\n: The sql to select data from the table (list)  \n\n\n\n\n\n\n\n\n\n\nstats\n\n\n\n\npMetaPval\n\n\n\n\n\n\ndescription\n\n    Combine p-values in the files from input directory\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:dir\n: The directory containing the input files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file containing the meta-pvalues  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nargs.pattern\n: The pattern used to filter the input files. Default: '*'  \n\n\nargs.header\n: Whether the input files contains a header. Default: True  \n\n\nCould be a list to specify it for each file.\n\n\nThe order should be concordant with the file names\n\n\n\n\n\n\nargs.pcol\n: Which column is the p-value. Default: -1 (last column)  \n\n\nargs.poutonly\n: Only output pvalues. Default: False (output all possible information)  \n\n\nargs.outheader\n: Whether output the header. Default: True  \n\n\nargs.method\n: The method used to calculate the meta-pvalue. Default: sumlog (Fisher's method)  \n\n\nOther available methods: logitp, sumz, votep, sump, meanp and wilkinsonp\n\n\nSee: https://www.rdocumentation.org/packages/metap/versions/0.8\n\n\n\n\n\n\n\n\n\n\n\n\nrequires\n\n\nr-matep\n\n\n\n\n\n\n\n\n\n\npMetaPval1\n\n\n\n\n\n\ndescription\n\n    Combine p-values in a single file by rows.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file containing the meta-pvalues  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nargs.header\n: Whether the input files contains a header. Default: True  \n\n\nargs.pcol\n: Which column is the p-value. Default: -1 (last column)  \n\n\nargs.poutonly\n: Only output pvalues. Default: False (output all possible information)  \n\n\nargs.outheader\n: Whether output the header. Default: True  \n\n\nargs.method\n: The method used to calculate the meta-pvalue. Default: sumlog (Fisher's method)  \n\n\nOther available methods: logitp, sumz, votep, sump, meanp and wilkinsonp\n\n\nSee: https://www.rdocumentation.org/packages/metap/versions/0.8\n\n\n\n\n\n\n\n\n\n\n\n\nrequires\n\n\nr-matep\n\n\n\n\n\n\n\n\n\n\npSurvival\n\n\n\n\n\n\ndescription\n\n    Survival analysis\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file (header is required).  \n\n\ncol1: rownames if args.inopts.rnames = True\n\n\ncol2: the survival time\n\n\ncol3: the status. 0/1 for alive/dead or 1/2 for alive dead\n\n\ncol4: var1.\n\n\n... other variables\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The outfile containing the pvalues  \n\n\noutdir:dir\n  : The output directory containing the pval files and plots  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninunit\n    : The time unit in input file. Default: days  \n\n\noutunit\n   : The output unit for plots. Default: days  \n\n\nnthread\n   : Number of threads used to perform analysis for groups. Default: 1  \n\n\ninopts\n    : The options for input file  \n\n\nrnames\n: Whether input file has row names. Default: True\n\n\n\n\n\n\ncombine\n   : Whether combine groups in the same plot. Default: True  \n\n\ndevpars\n   : The device parameters for png. Default: \n{res:300, height:2000, width:2000}\n  \n\n\nThe height and width are for each survival plot. If args.combine is True, the width and height will be multiplied by \nmax(arrange.ncol, arrange.nrow)\n\n\n\n\n\n\ncovfile\n   : The covariant file. Require rownames in both this file and input file.  \n\n\nngroups\n   : Number of curves to plot (the continuous number will divided into \nngroups\n groups.  \n\n\nplot\n      : The params for plot.  \n\n\nparams\n : The params for \nggsurvplot\n. Default: \nBox({'risk.table': True, 'conf.int': True, 'font.legend': 13, 'pval': '{method}\\np = {pval}'})\n\n\nYou may do \nylim.min\n to set the min ylim. Or you can set it as 'auto'. Default: 0. \n\n\n\n\n\n\narrange\n: How to arrange multiple survival plots in one if \nargs.combine = True\n.\n\n\nnrow\n: The number of rows. Default: 1\n\n\nncol\n: The number of cols. Default: 1\n\n\n\n\n\n\n\n\n\n\nggs\n       : Extra ggplot2 elements for main plot. \nggs.table\n is for the risk table.  \n\n\npval\n      : The method to calculate the pvalue shown on the plot. Default: True (logrank)  \n\n\nCould also be \nwaldtest\n, \nlikeratio\n (Likelihoold ratio test)\n\n\n\n\n\n\nmethod\n    : The method to do survival analysis.   \n\n\n\n\n\n\n\n\nrequires\n\n\nr-survival\n\n    \nr-survminer\n\n\n\n\n\n\n\n\n\n\npChiSquare\n\n\n\n\n\n\ndescription\n\n    Do chi-square test.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n : The output file containing Xsquare, df, pval and method  \n\n\nobsvfile:file\n: The observation matrix  \n\n\nexptfile:file\n: The expectation matrix  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nintype\n: The type of the input file:  \n\n\ncount\n (default): The contingency table\n\n#         | Disease | Healthy |\n# --------+---------+---------+\n#   mut   |   40    |   12    |\n# non-mut |   23    |   98    |\n# --------+---------+---------+\n\n\n\nraw\n: The raw values:\n\n# Contingency table rows: Mut, Non\n# Contingency table cols: Disease, Healthy\n#\n#         | S1 | S2 | ... | Sn |\n# --------+----+----+-----+----+\n# Disease | 1  | 0  | ... | 1  |\n# Healthy | 0  | 1  | ... | 0  |\n# --------+----+----+-----+----+\n# Mut     | 1  | 0  | ... | 1  |\n# Non     | 0  | 1  | ... | 0  |\n\n\n\n\n\n\n\nctcols\n: The colnames of contingency table if input file is raw values  \n\n\nYou may also specify them in the head of the input file\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npFisherExact\n\n\n\n\n\n\ndescription\n\n    Do fisher exact test.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n : The output file containing confInt1, confInt2, oddsRatio, pval, alternative and method.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nintype\n: The type of the input file:  \n\n\ncount\n (default): The contingency table\n\n#         | Disease | Healthy |\n# --------+---------+---------+\n#   mut   |   40    |   12    |\n# non-mut |   23    |   98    |\n# --------+---------+---------+\n\n\n\nraw\n: The raw values:\n\n# Contingency table rows: Mut, Non\n# Contingency table cols: Disease, Healthy\n#\n#         | S1 | S2 | ... | Sn |\n# --------+----+----+-----+----+\n# Disease | 1  | 0  | ... | 1  |\n# Healthy | 0  | 1  | ... | 0  |\n# --------+----+----+-----+----+\n# Mut     | 1  | 0  | ... | 1  |\n# Non     | 0  | 1  | ... | 0  |\n\n\n\n\n\n\n\nctcols\n: The colnames of contingency table if input file is raw values  \n\n\nYou may also specify them in the head of the input file\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npPWFisherExact\n\n\n\n\n\n\ndescription\n\n    Do pair-wise fisher exact test.\n    Commonly used for co-occurrence/mutual-exclusivity analysis.\n    P-value indicates if the pairs are significantly co-occurred or mutually exclusive.\n    Co-occurrence: Odds ratio \n 1\n    Mutual-exclusivity: Odds ratio \n 1\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n : The output file containing confInt1, confInt2, oddsRatio, pval, qval, alternative and method.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nintype\n: The type of the input file:  \n\n\npairs\n: The contingency table\n\n#\n# A+\tB+\t4\n# A-\tB-\t175\n# A+\tB-\t12\n# A-\tB+\t1\n#\n\n\n\nraw\n (default): The raw values:\n\n#\n#         | S1 | S2 | ... | Sn |\n# --------+----+----+-----+----+\n# A       | 1  | 0  | ... | 1  |\n# B       | 0  | 1  | ... | 0  |\n# ...     |           ...      |\n# X       | 0  | 1  | ... | 0  |\n# --------+----+----+-----+----+\n#\n\n\n\n\n\n\n\npadj\n: The p-value adjustment method, see \np.adjust.methods\n in R. Default: \nBH\n  \n\n\n\n\n\n\n\n\n\n\n\n\npMediation\n\n\n\n\n\n\ndescription\n\n    Do mediation analysis\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file (a matrix or data.frame).  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The result file.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninopts\n: The options for input file.  \n\n\ncnames\n: Whether the input file has column names\n\n\nrnames\n: Whether the input file has row names\n\n\n\n\n\n\nmedopts\n: The options for mediation analysis.  \n\n\nmodelm\n: The model for M ~ X. Default: \nlm(M ~ X)\n\n\nmodely\n: The model for Y ~ X + M. Default: \nlm(Y ~ X + M)\n\n\nmediator\n: Tell the model which column is the mediator\n\n\ntreat\n: Tell the model which column is the variable\n\n\nboot\n: Use bootstrap?\n\n\nsims\n: How many time simulations?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npHypergeom\n\n\n\n\n\n\ndescription\n\n    Do hypergeometric test.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file, could be raw data (presence (1) and absence (0) of elements) or number of overlapped elements and elements in each category.  \n\n\nSet \nargs.intype\n as \nraw\n if it is raw data. The population size \nargs.N\n is required\n\n\nSet \nargs.intype\n as \nnumbers\n (or any string except \nraw\n) if it is numbers. You can specified explicit header: \nk\n = overlapped elements, \nm\n = size of set 1, \nn\n = size of set 2 and \nN\n = the population size. If \nN\n not included, then \nargs.N\n is required\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nintype\n: the type of input file. Default: \nraw\n. See \ninfile:file\n  \n\n\ninopts\n: The options for input file.  \n\n\ncnames\n: Whether the input file has column names\n\n\nrnames\n: Whether the input file has row names\n\n\n\n\n\n\nN\n: The population size. Default: \nNone\n  \n\n\n\n\n\n\n\n\n\n\ntabix\n\n\n\n\npTabix\n\n\n\n\n\n\ndescription\n\n    Use tabix to extract information.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile\n: a local or remote file  \n\n\nregion\n: a region or a file containing regions  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The information extracted from the input file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntabix\n: The path to \ntabix\n  \n\n\nparams\n: Other params for \ntabix\n  \n\n\n\n\n\n\n\n\n\n\n\n\npTabixIndex\n\n\n\n\n\n\ndescription\n\n    Generate tabix index file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: the input file  \n\n\nCould be bgzipped.\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The bgzipped file  \n\n\noutidx:file\n: The tabix index file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntabix\n: The path to \ntabix\n  \n\n\nparams\n: Other params for \ntabix\n  \n\n\npython\n: Will be used to generate command line arguments.  \n\n\n\n\n\n\n\n\n\n\ntcga\n\n\n\n\npDownload\n\n\n\n\n\n\ndescription\n\n    Download TCGA use \ngdc-client\n and a manifest file\n\n\n\n\n\n\ninput\n  \n\n\n\n\nmanifile:file\n: the manifest file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:file\n: the directory containing downloaded file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nparams\n: other params for \ngdc-client\n, default: \"--no-related-files --no-file-md5sum -n 20\"  \n\n\nbin-gdc\n: the executable file of \ngdc-client\n, default: \"gdc-client\"  \n\n\n\n\n\n\n\n\n\n\n\n\npSample2SubmitterID\n\n\n\n\n\n\ndescription\n\n    convert TCGA sample names with submitter id with metadata and sample containing folder\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: the directory containing the samples  \n\n\nmdfile:file\n: the metadata file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:file\n: the directory containing submitter-id named files  \n\n\n\n\n\n\n\n\n\n\n\n\npConvertExpFiles2Matrix\n\n\n\n\n\n\ndescription\n\n    convert TCGA expression files to expression matrix, and convert sample name to submitter id\n\n\n\n\n\n\ninput\n  \n\n\n\n\ndir:file\n: the directory containing the samples  \n\n\nmdfile:file\n: the metadata file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the output matrix  \n\n\n\n\n\n\n\n\nrequires\n\n\npython-mygene\n\n\n\n\n\n\n\n\n\n\npConvertMutFiles2Matrix\n\n\n\n\n\n\ndescription\n\n    convert TCGA mutation files (vcf.gz) to mut matrix, and convert sample name to submitter id\n\n\n\n\n\n\ninput\n  \n\n\n\n\ndir:file\n: the directory containing the samples  \n\n\nmdfile:file\n: the metadata file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the output matrix  \n\n\n\n\n\n\n\n\n\n\ntfbs\n\n\n\n\npMotifScan\n\n\n\n\n\n\ndescription\n\n    Scan motif along the given sequences.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ntffile:file\n: The infile containing TF name and motif name.  \n\n\nIf only one column is give, will be used as both TF and motif name\n\n\nIf there are 2 columns, 1st column will be motif name, 2nd column will be TF name\n\n\n\n\n\n\nsfile:file\n: The sequence file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:file\n: The output dir  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntools\n   : The tool used to scan the motif. Default: 'meme'  \n\n\nmeme\n    : The path of MEME's fimo. Default: 'fimo'\n\n`motifs   : The motif database in MEME format.\n\n\npval\n    : The pvalue cutoff. Default: 1e-4  \n\n\ncleanmname\n: Whether to clean motif name. Default: True  \n\n\nucsclink\n: The ucsc link template. Default: \nhttps://genome.ucsc.edu/cgi-bin/hgTracks?db=hg19\nposition={}\n  \n\n\nnthread\n : Number of threads used to scan, only available when you have multiple mids. Default: 1  \n\n\nparams\n  : Other parameters for \nfimo\n  \n\n\n\n\n\n\n\n\nrequires\n\n\nfimo\n from MEME Suite\n\n\n\n\n\n\n\n\ntsv\n\n\n\n\npMatrixR\n\n\n\n\n\n\ndescription\n\n    Operate a matrix and save the new matrix to file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file containing the matrix  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output matrix  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n: Whether the input file has cnames. Default: True  \n\n\nrnames\n: Whether the input file has rnames  . Default: 1  \n\n\ncode\n: The R code to operating the matrix. (the matrix is read in variable \nmat\n)  \n\n\n\n\n\n\n\n\n\n\n\n\npCbind\n\n\n\n\n\n\ndescription\n\n    Cbind the rest of files to the first file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfiles:files\n: The input files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output matrix  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n: Whether the input file has cnames. Default: True  \n\n\nor [True, True, False] corresponding to the file order\n\n\n\n\n\n\nrnames\n: Whether the input file has rnames  . Default: 1  \n\n\nmiss\n: Replacement for missing values. Default: \nNA\n  \n\n\n\n\n\n\n\n\n\n\n\n\npRbind\n\n\n\n\n\n\ndescription\n\n    Rbind the rest of files to the first file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfiles:files\n: The input files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output matrix  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n: Whether the input file has cnames. Default: True  \n\n\nor [True, True, False] corresponding to the file order\n\n\n\n\n\n\nrnames\n: Whether the input file has rnames  . Default: 1  \n\n\nmiss\n: Replacement for missing values. Default: \nNA\n  \n\n\n\n\n\n\n\n\n\n\n\n\npCsplit\n\n\n\n\n\n\ndescription\n\n    Split a matrix by columns and save them into files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The directory containing the output column files  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n: Whether the input file has cnames. Default: True  \n\n\nor [True, True, False] corresponding to the file order\n\n\n\n\n\n\nrnames\n: Whether the input file has rnames  . Default: 1  \n\n\n\n\n\n\n\n\n\n\n\n\npRsplit\n\n\n\n\n\n\ndescription\n\n    Split a matrix by rows and save them into files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The directory containing the output row files  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnames\n: Whether the input file has cnames. Default: True  \n\n\nor [True, True, False] corresponding to the file order\n\n\n\n\n\n\nrnames\n: Whether the input file has rnames  . Default: 1  \n\n\n\n\n\n\n\n\n\n\n\n\npTsv\n\n\n\n\n\n\ndescription\n\n    Read, Transform, filter a TSV file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninopts\n: The input options for infile:  \n\n\ndelimit\n: The delimit. Default: \n\\\\t\n\n\ncomment\n: The comment sign. Default: \n#\n\n\nskip\n: First N lines to skip. Default: \n0\n\n\nftype\n: The file type. Metadata can be assigned direct (list/OrderedDict). If not specified, metadata will be generated automatically.\n\n\n\n\n\n\noutopts\n: The output options for outfile:  \n\n\ndelimit\n: The delimit for records. Default: \n\\\\t\n\n\nhead\n: Output header or not. Default: \nFalse\n\n\nheadDelimit\n: The delimit for header. Default: \n\\\\t\n\n\nheadPrefix\n: The prefix for header. Default: ``\n\n\nheadTransform\n: The transformer for header. Default: \nNone\n\n\nftype\n: The file type. Metadata can be assigned direct (list/OrderedDict, '+' as an element or key is allowed to indicate extra meta from the reader). If not specified, metadata will be borrowed from the reader. \n\n\n\n\n\n\nops\n: A ops function to transform the row. Argument is an instance of \nreadRecord\n  \n\n\nopshelper\n: A helper function for \nargs.ops\n  \n\n\n\n\n\n\n\n\n\n\n\n\npSimRead\n\n\n\n\n\n\ndescription\n\n    Read files simultaneously.\n    NOTE: only one file allows multiple lines with same value to compare, and that file should be the first one. For example: \n    \nFile1:\n1\t1\n1\t2\n1\t3\nFile2:\n1\t1\n2\t2\n3\t3\n\n\n    If you compare the first column, File1 has to put at the begining for input.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfiles:files\n: The input files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nskip\n: argument skip for each file  \n\n\ndelimit\n: argument delimit for each file  \n\n\nusehead\n: The header from which input file will be used for output file.  \n\n\nDefault: None (Don't write header)\n\n\n\n\n\n\ngzip\n: argument gzip for each file  \n\n\nmatch\n: The match function.   \n\n\ndo\n: The do function. Global vaiable \nfout\n is available to write results to output file.  \n\n\n\n\n\n\n\n\nrequires\n\n\npython-simread\n\n\n\n\n\n\n\n\nutils\n\n\nvcf\n\n\n\n\npVcfFilter\n\n\n\n\n\n\ndescription\n\n    Filter records in vcf file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nfilters\n: The filters, should be a string of lambda function:\n\n    \nlambda record, samples: \nexpression\n\n* ``record.CHROM`` : \nchr20\n\n* ``record.POS``   : 1234567\n* ``record.ID``    : \nmicrosat1\n\n* ``record.REF``   : \nGTC\n\n* ``record.ALT``   : [G, GTCT]\n* ``record.QUAL``  : 50\n* ``record.FILTER``: [\nPASS\n] # NO!, PASS should be []\n* ``record.INFO``  : {\nAA\n: \nG\n, \nNS\n: 3, \nDP\n: 9}\n* samples = record.samples\n* len(samples): 3\n* samples[0].sample: \nNA00001\n\n* samples[0]: Call(sample=NA00001, CallData(GT=0/1, GQ=35, DP=4))\n* samples[0].data: calldata(GT=\n0/1\n, GQ=35, DP=4)\n* samples[0].data.GT: \n0/1\n\n\n\n\nsee here for record and samples: https://github.com/jamescasbon/PyVCF\n\n\nRemember if filters() returns True, record remained.\n\n\n\n\n\n\ngz\n     : Whether to gzip the output file. Default: False  \n\n\nkeep\n   : Whether to keep the filtered records. Default: True. (only for gatk, snpsift at filter step)  \n\n\n\n\n\n\n\n\nrequires\n\n\npyvcf\n\n\n\n\n\n\n\n\n\n\npVcf\n\n\n\n\n\n\ndescription\n\n    Use pyvcf to manipulate vcf file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input vcf file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output vcf file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nhelper\n: The helper code injected to script  \n\n\nSince lambda function can't do assignment and manipulation so you can write some help function here\n\n\n\n\n\n\nreaderops\n: A lambda function (must be quoted) to manipulate the reader (vcf.Reader instance)  \n\n\nrecordops\n: A lambda function (must be quoted) to manipulate the record (vcf.Record instance)  \n\n\ngz\n: Gzip the ouput file  \n\n\n\n\n\n\n\n\n\n\n\n\npVcfAnno\n\n\n\n\n\n\ndescription\n\n    Annotate the variants in vcf file.\n    You have to prepare the databases for each tool.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input vcf file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file (output file of annovar will also be converted to vcf)  \n\n\noutdir\n: The output directory, used to fetch some stat/summary files  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to do annotation. Default: snpeff  \n\n\nsnpeff\n: The path of snpeff. Default: snpEff  \n\n\nvep\n: The path to vep. Default: vep  \n\n\ngz\n: Whether to gzip the result file. Default: False  \n\n\nannovar\n: The path of annovar. Default: annotate_variation.pl  \n\n\nannovar_convert\n: The path of convert2annovar.pl, used to convert vcf to annovar input file. Default: convert2annovar.pl  \n\n\ngenome\n: The genome for annotation. Default: hg19  \n\n\ntmpdir\n: The tmpdir, mainly used by snpeff. Default: \n  \n\n\ndbpath\n: The path of database for each tool. Required by 'annovar' and 'vep'  \n\n\nparams\n: Other params for tool. Default: ''  \n\n\nsnpeffStats\n: Whether to generate stats file when use snpeff. Default: False  \n\n\nmem\n: The memory used by snpeff. Default: '4G'  \n\n\n\n\n\n\n\n\nrequires\n\n\nannovar\n\n    \nsnpeff\n\n    \nvep\n\n\n\n\n\n\n\n\n\n\npVcfSplit\n\n\n\n\n\n\ndescription\n\n    Split multi-sample Vcf to single-sample Vcf files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input vcf file  \n\n\nsamples\n: The samples, if not provided, will extract all samples  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory containing the extracted vcfs  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to do extraction. Default: vcftools  \n\n\nvcftools\n: The path of vcftools' vcf-subset  \n\n\nbcftools\n: The path of bcftools, used to extract the sample names from input vcf file.  \n\n\ngatk\n: The path of gatk.  \n\n\n\n\n\n\n\n\n\n\n\n\npVcfMerge\n\n\n\n\n\n\ndescription\n\n    Merge single-sample Vcf files to multi-sample Vcf file.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfiles:files\n: The input vcf files  \n\n\noutfile:dir\n: The output multi-sample vcf.  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n: The tool used to do extraction. Default: vcftools  \n\n\nvcftools\n: The path of vcftools' vcf-subset  \n\n\nbcftools\n: The path of bcftools, used to extract the sample names from input vcf file.  \n\n\ngatk\n: The path of gatk.  \n\n\n\n\n\n\n\n\n\n\n\n\npVcf2Maf\n\n\n\n\n\n\ndescription\n\n    Convert Vcf file to Maf file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n : The input vcf file  \n\n\nsee \nargs.somatic\n\n\n\n\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output maf file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntool\n     : Which tool to use. Default: vcf2maf  \n\n\nvcf2maf\n  : The path of vcf2maf.pl  \n\n\nvep\n      : The path of vep  \n\n\nvepDb\n    : The path of database for vep  \n\n\nfiltervcf\n: The filter vcf. Something like: ExAC_nonTCGA.r0.3.1.sites.vep.vcf.gz  \n\n\nref\n      : The reference genome  \n\n\nnthread\n  : Number of threads used to extract samples. Default: 1  \n\n\ntumor1st\n : Whether tumor sample comes first. Default: \nTrue\n  \n\n\nbcftools\n : Path to bcftools used to extract sample names.  \n\n\nvcftools\n : Path to vcftools used to split vcf.  \n\n\nsamfunc\n  : A lambda function used to deduce sample names from file name.  \n\n\nsomatic\n  : Whether input vcf file is a somatic mutation file. Default: False  \n\n\nsomatic mutation vcf file can only have one sample TUMOR, or two samples, TUMOR and NORMAL, but will be considered as single sample.\n\n\notherwise, multiple samples are supported in the input vcf file. Tumor id will be sample name for each sample, normal id will be NORMAL.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npVcf2GTMat\n\n\n\n\ndescription\n\n    Convert Vcf file to genotype matrix.\n\n\n\n\n\n\nvcfnext\n\n\n\n\npVcfStatsPlot\n\n\n\n\n\n\ndescription\n\n    Convert csvstat file from snpEff to R-readable matrix and plot them.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The directory containing the csv stat files from \nsnpEff ann\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nchroms\n: The chromsome filter. Default: \"\" (all chroms)  \n\n\nNote: snpEff csvstat file has no \"chr\" prefix\n\n\n\n\n\n\n\n\n\n\n\n\npCallRate\n\n\n\n\n\n\ndescription\n\n    Calculate sample/snp call rate from single sample vcfs\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The dir containing the vcfs  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutsample:file\n: The report of call rate for each sample  \n\n\nfigsample:file\n: The bar chat of sample call rates  \n\n\noutsnp:file\n: The report of call rate for each snp  \n\n\nfigsnp:file\n: The bar chat of snp call rates  \n\n\n\n\n\n\n\n\n\n\n\n\npCepip\n\n\n\n\n\n\ndescription\n\n    Run CEPIP.\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file (vcf or avinput)  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The cepip result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncepip\n: The path of cepip  \n\n\ncell\n : The related cell line  \n\n\nparams\n: Other params for cepip  \n\n\n\n\n\n\n\n\nrequires\n\n\ncepip\n\n\n\n\n\n\n\n\n\n\npMutSig\n\n\n\n\n\n\ndescription\n\n    MutSig stands for \"Mutation Significance\".  MutSig analyzes lists of mutations discovered in DNA sequencing, to identify genes that were mutated more often than expected by chance given background mutation processes.\n    For more information, see Lawrence, M. et al. Mutational heterogeneity in cancer and the search for new cancer-associated genes. Nature 499, 214-218 (2013).\n\n\nSee \ndcumentation\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: mutation table  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nmutsig\n : The path to \nrun_MutSigCV.sh\n, default: 'mutsig'  \n\n\nmcr\n    : The Matlab MCR path  \n\n\ncvrg\n   : coverage table  \n\n\ncvrt\n   : covariates table  \n\n\nmutdict\n: mutation_type_dictionary_file  \n\n\nchrdir\n : chr_files_hg18 or chr_files_hg19  \n\n\n\n\n\n\n\n\nrequires\n\n\nMutSig\n\n\n\n\n\n\n\n\n\n\npMafMerge\n\n\n\n\n\n\ndescription\n\n    Merge maf files.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:dir\n: The directory containing the maf files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The merged maf file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nexcols\n: How to deal with extra columns other than 34 standard columns from TCGA.  \n\n\nmerge(default): Merge the columns, if one not exists, fill with an empty string.\n\n\ndiscard: Just discard the extra columns, with only 34 columns left. So you can also put just one maf file in the indir with some columns missed to fill it with standard columns.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npMaftools\n\n\n\n\n\n\ndescription\n\n    Use maftools to draw plots.\n\n\n\n\n\n\nargs\n  \n\n\n\n\nngenes\n:   \n\n\n\n\n\n\n\n\nrequires\n\n    [``]\n\n\n\n\n\n\n\n\nweb\n\n\n\n\npDownloadForm\n\n\n\n\n\n\ndescription\n\n    Download results by submitting a form, supporting pagination.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nurl\n   : the URL contains the form  \n\n\ndata\n  : the data used to fill the form (JSON string or transformed from dict by json.dumps).  \n\n\nsubmit\n: the submit button to submit the form (use Xpath).  \n\n\nnext\n  : the button for next page (use Xpath)  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:file\n: The directory saves the results  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ninterval\n: seconds to wait between fetching each page. Default: 1  \n\n\n\n\n\n\n\n\nrequires\n\n\nSplinter\n\n    \nPhantomjs\n\n\n\n\n\n\n\n\n\n\npDownloadGet\n\n\n\n\n\n\ndescription\n\n    Download results by urls.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nurl\n: the URLs to download  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\n\n\n\n\npDownload\n\n\n\n\ndescription\n\n    Alias of \npDownloadGet\n\n\n\n\n\n\n\n\npDownloadPost\n\n\n\n\n\n\ndescription\n\n    Download results by POST.\n\n\n\n\n\n\ninput\n  \n\n\n\n\nurl\n : the URLs to download  \n\n\ndata\n: the POST data.  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\n\n\nwxs\n\n\nwxsanno\n\n\n\n\npSnpEff\n\n\n\n\n\n\ndescription\n\n    This is the default command. It is used for annotating variant filed (e.g. VCF files).\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The input file   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:file\n: The directory containing output anntated file, snpEff_genes.txt and snpEff_summary.html  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nsnpEff\n: The snpEff executable, default: \"snpEff\"  \n\n\nparams\n: Other parameters for \nsnpEff\n, default: \"-Xms1g -Xmx4g -v\"  \n\n\ngenome\n: The genome used for annotation, default: \"hg19\"  \n\n\ninformat\n: The format of input file [vcf or bed], default: \"vcf\"  \n\n\noutformat\n: The format of output file [vcf, gatk, bed, bedAnn], default: \"vcf\"  \n\n\ncsvStats\n: Whether to generate csv stats file, default: True.  \n\n\nhtmlStats\n: Whether to generate the html summary file, default: False.  \n\n\njavamem\n: The memory to use. Default: '-Xms1g -Xmx8g'  \n\n\n\n\n\n\n\n\nrequires\n\n\nsnpEff\n\n\n\n\n\n\n\n\nwxscall\n\n\n\n\npCNVnator\n\n\n\n\n\n\ndescription\n\n    Use \nCNVnator\n to call CNVs from bam file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The vcf file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ncnvnator\n: The CNVnator executable, default: \"cnvnator\"  \n\n\ncnv2vcf\n: The converter executable to convert CNVnator results to vcf, default: \"cnvnator2VCF.pl\"  \n\n\nbinsize\n: The bin_size, default: 100  \n\n\ngenome\n: The genome: default: hg19  \n\n\nchrom\n: Chromosome names, default: \"\" (all chromosomes)  \n\n\nchrdir\n: The dir contains reference sequence of chromosomes, default: \"\" (don't specify)  \n\n\n\n\n\n\n\n\nrequires\n\n\nCNVnator\n\n\n\n\n\n\n\n\nwxsdown\n\n\n\n\npMutSig\n\n\n\n\n\n\ndescription\n\n    MutSig stands for \"Mutation Significance\".  MutSig analyzes lists of mutations discovered in DNA sequencing, to identify genes that were mutated more often than expected by chance given background mutation processes.\n\n\nFor more information, see Lawrence, M. et al. Mutational heterogeneity in cancer and the search for new cancer-associated genes. Nature 499, 214-218 (2013).\n\n\nSee \ndcumentation\n\n\n\n\n\n\ninput\n  \n\n\n\n\nmaffile:file\n: mutation table  \n\n\ncvgfile:file\n: coverage table  \n\n\ncvrfile:file\n: covariates table  \n\n\nmutdict:file\n: mutation_type_dictionary_file  \n\n\nchrdir:file\n: chr_files_hg18 or chr_files_hg19   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nmutsig\n: The path to \nrun_MutSigCV.sh\n, default: 'mutsig'  \n\n\nmcr\n: The Matlab MCR path  \n\n\n\n\n\n\n\n\nrequires\n\n\nMutSing\n\n\n\n\n\n\n\n\n\n\npVcf2Maf\n\n\n\n\n\n\ndescription\n\n    Convert a snpEff-annotated somatic mutation vcf file (with normal and tumor samples) to \nmaf\n file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: vcf file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The maf file  \n\n\n\n\n\n\n\n\nargs\n\n\nvepdata\n: The path of vep data. Default: \"\" (default data dir of vep)\n       \nvep\n: The path of vep excutable. Default: \"vep\"\n       \nvcf2maf\n: The path of vcf2maf excutable. Default: \"vcf2maf.pl\"\n       \nreffile\n: The reference fasta file.\n       \nnthread\n: The number of threads used by vep. Default: 1\n       \nfiltervcf\n: The filter vcf\n\n\n\n\nparams\n: Other parameters for \nvcf2maf.pl\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nvcf2maf.py\n\n\n\n\n\n\n\n\n\n\npMergeMafs\n\n\n\n\n\n\ndescription\n\n    Merge MAF files\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The directory containing MAF files to be merged  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The merged MAF file  \n\n\n\n\n\n\n\n\n\n\n\n\npMutsig4Plot\n\n\n\n\n\n\ndescription\n\n    Prepare somatic mutations for  plotting\n\n\n\n\n\n\ninput\n  \n\n\n\n\nmsdir:file\n: The mutsig output directory  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The file for plotting\n\n\n#PANEL: Somatic mutations\n#INFO: MT|PI\n#DESC: Mutation type|Putative impact\n# could also be bordercolor, you can have up to 4 shape features\n#TYPE: shape|bgcolor\n# could also be continuous\n# expressions for set: a,b,c\n#                 norminal: no\n#                 continuous: [0,1]\n#DATA: set|norminal\n#NCOL: 2|2\n#NAME_MT: Frameshift|Missense|Nonsense|Silent|Splice_site|TSS|Nonstop\n#NAME_PI: HIGH|MODERATE|LOW|MODIFIER\n#VALUE_MT: 0|1|20|13|4|17|14\n#EXP_MT: frameshift_variant,inframe_deletion,inframe_insertion|missense_variant,initiator_codon_variant,stop_retained_variant,rare_amino_acid_variant|stop_gained|synonymous_variant|splice_acceptor_variant,splice_donor_variant|start_lost,start_retained|stop_lost\n#\nSample1\tSample2\tSample3\tSample4\tSample5\nABC\tmissense_variant|HIGH\tmissense_variant|HIGH\t...\n...\n\n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntopn\n: the cutoff to select genes. If it is \n= 1, top N genes will be selected, otherwise, it will be used as pvalue cutoff. Default: .05  \n\n\n\n\n\n\n\n\nrequires\n\n\npyvcf\n\n\n\n\n\n\n\n\n\n\npMutPlot\n\n\n\n\n\n\ndescription\n\n    Plot mutations\n    \n|           |             |           |           |---\n|- ftWidth -|  s   s   s  |- pnWidth -|- lgWidth -| snHeight\n|           |             |           |           |---\n    feature1\n\tfeature2\n\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The input directory containing plot files  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The plot png file  \n\n\n\n\n\n\n\n\n\n\n\n\npCepip\n\n\n\n\n\n\ndescription\n\n    run CEPIP.\n\n\n\n\n\n\ninput\n  \n\n\n\n\navinput:file\n: The avinput file  \n\n\ncell\n: The cell  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The cepip result file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin-cepip\n: The jar file path of cepip, default: /data2/junwenwang/shared/tools/cepip/cepip.jar  \n\n\n\n\n\n\n\n\nrequires\n\n\ncepip\n\n\n\n\n\n\n\n\nwxsprep\n\n\n\n\npTrimmomaticPE\n\n\n\n\n\n\ndescription\n\n    Trimming Illumina NGS paired-end data\n\n\n\n\n\n\ninput\n  \n\n\n\n\nfqfile1:file\n: The 1st fastq file (could be in .gz format)  \n\n\nfqfile2:file\n: The 2nd fastq file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile1:file\n: The 1st output file  \n\n\noutfile2:file\n: The 2nd output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntrimmomatic\n: The trimmomatic executable, default: \"trimmomatic\"  \n\n\nphred\n: \"phred33\" (default) or \"phred64\"  \n\n\nparams\n: Other params for trimmomatric, default: \"ILLUMINACLIP:{adapter}:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\"  \n\n\nhave to replace \n{adapter}\n with the path of the adapter file\n\n\n\n\n\n\nnthread\n: 1  \n\n\n\n\n\n\n\n\nrequires\n\n\ntrimmomatic\n\n\n\n\n\n\n\n\n\n\npTrimmomaticSE\n\n\n\n\n\n\ndescription\n\n    Trimming Illumina NGS single-end data\n\n\n\n\n\n\ninput\n  \n\n\n\n\nfqfile:file\n: The fastq file (could be in .gz format)  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\ntrimmomatic\n: The trimmomatic executable, default: \"trimmomatic\"  \n\n\nphred\n: \"phred33\" (default) or \"phred64\"  \n\n\nparams\n: Other params for trimmomatric, default: \"ILLUMINACLIP:{adapter}:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\"  \n\n\nhave to replace \n{adapter}\n with the path of the adapter file\n\n\n\n\n\n\nnthread\n: 1  \n\n\n\n\n\n\n\n\nrequires\n\n\ntrimmomatic\n\n\n\n\n\n\n\n\n\n\npAlignPEByBWA\n\n\n\n\n\n\ndescription\n\n    Align paired-end reads to reference genome using bwa mem\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile1:file\n: read file 1 (fastq, or fastq gzipped)  \n\n\ninfile2:file\n: read file 2 (fastq, or fastq gzipped)  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output sam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbwa\n: The bwa executable, default: bwa  \n\n\nparams\n: Other params for bwa mem, default: \"-M\"  \n\n\nnthread\n: 1  \n\n\n\n\n\n\n\n\nrequires\n\n\nbwa\n\n\n\n\n\n\n\n\n\n\npAlignSEByBWA\n\n\n\n\n\n\ndescription\n\n    Align paired-end reads to reference genome using bwa mem\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: read file (fastq, or fastq gzipped)  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\nbrings\n  \n\n\n\n\nreffile#bwt\n: \"{{reffile | bn}}.bwt\",   \n\n\nreffile#sa\n: \"{{reffile | bn}}.sa\",  \n\n\nreffile#ann\n: \"{{reffile | bn}}.ann\",  \n\n\nreffile#amb\n: \"{{reffile | bn}}.amb\",  \n\n\nreffile#pac\n: \"{{reffile | bn}}.pac\"  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output sam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbwa\n: The bwa executable, default: bwa  \n\n\nparams\n: Other params for bwa mem, default: \"-M\"  \n\n\nnthread\n: 1  \n\n\nreffile\n: The reference file, required  \n\n\n\n\n\n\n\n\nrequires\n\n\nbwa\n\n\n\n\n\n\n\n\n\n\npAlignPEByNGM\n\n\n\n\n\n\ndescription\n\n    Align paired-end reads to reference genome using NextGenMap\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile1:file\n: read file 1 (fastq, or fastq gzipped)  \n\n\ninfile2:file\n: read file 2 (fastq, or fastq gzipped)  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output sam/bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nngm\n: The NextGenMap executable, default: ngm  \n\n\nnthread\n: 1  \n\n\nouttype\n: sam or bam, default: sam (only sam for now, due to bug of ngm 0.5.3 (fixed in 0.5.4))  \n\n\nparams\n: Other params for ngm, default: \"--rg-id ngm --rg-sm sample\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nNextGenMap\n\n\n\n\n\n\n\n\n\n\npAlignSEByNGM\n\n\n\n\n\n\ndescription\n\n    Align single-end reads to reference genome using NextGenMap\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile1:file\n: read file 1 (fastq, or fastq gzipped)  \n\n\ninfile2:file\n: read file 2 (fastq, or fastq gzipped)  \n\n\nreffile:file\n: The reference file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The output sam/bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nngm\n: The NextGenMap executable, default: ngm  \n\n\nnthread\n: 1  \n\n\nouttype\n: sam or bam, default: sam (only sam for now, due to bug of ngm 0.5.3 (fixed in 0.5.4))  \n\n\nparams\n: Other params for ngm, default: \"--rg-id ngm --rg-sm sample\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nNextGenMap\n\n\n\n\n\n\n\n\n\n\npMergeBams\n\n\n\n\n\n\ndescription\n\n    Merge bam files\n\n\n\n\n\n\ninput\n  \n\n\n\n\nbamdir:dir\n: the dir containing bam files   \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: the merged bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nsamtools\n: the executable path of samtools, default: \"samtools\"  \n\n\nnthread\n: Number of BAM/CRAM compression threads  \n\n\nparams\n: Other parameters for \nsamtools merge\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nsamtools\n\n\n\n\n\n\n\n\nwxsstat\n\n\n\n\npVcf2List\n\n\n\n\n\n\ndescription\n\n    Convert vcf to stat files for pCallRate\n\n\n\n\n\n\ninput\n  \n\n\n\n\nvcffile:file\n: The vcf file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The stat file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nchroms\n: SNPs on chromosomes to consider, default: \"\" (all chroms)  \n\n\nuse \"chr1-22, chrX, chrY\" for chr1 to chr22, chrX and chrY\n\n\n\n\n\n\n\n\nrequires\n\n\npyvcf\n\n\n\n\n\n\n\n\n\n\npCallRate\n\n\n\n\n\n\ndescription\n\n    Calculate sample/snp call rate from a matrix of snp-sample\n\n\n\n\nrows are snps, columns are samples\n\n\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The snp-sample matrix file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutsample:file\n: The report of call rate for each sample  \n\n\nfigsample:file\n: The bar chat of sample call rates  \n\n\noutsnp:file\n: The report of call rate for each snp  \n\n\nfigsnp:file\n: The bar chat of snp call rates  \n\n\n\n\n\n\n\n\n\n\n\n\npCoverageByBamstats\n\n\n\n\n\n\ndescription\n\n    Use \nbamstats\n to calculate coverage for bam file\n\n\n\n\n\n\ninput\n  \n\n\n\n\ninfile:file\n: The bam file  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutfile:file\n: The report of coverage for the bam file  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nbin\n: The \nbamstats\n executable, default: \"bamstats\"  \n\n\nparams\n: Other parameters for \nbamstats\n, default: \"\"  \n\n\n\n\n\n\n\n\nrequires\n\n\nbamstats\n\n\n\n\n\n\n\n\n\n\npPlotBamstats\n\n\n\n\n\n\ndescription\n\n    Plot coverage use output files generated by \nbamstats\n or \nwxs.pCoverageByBamstats\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The directory containing bamstats output files  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nchroms\n: Chromosomes to plot. Default: \"\" (all chroms)  \n\n\nNote: Whether to have \"chr\" prefix or not depends on your reference when mapping.\n\n\nYou can do a scope assignment: \"chr1-chr22, chrX, chrY\"\n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:file\n: The directory containing output figures  \n\n\n\n\n\n\n\n\n\n\n\n\npSnpEff2Stat\n\n\n\n\n\n\ndescription\n\n    Convert csvstat file from snpEff to R-readable matrix for plotting\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The directory containing the csv stat files from \nsnpEff ann\n  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\nargs\n  \n\n\n\n\nchroms\n: The chromsome filter. Default: \"\" (all chroms)  \n\n\nNote: snpEff csvstat file has no \"chr\" prefix\n\n\n\n\n\n\n\n\n\n\n\n\npPlotSnpEff\n\n\n\n\n\n\ndescription\n\n    Plot snpEff annotation statistics\n\n\n\n\n\n\ninput\n  \n\n\n\n\nindir:file\n: The snpEff result directory containing matrix files generated by pSnpEff2Stat  \n\n\n\n\n\n\n\n\noutput\n  \n\n\n\n\noutdir:dir\n: The output directory  \n\n\n\n\n\n\n\n\nrequires\n\n\npwwang/corrplot\n\n\n\n\nuse \nlibrary(devtools); install.github(\"pwwang/corrplot\")\n\n\nggplot2", 
            "title": "Processes"
        }, 
        {
            "location": "/processes/#algorithm", 
            "text": "pRWR    description \n    Do random walk with restart (RWR)    input      Wfile:file : The adjecent matrix    Efile:file : The start vector       output      outfile:file : The output of final probabilities       args      c : The restart probability. Default: 0.1    eps : The convergent cutoff || R(i+1) - R(i) ||. Default: 1e-5    niter : Max iterations to stop. Default: 10000    normW : Weather to normalize W or not, default True.     Laplacian normalization is used (more to add).    normE : Weather to normalize E or not, default True.     E will be normalized as: E = E/sum(E)       requires \n    if normW = True, R package  NetPreProc  is required.      pAR    description \n    Affinity Regression.\n    Ref: https://www.nature.com/articles/nbt.3343\n             b           c        d          d  \n    _________    _______    ____       ____\n    |       |    |  W  |    |  |       |  |\n  a |   D   |  b |_____|  c |Pt|  =  a |Y |    = \n    |_______|               |__|       |  |\n                                       |__|\n\nkronecker(P, YtD)*vec(W) = vec(YtY)              = \nX*vec(W) = vec(YtY)\nWPt:\n       c        d              d  \n    _______    ____          _____\n    |  W  |    |  |          |   |\n  b |_____|  c |Pt|  ---   b |___|\n                  |__|\n\nYtDW:\nWtDtY:\n     b           a        d               d    \n  _______    _________   ____           _____  \n  |  Wt |    |       |   |  |           |   |  \nc |_____|  b |   Dt  | a |Y |    ---  c |___|  \n             |_______|   |  |                 \n                         |__|                      input      D:file  : The D matrix    Pt:file : The Pt matrix    Y:file : The Y matrix    All input files could be gzipped       output      W:file : The interaction matrix    outdir:dir : The output directory       args      seed : The seed for sampling the training set.    tfrac : The fraction of samples used for training. \n``", 
            "title": "algorithm"
        }, 
        {
            "location": "/processes/#bed", 
            "text": "pBedSort    description \n    Sort bed files    input      infile:file : The input file       output      outfile:file : The output file       args      tool : The tool used to sort the file. Default: sort (bedtools, bedops)    bedtools : The path to bedtools. Default: bedtools    bedops_sort : The path to bedops' sort-bed. Default: sort-bed    mem : The memory to use. Default: 8G    tmpdir : The tmpdir to use. Default:  $TMPDIR     unique : Remove the dupliated records? Default: True    params : Other params for  tool . Default: {}       requires  bedtools \n     bedops      pBedCluster    description \n    Assign cluster id to each record    input      infile:file : The input bed file       output      outfile:file : The output file       args      tool : The tool used to sort the file. Default: bedtools    bedtools : The path to bedtools. Default: bedtools    params : Other params for  tool . Default: ''       requires  bedtools", 
            "title": "bed"
        }, 
        {
            "location": "/processes/#bedtools", 
            "text": "pBedGetfasta    description  bedtools getfasta  extracts sequences from a FASTA file for each of the intervals defined in a BED file.    input      infile:file : The input bed file       output      outfile:file : The generated fasta file       args      ref      : The fasta file    bedtools : The bedtools executable,                  default: \"bedtools\"    params   : Other parameters for  bedtools getfasta , default: \"\"       requires  bedtools      pBedClosest    description \n    Similar to intersect, closest searches for overlapping features in A and B. In the event that no feature in B overlaps the current feature in A, closest will report the nearest (that is, least genomic distance from the start or end of A) feature in B. For example, one might want to find which is the closest gene to a significant GWAS polymorphism. Note that closest will report an overlapping feature as the closest that is, it does not restrict to closest non-overlapping feature. The following iconic cheatsheet summarizes the funcitonality available through the various optyions provided by the closest tool.    input      afile:file : The -a file    bfile:file : The -b file       output      outfile:file : The result file       args      bedtools : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools closest , default: \"\"       requires  bedtools      pBedClosest2    description \n    Multiple b-file version of pBedClosest    input      afile:file : The -a file    bfiles:files : The -b files       output      outfile:file : The result file       args      bedtools : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools closest , default: \"\"       requires  bedtools      pBedFlank    description  bedtools flank  will create two new flanking intervals for each interval in a BED file. Note that flank will restrict the created flanking intervals to the size of the chromosome (i.e. no start   0 and no end   chromosome size).    input      infile:file : The input file    gfile:file : The genome size file       output      outfile:file : The result file       args      bin : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools flank , default: \"\"       requires  bedtools      pBedIntersect    description \n    By far, the most common question asked of two sets of genomic features is whether or not any of the features in the two sets overlap with one another. This is known as feature intersection. bedtools intersect allows one to screen for overlaps between two sets of genomic features. Moreover, it allows one to have fine control as to how the intersections are reported. bedtools intersect works with both BED/GFF/VCF and BAM files as input.    input      afile:file  : The a file    bfile:file : The b file       output      outfile:file : The result file       args      bedtools : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools intersect , default: \"\"       requires  bedtools      pBedIntersect2    description \n    Multiple b-file version of pBedIntersect    input      afile:file  : The a file    bfiles:files : The b files       output      outfile:file : The result file       args      bedtools : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools intersect , default: \"\"       requires  bedtools      pBedMakewindows    description \n    Makes adjacent or sliding windows across a genome or BED file.    input      infile:file : The input file       output      outfile:file : The result file       args      bin : The bedtools executable, default: \"bedtools\"    informat : The format of input file, whether is a \"bed\" file or \"genome\" size file. Default: \"bed\"    params : Other parameters for  bedtools makewindows , default: \"\"       requires  bedtools      pBedMerge    description  bedtools merge  combines overlapping or book-ended features in an interval file into a single feature which spans all of the combined features.    input      infile:file : The input file       output      outfile:file : The result file       args      bedtools : The bedtools executable,               default: \"bedtools\"    params   : Other parameters for  bedtools merge , default: {}       requires  bedtools      pBedMerge2    description \n    A multi-input file model of pBedMerge: Merge multiple input files.    input      infiles:files : The input files       output      outfile:file : The result file       args      bedtools : The bedtools executable,               default: \"bedtools\"    params   : Other parameters for  bedtools merge , default: {}       requires  bedtools      pBedMultiinter    description \n    Identifies common intervals among multiple BED/GFF/VCF files.    input      infiles:files : The input files       output      outfile:file : The result file       args      bin : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools multiinter , default: \"\"       requires  bedtools      pBedRandom    description  bedtools random  will generate a random set of intervals in BED6 format. One can specify both the number (-n) and the size (-l) of the intervals that should be generated.    input      gfile:file : The genome size file       output      outfile:file : The result file       args      bedtools : The bedtools executable,    default: \"bedtools\"    seed     : The seed for randomization, default: None    gsize    : The chromsize file.       requires  bedtools      pBedShift    description  bedtools shift  will move each feature in a feature file by a user-defined number of bases. While something like this could be done with an awk '{OFS=\"\\t\" print $1,$2+ ,$3+ }', bedtools shift will restrict the resizing to the size of the chromosome (i.e. no features before 0 or past the chromosome end).    input      infile:file : The input file    gfile:file : The genome size file       output      outfile:file : The result file       args      bin : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools shift , default: \"\"       requires  bedtools      pBedShuffle    description  bedtools shuffle  will randomly permute the genomic locations of a feature file among a genome defined in a genome file. One can also provide an exclusions BED/GFF/VCF file that lists regions where you do not want the permuted features to be placed. For example, one might want to prevent features from being placed in known genome gaps. shuffle is useful as a null basis against which to test the significance of associations of one feature with another.    input      infile:file : The input file    gfile:file : The genome size file       output      outfile:file : The result file       args      bin : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools shuffle , default: \"\"       requires  bedtools      pBedSubtract    description  bedtools subtract  searches for features in B that overlap A. If an overlapping feature is found in B, the overlapping portion is removed from A and the remaining portion of A is reported. If a feature in B overlaps all of a feature in A, the A feature will not be reported.    input      afile:file : The a file    bfile:file : The b file       output      outfile:file : The result file       args      bin : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools subtract , default: \"\"       requires  bedtools      pBedWindow    description \n    Similar to  bedtools intersect ,  window  searches for overlapping features in A and B. However, window adds a specified number (1000, by default) of base pairs upstream and downstream of each feature in A. In effect, this allows features in B that are near features in A to be detected.    input      afile:file : The a file    bfile:file : The b file       output      outfile:file : The result file       args      bin : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools window , default: \"\"       requires  bedtools      pBedGenomecov    description  bedtools genomecov  computes histograms (default), per-base reports (-d) and BEDGRAPH (-bg) summaries of feature coverage (e.g., aligned sequences) for a given genome.  NOTE: only bam file input implemented here.    input      infile:file : The bam file       output      outfile:file : The result file       args      bin : The bedtools executable, default: \"bedtools\"    params : Other parameters for  bedtools genomecov , default: \"-bg\"       requires  bedtools", 
            "title": "bedtools"
        }, 
        {
            "location": "/processes/#chipseq", 
            "text": "pPeakToRegPotential    description \n    Convert peaks to regulatory potential score for each gene\n    The formula is:\n     -(0.5 + 4*di/d0)\n    PC = sum (pi * e                  ) \n    Ref: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4489297/    input      peakfile:file : The BED/peak file for peaks    genefile:file : The BED file for gene coordinates       output      outfile:file : The regulatory potential file for each gene       args      intensity :  pi  in the formula. Boolean value, whether use the peak intensity or not, default:  True ,    geneformat : The format for  genefile , default:  ucsc+gz . It could be:    ucsc or ucsc+gz: typically, you can download from http://hgdownload.cse.ucsc.edu/goldenPath/hg38/database/refGene.txt.gz  bed or bed+gz:  format , 4th column required as gene identity.    peakformat : The format for  peakfile , default:  peak . It could be:    peak or peak+gz: (either  narrowPeak  or  broadPeak , the 7th column will be used as intensity  bed or bed+gz:  format , 5th column will be used as intensity.    window :  2 * d0  in the formula. The window where the peaks fall in will be consided, default:  100000 .   |--------- window ----------|\n    |---- d0 -----|\n    |--- 50K --- TSS --- 50K ---|\n         ^ (peak center)\n         |-- di --|", 
            "title": "chipseq"
        }, 
        {
            "location": "/processes/#cluster", 
            "text": "pDist2Coords    description \n    Convert a distance matrix to coordinates, using multidimensional scaling.    input      infile:file : The distance matrix, could be a full distance matrix, a triangle matrix or a pair-wise distance file    full dist matrix (full): \ts1\ts2\ts3\ns1\t0\t1\t1\ns2\t1\t0\t1\ns3\t1\t1\t0  triangle matrix (upper/lower), could be also lower triangle \ts1\ts2\ts3\ns1\t0\t1\t1\ns2\t\t0\t1\ns3\t\t\t0  pair-wise (pair): (assuming auto-pair-wise distance = 0, that is:  s1 s1  0 ) s1\ts2\t1\ns1\ts3\t1\ns2\ts3\t1  Both rownames and header are required.       output      outfile:file : The output coordinate file       args      informat : The format of the input file: full, triangle or pair. Default: full    Could also be upper, lower, pair    k : How many dimensions? Default: 2 (R^2)         pCluster    description \n    Use  optCluster  to select the best number of clusters and cluster method, then perform the clustering    input      infile:file : The input matrix file. Clustering will be performed against rows. If not, set  args.transpose  = True       output      outfile:file : The output cluster file    outdir:dir : The output directory containing the figures       args      transpose : Transpose the input matrix. Default: False    cnames : Whether the input matrix contains header before transposing. Default: False    rnames : Which column is the rownames before transposing. Default: 1    plot : Whether plot the cluster. Default: True    minc : Min number of clusters to test. Default: 2    maxc : Min number of clusters to test. Default: 15    If number of rows (nrows)  = 15, then max = nrows - 1    methods : The methods to test. Default: \"all\"    Could be any of \"agnes\", \"clara\", \"diana\", \"fanny\", \"hierarchical\", \"kmeans\", \"model\", \"pam\", \"som\", \"sota\", \"em.nbinom\", \"da.nbinom\", \"sa.nbinom\", \"em.poisson\", \"da.poisson\", \"sa.poisson\"  Multiple methods could be separated by comma (,), or put in a list  By default, fanny, model and sota will be excluded because fanny causes error and the latter two are slow. You can manually include them if you want.  Improper methods will be automatically excluded by  args.isCount    isCount : Whether the data is count data. Corresponding methods will be tested. Default: False       requires  r-optCluster \n     r-factoextra      pMCluster    description \n    Use  r-mclust  to do clustering. Current just do simple clustering with the package    input      infile:file : The input a coordinate file       output      outdir:dir : The output of final results       args      transpose : Transpose the input matrix? Default: False    rnames : The  row.names  for  read.table  to read the input file, default: True.    cnames : The  header  argument for  read.table  to read the input file, default: True.    caption : The caption for the  fviz_cluster , default: \"CLARA Clustering\".    minc : The min # clusters to try, default: 2    maxc : The max # clusters to try, default: 15       requires  r-mclust \n     r-factoextra      pAPCluster    description \n    Use  r-apcluster  to do clustering.     input      infile:file : The input a coordinate file       output      outdir:dir : The output of final results       args      transpose : Transpose the input matrix? Default: False    rownames : The  row.names  for  read.table  to read the input file, default: 1.    header : The  header  argument for  read.table  to read the input file, default: True.    caption : The caption for the  fviz_cluster , default: \"APClustering\".       requires  r-apcluster \n     r-factoextra      pHCluster    description \n    Do hierarchical clustering.    input      infile:file : The input files with variants as rows, features as columns.    NOTE: clustering is performed on rows, rownames are the leaf labels.       output      outdir:dir : The result directory, containing:    hclust.merge.txt : including merge and height information  hclust.order.txt : including order and labels information  hclust.png :       the dendrogram plot       args      fast : whether to use  fastcluster  package or not, default: False    gg : whether to use  ggdendro  or not, default: False    rownames : The  row.names  for  read.table  to read the input file, default: 1.    header : The  header  argument for  read.table  to read the input file, default: True.    method : Which method to use for  hclust . Default: \"complete\" (use  ?hclust  to check all availables)    rotate : Which to rotate the plot or not. Default: False    transpose : Whether to transpose the matrix before cluster. Default: False       requires  r-fastcluster  if  args.fast  is True\n     r-ggdendro  if  args.gg  is True", 
            "title": "cluster"
        }, 
        {
            "location": "/processes/#cnvkit", 
            "text": "pCNVkitAccess    description \n    Calculate the sequence-accessible coordinates in chromosomes from the given reference genome, output as a BED file.    input      fafile:file : The fasta file       output      outfile:file : The output file       args      params : Other parameters for  cnvkit.py access     cnvkit : The executable of cnvkit. Default: 'cnvkit.py'       requires  CNVkit      pCNVkitTarget    description \n    Generate targets file for CNVkit using access file and annotate file ( cnvkit.py target )    input      acfile:file : The access file    anfile:file : The annotate file       output      outfile:file : The targets file       args      cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    params : Other parameters for  cnvkit.py target        requires  CNVkit      pCNVkitCov    description \n    Calculate coverage in the given regions from BAM read depths.    input      infile:file : The bam file       output      outfile:file : The output cnn file       args      tgfile : The target file    cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    nthread : The number of threads to use. Default: 1    params : Other parameters for  cnvkit.py coverage        requires  CNVkit      pCNVkitRef    description \n    Compile a copy-number reference from the given files or directory (containing normal samples). If given a reference genome (-f option), also calculate the GC content and repeat-masked proportion of each region.    input      indir:file : The input directory containing the cnn files       output      outfile:file : The output reference cnn file       args      cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    params : Other parameters for  cnvkit.py reference , default: \" --no-edge \"       requires  CNVkit      pCNVkitFix    description \n    Combine the uncorrected target and antitarget coverage tables (.cnn) and correct for biases in regional coverage and GC content, according to the given reference. Output a table of copy number ratios (.cnr)    input      infile:file : The cnn file to be fixed    rcfile:file : The reference cnn file       output      outfile:file : The cnr file       args      cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    params : Other parameters for  cnvkit.py fix , default: \" --no-edge \"       requires  CNVkit      pCNVkitSeg    description \n    Infer discrete copy number segments from the given coverage table    input      infile:file : The cnr file        output      outfile:file : The cns file       args      cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    nthread : The number of threads to use. Default: 1    params : Other parameters for  cnvkit.py segment , default: \"\"       requires  CNVkit      pCNVkitCall    description \n    Given segmented log2 ratio estimates (.cns), derive each segment's absolute integer copy number     input      infile:file : The cns file        output      outfile:file : The callcns file       args      cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    params : Other parameters for  cnvkit.py segment , default: \"\"       requires  CNVkit      pCNVkitPlot    description \n    Plot CNVkit results    input      cnrdir:file : The directory containing copy number ratio files    cnsdir:file : The directory containing copy number segment files       output      outdir:dir : The output directory       args      cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    region : The region for zoom-in plots. Default: '' (don't plot zoom-in view)    gene : The genes to be highlighted. Default: ''    scatter : Whether to generate the scatter plot. Default: True    diagram : Whether to generate the diagram plot. Default: True    heatmap : Whether to generate the heatmap plot. Default: True       requires  CNVkit      pCNVkitRpt    description \n    Report CNVkit results    input      cnrfile:file : The file containing copy number ratio    cnsfile:file : The file containing copy number segment       output      outdir:dir : The output directory       args      cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    breaks : Whether to report breakpoints. Default: True    gainloss : Whether to report gainloss. Default: True    metrics : Whether to report metrics. Default: True    segmetrics : Whether to report segmetrics. Default: True       requires  CNVkit      pCNVkit2Vcf    description \n    Output vcf file for cnvkit results    input      cnsfile:file : The cns file       output      outfile:file : The vcf file       args      cnvkit : The executable of cnvkit. Default: 'cnvkit.py'    params : Other params for  cnvkit.py export        requires  CNVkit", 
            "title": "cnvkit"
        }, 
        {
            "location": "/processes/#common", 
            "text": "pSort    description \n    Sort file using linux command  sort    input      infile:file : The input file       output      outfile:file : The output file       args      skip : To skip first N lines. Default: 0    case : Case-sensitivity. Default: True    If True, will set $LANG as C  Otherwise, $LANG will be set as en_US.UTF-8    mem     : The buffer size. Default: 4G    tmpdir  : The tmpdir.    unique  : Just keep the unique lines. Default: False    delimit : The delimit to separate the fields. Default: '\\t'    params  : The arguments used by  sort          pFiles2Dir    description \n    A helper process to convert a list of files into a directory, so that some processes can take it as input    input      infiles:files : The input files       output      outdir:dir : The output directory         pFile2Proc    description \n    Convert a file to a proc so it can be used as dependent    input      infile:file : The input file       output      outfile:file : The output file         pStr2File    description \n    Save string to a file.    input      in:var : The input string.       output      outfile:file : The output file.         pHead    description \n    Get the top N lines from a file    input      infile:file : The input file       output      outfile:file : The output file       args      n : Top n lines. You may use '-n' to skip last n lines.         pTail    description \n    Get the bottom N lines from a file    input      infile:file : The input file       output      outfile:file : The output file       args      n : Bottom n lines. You may use '+n' to skip first n lines.         pPrepend    description \n    Prepend a string to a file    input      in:var : The input string.    infile:file : The input file.       output      outfile:file : The output file.         pAddHeader    description \n    Add the header of 1st file to 2nd file.    input      infile1:file : The first file containing the header.    infile2:file : The second file with the body.       output      outfile:file : The output file with the header from 1st input file, body from 2nd file.       args      n : The number of header lines.         pMergeFiles    description \n    Merge files in the input directory    input      indir:file : The input directory       output      outfile:file : The output file       args      inopts : The options for input file.    defaults: skip: 0, comment: #, delimit '\\t'    outopts : The options for output file. Defaults:    head: False (not output head line)  headPrefix:  #  (The prefix for head line)  headDelimit:  \\\\t  (The delimit for head line)  headTransform:  None  (The callback for head line)  delimit:  \\\\t  (The delimit for output line)         pSplitRows    description \n    Split a file by rows, specially usefull to split a job into multithreads/multiprocesses.    input      infile:file : The input file       output      outdir:dir : The output directory including the split files       args      skip : The skip first n lines. Default:  0     cnames : The column names. If True, the column names will be added to each split file. Default:  True     n : Number of files to split. Default:  8", 
            "title": "common"
        }, 
        {
            "location": "/processes/#eqtl", 
            "text": "pMatrixeQTL    description \n    Call eQTLs using Matrix eQTL    input      snpfile:file : The genotype file, rows are snps and columns are samples    expfile:file : The expression file, rows are genes    covfile:file : The covariant file, rows are covariants       output      outfile:file : The matrix eqtl output file       args      model : The model to use, either modelLINEAR(default) or modelANOVA    pval  : The pvalue cutoff (if  cisopts.dist    0, will be used as pval for trans-eQTL)    fdr   : Calculate FDR or not (default: True)    cisopts : Options for calling cis-, trans-eQTL    snppos  : The snp position file (columns are: snp, chr, pos)  genepos : The gene position file (columns are: gene, chr, start, end)  dist    : The distance to define cis-eQTL. (default: 0 (don't do cis-, trans- calling)  cispv   : The pvalue cutoff for cis-eQTL ( pval  will not work)       requires  Matrix-eQTL (R)", 
            "title": "eqtl"
        }, 
        {
            "location": "/processes/#fastx", 
            "text": "pFastq2Expr   description \n    Use Kallisto to get gene expression from pair-end fastq files.     pFastqSim    description \n    Simulate reads    input      seed : The seed to generate simulation file    None: use current timestamp.       output      fq1:file : The first pair read file    fq2:file : The second pair read file       args      tool : The tool used for simulation. Default: wgsim (dwgsim)    len1 : The length of first pair read. Default: 100    len2 : The length of second pair read. Default: 100    num : The number of read PAIRs. Default: 1000000    gz : Whether generate gzipped read file. Default: True    wgsim : The path of wgsim. Default: wgsim    dwgsim : The path of wgsim. Default: dwgsim    ref : The reference genome. Required    params : Other params for  tool . Default: \"\"       requires  wgsim      pFastQC    description \n    QC report for fastq file    input      fq:file : The fastq file (also fine with gzipped)       output      outdir:dir : The output direcotry       args      tool : The tool used for simulation. Default: fastqc    fastqc : The path of fastqc. Default: fastqc    nthread : Number of threads to use. Default: 1    params : Other params for  tool . Default: \"\"       requires  fastqc      pFastMC    description \n    Multi-QC based on pFastQC    input      qcdir:file : The direcotry containing QC files       output      outdir:dir : The output direcotry       args      tool : The tool used for simulation. Default: multiqc    multiqc : The path of fastqc. Default: multiqc    params : Other params for  tool . Default: \"\"       requires  multiqc      pFastqTrim    description \n    Trim pair-end FASTQ reads    input      fq1:file : The input fastq file    fq2:file : The input fastq file       output      outfq1:file : The trimmed fastq file    outfq2:file : The trimmed fastq file       args      tool         : The tools used for trimming. Default: trimmomatic (cutadapt|skewer)    cutadapt     : The path of seqtk. Default: cutadapt    skewer       : The path of fastx toolkit trimmer. Default: skewer    trimmomatic  : The path of trimmomatic. Default: trimmomatic    params       : Other params for  tool . Default: \"\"    nthread      : Number of threads to be used. Default: 1    Not for cutadapt  gz           : Whether gzip output files. Default: True    mem          : The memory to be used. Default: 4G    Only for trimmomatic  minlen       : Discard trimmed reads that are shorter than  minlen . Default: 18    For trimmomatic, the number will be  minlen *2 for MINLEN, as it filters before trimming  minq         : Minimal mean qulity for 4-base window or leading/tailing reads. Default: 3    cut5         : Remove the 5'end reads if they are below qulity. Default: 3    cut3         : Remove the 3'end reads if they are below qulity. Default: 3    Not for skewer  adapter1     : The adapter for sequence. Default: AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC    adapter2     : The adapter for pair-end sequence. Default: AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA       requires  cutadapt \n     skewer \n     trimmomatic      pFastqSETrim    description \n    Trim single-end FASTQ reads    input      fq:file : The input fastq file       output      outfq:file : The trimmed fastq file       args      tool         : The tools used for trimming. Default: trimmomatic (cutadapt|skewer)    cutadapt     : The path of seqtk. Default: cutadapt    skewer       : The path of fastx toolkit trimmer. Default: skewer    trimmomatic  : The path of trimmomatic. Default: trimmomatic    params       : Other params for  tool . Default: \"\"    nthread      : Number of threads to be used. Default: 1    Not for cutadapt  gz           : Whether gzip output files. Default: True    mem          : The memory to be used. Default: 4G    Only for trimmomatic  minlen       : Discard trimmed reads that are shorter than  minlen . Default: 18    For trimmomatic, the number will be  minlen *2 for MINLEN, as it filters before trimming  minq         : Minimal mean qulity for 4-base window or leading/tailing reads. Default: 3    cut5         : Remove the 5'end reads if they are below qulity. Default: 3    cut3         : Remove the 3'end reads if they are below qulity. Default: 3    Not for skewer  adapter      : The adapter for sequence. Default: AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC       requires  cutadapt \n     skewer \n     trimmomatic      pFastqSE2Sam    description \n    Cleaned paired fastq (.fq, .fq.gz, .fastq, .fastq.gz file to mapped sam/bam file    args      tool : The tool used for alignment. Default: bwa (bowtie2|ngm)    bwa : Path of bwa, default: bwa    ngm : Path of ngm, default: ngm    bowtie2 : Path of bowtie2, default: bowtie2    rg : The read group. Default: {'id': '', 'pl': 'Illumina', 'pu': 'unit1', 'lb': 'lib1', 'sm': ''}    id  will be parsed from filename with \" LX \" in it if not given  sm  will be parsed from filename  ref : Path of reference file    params : Other params for tool, default: ''         pFastq2Sam    description \n    Cleaned paired fastq (.fq, .fq.gz, .fastq, .fastq.gz file to mapped sam/bam file    args      tool    : The tool used for alignment. Default: bwa (bowtie2, ngm, star)    bwa     : Path of bwa, default: bwa    ngm     : Path of ngm, default: ngm    star    : Path of ngm, default: STAR    bowtie2 : Path of bowtie2, default: bowtie2    rg : The read group. Default: {'id': '', 'pl': 'Illumina', 'pu': 'unit1', 'lb': 'lib1', 'sm': ''}    id  will be parsed from filename with \" LX \" in it if not given  sm  will be parsed from filename  ref     : Path of reference file    refgene : The GTF file for STAR to build index. It's not neccessary if index is already been built. Default: ''    params  : Other params for tool, default: ''", 
            "title": "fastx"
        }, 
        {
            "location": "/processes/#gatk", 
            "text": "pRealignerTargetCreator    description \n    The local realignment process is designed to consume one or more BAM files and to locally realign reads such that the number of mismatching bases is minimized across all the reads. In general, a large percent of regions requiring local realignment are due to the presence of an insertion or deletion (indels) in the individual's genome with respect to the reference genome. Such alignment artifacts result in many bases mismatching the reference near the misalignment, which are easily mistaken as SNPs. Moreover, since read mapping algorithms operate on each read independently, it is impossible to place reads on the reference genome such that mismatches are minimized across all reads. Consequently, even when some reads are correctly mapped with indels, reads covering the indel near just the start or end of the read are often incorrectly mapped with respect the true indel, also requiring realignment. Local realignment serves to transform regions with misalignments due to indels into clean reads containing a consensus indel suitable for standard variant discovery approaches.\n    Note that indel realignment is no longer necessary for variant discovery if you plan to use a variant caller that performs a haplotype assembly step, such as HaplotypeCaller or MuTect2. However it is still required when using legacy callers such as UnifiedGenotyper or the original MuTect. There are 2 steps to the realignment process:   Determining (small) suspicious intervals which are likely in need of realignment (RealignerTargetCreator)  Running the realigner over those intervals (see the IndelRealigner tool)\nFor more details, see  the indel realignment method documentation .     input      bamfile:file : The aligned bam file    reffile : The reference file       brings      bamfile :  {{bamfile | bn}}.bai  The index file of input bam file    reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : A list of target intervals to pass to the IndelRealigner.       args      gatk : The gatk executable, default: \"gatk\"    picard : The picard executable, default: \"picard\"    params : Other parameters for RealignerTargetCreator, default: \"\"    samtools : The samtools executable, default: \"samtools\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  GATK \n     samtools  if  reffile  is not indexed or  bamfile  is not indexed.\n     picard  if  reffile  is not dicted.      pIndelRealigner    description \n    The local realignment process is designed to consume one or more BAM files and to locally realign reads such that the number of mismatching bases is minimized across all the reads. In general, a large percent of regions requiring local realignment are due to the presence of an insertion or deletion (indels) in the individual's genome with respect to the reference genome. Such alignment artifacts result in many bases mismatching the reference near the misalignment, which are easily mistaken as SNPs. Moreover, since read mapping algorithms operate on each read independently, it is impossible to place reads on the reference genome such at mismatches are minimized across all reads. Consequently, even when some reads are correctly mapped with indels, reads covering the indel near just the start or end of the read are often incorrectly mapped with respect the true indel, also requiring realignment. Local realignment serves to transform regions with misalignments due to indels into clean reads containing a consensus indel suitable for standard variant discovery approaches.\n    Note that indel realignment is no longer necessary for variant discovery if you plan to use a variant caller that performs a haplotype assembly step, such as HaplotypeCaller or MuTect2. However it is still required when using legacy callers such as UnifiedGenotyper or the original MuTect.\n    There are 2 steps to the realignment process:   Determining (small) suspicious intervals which are likely in need of realignment (see the RealignerTargetCreator tool)  Running the realigner over those intervals (IndelRealigner)\nFor more details, see  the indel realignment method documentation .     input      bamfile:file : The aligned bam file    intfile:file : Intervals file output from RealignerTargetCreator    reffile:file : The reference file       brings      bamfile :  {{bamfile | bn}}.bai  The index file of input bam file    reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : A realigned version of input BAM file.       args      gatk : The gatk executable, default: \"gatk\"    picard : The picard executable, default: \"picard\"    params : Other parameters for IndelRealigner, default: \"\"    samtools : The samtools executable, default: samtools    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  GATK \n     samtools  if  reffile  is not indexed or  bamfile  is not indexed.\n     picard  if  reffile  is not dicted.      pBaseRecalibrator    description \n    Variant calling algorithms rely heavily on the quality scores assigned to the individual base calls in each sequence read. These scores are per-base estimates of error emitted by the sequencing machines. Unfortunately the scores produced by the machines are subject to various sources of systematic technical error, leading to over- or under-estimated base quality scores in the data. Base quality score recalibration (BQSR) is a process in which we apply machine learning to model these errors empirically and adjust the quality scores accordingly. This allows us to get more accurate base qualities, which in turn improves the accuracy of our variant calls. The base recalibration process involves two key steps: first the program builds a model of covariation based on the data and a set of known variants (which you can bootstrap if there is none available for your organism), then it adjusts the base quality scores in the data based on the model. There is an optional but highly recommended step that involves building a second model and generating before/after plots to visualize the effects of the recalibration process. This is useful for quality control purposes. This tool performs the first step described above: it builds the model of covariation and produces the recalibration table. It operates only at sites that are not in dbSNP; we assume that all reference mismatches we see are therefore errors and indicative of poor base quality. This tool generates tables based on various user-specified covariates (such as read group, reported quality score, cycle, and context). Assuming we are working with a large amount of data, we can then calculate an empirical probability of error given the particular covariates seen at this site, where p(error) = num mismatches / num observations. The output file is a table (of the several covariate values, number of observations, number of mismatches, empirical quality score).    input      bamfile:file : A BAM file containing data that needs to be recalibrated.    reffile:file : The reference file       brings      bamfile :  {{bamfile | bn}}.bai  The index file of input bam file    reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : A GATKReport file with many tables:    The list of arguments  The quantized qualities table  The recalibration table by read group  The recalibration table by quality score  The recalibration table for all the optional covariates       args      gatk : The gatk executable, default: \"gatk\"    params : Other parameters for BaseRecalibrator, default: \"\"    knownSites : The known polymorphic sites to mask out, required    samtools : The samtools executable, default: samtools    picard : The picard executable, default: \"picard\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  GATK \n     samtools  if  reffile  is not indexed or  bamfile  is not indexed.\n     picard  if  reffile  is not dicted.      pPrintReads    description \n    PrintReads is a generic utility tool for manipulating sequencing data in SAM/BAM format. It can dynamically merge the contents of multiple input BAM files, resulting in merged output sorted in coordinate order. It can also optionally filter reads based on various read properties such as read group tags using the  --read_filter/-rf  command line argument (see documentation on read filters for more information).\n    Note that when PrintReads is used as part of the Base Quality Score Recalibration workflow, it takes the  --BQSR  engine argument, which is listed under Inherited Arguments   CommandLineGATK below.    input      bamfile:file : A BAM file.    recaltable:file : The GATKReport file    reffile:file : The reference file       brings      bamfile :  {{bamfile | bn}}.bai  The index file of input bam file    reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : A single processed bam file.       args      gatk : The gatk executable, default: \"gatk\"    params : Other parameters for PrintReads, default: \"\"    samtools : The samtools executable, default: samtools    picard : The picard executable, default: \"picard\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  GATK \n     samtools  if  reffile  is not indexed or  infile  is not indexed.\n     picard  if  reffile  is not dicted.      pHaplotypeCaller    description \n    PrintReads is a generic utility tool for manipulating sequencing data in SAM/BAM format. It can dynamically merge the contents of multiple input BAM files, resulting in merged output sorted in coordinate order. It can also optionally filter reads based on various read properties such as read group tags using the  --read_filter/-rf  command line argument (see documentation on read filters for more information).\n    Note that when PrintReads is used as part of the Base Quality Score Recalibration workflow, it takes the  --BQSR  engine argument, which is listed under Inherited Arguments   CommandLineGATK below.    input      bamfile:file : A BAM file.    reffile:file : The reference file       brings      bamfile :  {{bamfile | bn}}.bai  The index file of input bam file    reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : Either a VCF or gVCF file with raw, unfiltered SNP and indel calls.       args      gatk     : The gatk executable, default: \"gatk\"    params   : Other parameters for HaplotypeCaller, default: \"\"    samtools : The samtools executable, default: samtools    picard : The picard executable, default: \"picard\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"    nthread : Corresponding to -nct option       requires  GATK \n     samtools  if  reffile  is not indexed or  infile  is not indexed.\n     picard  if  reffile  is not dicted.      pSelectVariants    description \n    Often, a VCF containing many samples and/or variants will need to be subset in order to facilitate certain analyses (e.g. comparing and contrasting cases vs. controls; extracting variant or non-variant loci that meet certain requirements, displaying just a few samples in a browser like IGV, etc.). SelectVariants can be used for this purpose.\n    There are many different options for selecting subsets of variants from a larger callset:   Extract one or more samples from a callset based on either a complete sample name or a pattern match.  Specify criteria for inclusion that place thresholds on annotation values, e.g. \"DP   1000\" (depth of coverage greater than 1000x), \"AF   0.25\" (sites with allele frequency less than 0.25). These - criteria are written as \"JEXL expressions\", which are documented in the article about using JEXL expressions.  Provide concordance or discordance tracks in order to include or exclude variants that are also present in other given callsets.  Select variants based on criteria like their type (e.g. INDELs only), evidence of mendelian violation, filtering status, allelicity, and so on.\nThere are also several options for recording the original values of certain annotations that are recalculated when a subsetting the new callset, trimming alleles, and so on.     input      vcffile:file : A variant call set from which to select a subset.    reffile:file : The reference file       brings      reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : A new VCF file containing the selected subset of variants.       args      gatk : The gatk executable, default: \"gatk\"    params : Other parameters for SelectVariants, default: \"\"    samtools : The samtools executable, default: samtools    picard : The picard executable, default: \"picard\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  GATK \n     samtools  if  reffile  is not indexed or  infile  is not indexed.\n     picard  if  reffile  is not dicted.      pVariantFiltration    description \n    This tool is designed for hard-filtering variant calls based on certain criteria. Records are hard-filtered by changing the value in the FILTER field to something other than PASS. Filtered records will be preserved in the output unless their removal is requested in the command line.\n    The most common way of specifying filtering criteria is by using JEXL queries. See the article on JEXL expressions in the documentation Guide for detailed information and examples.    input      vcffile:file : A variant call set from which to select a subset.    reffile:file : The reference file       brings      reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : A filtered VCF.       args      gatk : The gatk executable, default: \"gatk -T VariantFiltration\"    params : Other parameters for VariantFiltration, default: \"\"    samtools : The samtools executable, default: samtools    picard : The picard executable, default: \"picard\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  GATK \n     samtools  if  reffile  is not indexed or  infile  is not indexed.\n     picard  if  reffile  is not dicted.      pMuTect2    description \n    MuTect2 is a somatic SNP and indel caller that combines the DREAM challenge-winning somatic genotyping engine of the original MuTect ( Cibulskis et al., 2013 ) with the assembly-based machinery of HaplotypeCaller. The basic operation of MuTect2 proceeds similarly to that of the HaplotypeCaller.\n    NOTE: only Tumor/Normal variant calling implemented in bioprocs    input      tumor:file : the tumor bam file    normal:file : the normal bam file    reffile:file : the reference file       brings      tumor :  {{tumor | bn}}.bai  the index file of tumor    normal :  {{normal | bn}}.bai  the index file of normal    reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : The vcf file containing somatic mutations       args      gatk : The gatk executable, default: \"gatk\"    samtools : The samtools executable, default: samtools    params : Other parameters for MuTect2, default: \"\"    picard : The picard executable, default: \"picard\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  GATK \n     samtools  if index files of input files are not found\n     picard  if  reffile  is not dicted.      pMuTect2Interval    description \n    Use interval file model of MuTect2    input      tumor:file : the tumor bam file    normal:file : the normal bam file    reffile:file : the reference file       brings      tumor :  {{tumor | bn}}.bai  the index file of tumor    normal :  {{normal | bn}}.bai  the index file of normal    reffile#fai :  {{reffile | bn}}.fai     reffile#dict :  {{reffile | bn}}.dict        output      outfile:file : The vcf file containing somatic mutations       args      gatk : The gatk executable, default: \"gatk\"    samtools : The samtools executable, default: samtools    params : Other parameters for MuTect2, default: \"\"    picard : The picard executable, default: \"picard\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  GATK \n     samtools  if index files of input files are not found\n     picard  if  reffile  is not dicted.", 
            "title": "gatk"
        }, 
        {
            "location": "/processes/#gene", 
            "text": "pGenePromoters   description \n    Alias of  seq.pPromoters .     pGeneNameNorm    description \n    Normalize gene names using MyGeneinfo.    input      infile:file : The input file       output      outfile:file : The output file       args      notfound : What if a symbol is not found. Default: ignore    skip  : skip the record(don't write it to output file)  ignore: use the original name;  error : report error    col : the column index containing the gene names    from : the original format. Default: 'symbol, alias'    to : the output gene name format. Default: 'symbol'    genome : the genome. Default: 'hg19'         pGeneTss    description \n    Get gene TSS in BEd format.    input      infile:file : The input file containing genes       output      outfile:file : The output BED file       args      notfound : What if the gene is not found. Default: skip.    error: report error    header : Whether the input file contains header. Default: False    skip : Skip N lines of input file. Default: 0    This has highest priority of header and comment    comment : The comment line start sign. Default: #    delimit : The delimit of input file if it has multiple column. Default:  \\\\t     col : The column index contains the genes. Default: 0    frm : The format of the genes. Default:  symbol, alias     tmpdir : The tmpdir used to store mygene cache files.    genome : In which genome to fetch the coordinates. Default: hg19         pGeneBody    description \n    Get gene body region in BED format    input      infile:file : The input file containing genes       output      outfile:file : The gene body region       args      notfound : What if a gene is not found when transfer the gene names to gene symbols    error: report error  skip (default): skip it    inmeta : The metadata for input file, mainly to indicate where the GENE column is.    inopts : Input options for reading input file.    skip: number of lines to skip. Default: 0  comment: the starting string for comment lines. Default: #  delimit: The delimit for the input file. Default: '\\t'\nfrm: The gene name format in the input file. Default: 'symbol, alias'\ntmpdir: The tmpdir to cache the gene name conversion.\ngenome: The genome used to do the conversion.", 
            "title": "gene"
        }, 
        {
            "location": "/processes/#genomeplot", 
            "text": "pInteractionTrack    description \n    Gererate genomic interaction track for Gviz    input      name : The name of the track    infile:file : The input file.     See the  type  argument for  makeGenomicInteractionsFromFile  from  GenomicInteractions  r-package    region : the region, just chromosome!       output      outfile:file : The dumped track data       args      intype : Input file type. Default: auto    Identified by extension  One of \"chiapet.tool\", \"bed12\", \"bedpe\", \"hiclib\", \"homer\", \"bam\", \"two.bams\".    params : The display params         pGeneTrack    description \n    Generate gene track using ucsc data source    input      name : The name of the track       output      outfile:file : The file to save the track       args      genome : The genome    params : use  displayPars(UcscTrack(genome=\"mm9\", chromosome=\"chrM\", track=\"knownGene\"))  to see all available args       requires  r-Gviz      pAnnoTrack    description \n    The annotation track of Gviz    input      name : the name of the track    infile:file : the file for the track. (wig, bigWig or bedGraph, bam, need to be indexed!)    chrom : the chrom       output      outfile:file : the rds file for the track       args      genome : The genome    params : See  displayPars(DataTrack())  for all available display params       requires  r-Gviz      pDataTrack    description \n    The data track of Gviz    input      name : the name of the track    infile:file : the file for the track. (wig, bigWig or bedGraph, bam, need to be indexed!)    chrom : the chrom       output      outfile:file : the rds file for the track       args      genome : The genome    params : See  displayPars(DataTrack())  for all available display params       requires  r-Gviz      pUcscTrack    description \n    Generate track from ucsc    input      name      : the name of the track    track     : the UCSC track    trackType : the Gviz track    region    : the region       output      outfile:file : the dumped track       args      params : use  displayPars(UcscTrack(genome=\"mm9\", chromosome=\"chrM\", track=\"knownGene\"))  to see all available args.       requires  r-Gviz      pGenomePlot    description \n    plot the genomic features    input      trkfiles:files : the list of track dumped files    region : the region, in format of  chr1:1-1000     highlight : the highlight regions, informat of start1-end1; start2-end2; ...       output      outfile:file : the figure       args      genome   : The genome    showIdeo : Show ideogram track? Default: True    showAxis : Show axis? Default: True    showGenes : Show geneTrack? Default: True    params : The params    genneral :  General params for plotTracks  geneTrack : The params for geneTrack       requires  r-Gviz", 
            "title": "genomeplot"
        }, 
        {
            "location": "/processes/#gsea", 
            "text": "pGMT2Mat    description \n    Convert a GMT file to a matrix.\n    Rownames of GMT file will be the column names of output matrix.    input      infile:file : The input file in GMT format.       output      outfile:file : output matrix file         pExpmat2Gct    description \n    Convert expression matrix to GCT file.\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GCT for file format    input      expfile:file : the input expression matrix file. Samples as columns, genes as rows.       output      outfile:file : the gct file         pSampleinfo2Cls    description \n    Convert sample infomation to cls file.\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#CLS for file format\n    NOTE that the order of samples must be the same as in GMT file in further analysis.    input      sifile:file : the sample information file.    Headers are: [Sample, ]Patient, Group, Batch  Rows are samples       output      outfile:file : the cls file         pSSGSEA    description \n    Single sample GSEA\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GCT for GCT file format\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GMT for GMT file format    input      gctfile:file : the expression file    gmtfile:file : the gmtfile for gene sets       output      outdir:file : the output directory    report.txt : the enrichment report for each Gene set.  RES_ GeneSet .png : the running ES plot for   normP_ GeneSet .png : the norminal P value plot for      args      weightexp : Exponential weight employed in calculation of enrichment scores. Default: 0.75    nperm : Number of permutations. Default: 10000         pGSEA    description \n    GSEA\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GCT for GCT file format\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#GMT for GMT file format\n    Refer to http://software.broadinstitute.org/cancer/software/genepattern/file-formats-guide#CLS for CLS file format    input      gctfile:file : the expression file    clsfile:file : the class file    gmtfile:file : the gmtfile for gene sets       output      outdir:file : the output directory       args      weightexp : Exponential weight employed in calculation of enrichment scores. Default: 0.75    nperm : Number of permutations. Default: 10000         pEnrichr    description \n    Use APIs from http://amp.pharm.mssm.edu/Enrichr/help#api q=1 to analyze a gene list    input      infile:file : The gene list, each per line       output      outdir:dir : The output directory, containing the tables and figures.       args      topn : Top N pathways used to plot. Default: 10    col : The columns index containing the genes. Default: 0    delimit : The delimit of input file. Default: '\\t'    dbs : The databases to do enrichment against. Default: KEGG_2016    A full list can be found here: http://amp.pharm.mssm.edu/Enrichr/#stats  Multiple dbs separated by comma (,)  norm : Normalize the gene list use  python-mygene     rmtags : Remove pathway tags in the plot. Default: True    For example: change \"Lysine degradation_Homo sapiens_hsa00310\" to \"Lysine degradation\".  plot : Whether to plot the result. Default: True    title : The title for the plot. Default: \"Gene enrichment: {db}\"       requires  python-mygene  if  args.norm  is  True      pTargetEnrichr    description \n    Use APIs from http://amp.pharm.mssm.edu/Enrichr/help#api q=1 to analyze a gene list    input      infile:file : The target genes with regulators    Format:  Header is not required, but may specified in first line starting with  #  If only 3 columns are there, the 3rd column is anyway the relation!  If only 4 columns are there, 3rd is target status, 4th is relation!\n   #Regulator\tTarget\tRegulator status\tTarget status\tRelation\nhas-mir-22\tGene\t+\t+\t+       output      outdir:dir : The output directory, containing the tables and figures.       args      dbs        : The databases to do enrichment against. Default: KEGG_2016    A full list can be found here: http://amp.pharm.mssm.edu/Enrichr/#stats  Multiple dbs separated by comma (,)  rmtags     : Remove pathway tags in the plot. Default: True    For example: change \"Lysine degradation_Homo sapiens_hsa00310\" to \"Lysine degradation\".  enrplot    : Whether to plot the result. Default: True    enrn       : Top N pathways used to plot. Default: 10    netplot    : Whether to plot the network. Default: True    netn       : Top N pathways used to plot the network. Default: 5    Must  =  enrn . If  netn   =  enrn ,  netn  =  enrn    title      : The title for the plot. Default: \"Gene enrichment: {db}\"       requires  python-mygene \n     graphviz", 
            "title": "gsea"
        }, 
        {
            "location": "/processes/#hic", 
            "text": "", 
            "title": "hic"
        }, 
        {
            "location": "/processes/#marray", 
            "text": "pCELdir2Matrix    description \n    Convert CEL files to expression matrix\n    File names will be used as sample names (colnames)    input      indir:file : the directory containing the CEL files, could be gzipped    If you have files, then use  pFiles2Dir  first       output      outfile:file : the expression matrix file    outdir:dir : the directory containing expr file and plots       args      pattern   : The pattern to filter files. Default  '*'     norm      : The normalization method. Default: rma (mas5)    gfile     : The group file. Default: ''    cdffile   : The cdffile. Default: ''    annofile  : The annotation file. Default: ''    hmrows    : How many rows to be used to plot heatmap    plot : Whether to plot    boxplot    : Whether to plot a boxplot. Default: False  heatmap    : Whether to plot a heatmap. Default: False  histogram  : Whether to plot a histgram. Default: False    devpars     : Parameters for png. Default:  {'res': 300, 'width': 2000, 'height': 2000}     ggs : The ggplot parameters    boxplot   : The ggplot parameters for boxplot. Default:  Box(ylab = {0: \"Log2 Intensity\"})  heatmap   : The ggplot parameters for heatmap. Default:  Box(theme = {'axis.text.y': 'r:element_blank()'})  histogram : The ggplot parameters for histgram. Default:  Box(labs = {'x': \"Log2 Intensity\", \"y\": \"Density\"})", 
            "title": "marray"
        }, 
        {
            "location": "/processes/#misc", 
            "text": "pGEP70    description \n    Calculate GEP70 scores for multiple mylenoma 70-gene-signatures    input      infile:file : The input file with expression matrix    Columns are samples, rows are genes       output      outfile:file : The output files with gep70 scores for each sample.    Samples become rows, just one column is in the file.       args      inopts : The input options.    cnames : Whether the input file has column names. Default:  True    gep70 : The GEP70 genes.     Column 1: up-regulated genes (51)  Column 2: down-regulated genes (19)", 
            "title": "misc"
        }, 
        {
            "location": "/processes/#pca", 
            "text": "pPCA    description \n    Perform PCA analysis    input      infile:file : The matrix to do the analysis    Note that rows are samples, columns are features, if not, use  args.transpose = True     output      outfile:file : The output coordinate file    Columns are PCs, rows are samples     args      transpose : Whether to transpose the input matrix from infile. Default: False    rownames : The  row.names  argument for  read.table , default: 1    header : The  header  argument for  read.table  to read the input file, default: True.    screeplot : Whether to generate the screeplot or not. Default: True    sp_ncp : Number of components in screeplot. Default: 0 (auto detect)    if total # components (tcp)   20: use all  else if tcp   20, use 20  varplot : Whether to generate the variable plot or not. Default: False    biplot : Whether to generate the variable plot or not. Default: True       requires  r-factoextra  for plots      pSelectPCs    description \n    Select a subset of PCs from pPCA results    input      indir:file : The directory generated from pPCA       output      outfile:file : The file containing selected PCs       args      n : The number of PCs to select. Default: 0.9    If it is   1, used as the % variation explained from stdev.txt", 
            "title": "pca"
        }, 
        {
            "location": "/processes/#picard", 
            "text": "pMarkDuplicates    description \n    Identifies duplicate reads.  This tool locates and tags duplicate reads in a BAM or SAM file, where duplicate reads are defined as originating from a single fragment of DNA. Duplicates can arise during sample preparation e.g. library construction using PCR. See also EstimateLibraryComplexity for additional notes on PCR duplication artifacts. Duplicate reads can also result from a single amplification cluster, incorrectly detected as multiple clusters by the optical sensor of the sequencing instrument. These duplication artifacts are referred to as optical duplicates.  The MarkDuplicates tool works by comparing sequences in the 5 prime positions of both reads and read-pairs in a SAM/BAM file. An BARCODE_TAG option is available to facilitate duplicate marking using molecular barcodes. After duplicate reads are collected, the tool differentiates the primary and duplicate reads using an algorithm that ranks reads by the sums of their base-quality scores (default method).  The tool's main output is a new SAM or BAM file, in which duplicates have been identified in the SAM flags field for each read. Duplicates are marked with the hexadecimal value of 0x0400, which corresponds to a decimal value of 1024. If you are not familiar with this type of annotation, please see the following  blog post  for additional information.  Although the bitwise flag annotation indicates whether a read was marked as a duplicate, it does not identify the type of duplicate. To do this, a new tag called the duplicate type (DT) tag was recently added as an optional output in the 'optional field' section of a SAM/BAM file. Invoking the TAGGING_POLICY option, you can instruct the program to mark all the duplicates (All), only the optical duplicates (OpticalOnly), or no duplicates (DontTag). The records within the output of a SAM/BAM file will have values for the 'DT' tag (depending on the invoked TAGGING_POLICY), as either library/PCR-generated duplicates (LB), or sequencing-platform artifact duplicates (SQ). This tool uses the READ_NAME_REGEX and the OPTICAL_DUPLICATE_PIXEL_DISTANCE options as the primary methods to identify and differentiate duplicate types. Set READ_NAME_REGEX to null to skip optical duplicate detection, e.g. for RNA-seq or other data where duplicate sets are extremely large and estimating library complexity is not an aim. Note that without optical duplicate counts, library size estimation will be inaccurate.  MarkDuplicates also produces a metrics file indicating the numbers of duplicates for both single- and paired-end reads.  The program can take either coordinate-sorted or query-sorted inputs, however the behavior is slightly different. When the input is coordinate-sorted, unmapped mates of mapped records and supplementary/secondary alignments are not marked as duplicates. However, when the input is query-sorted (actually query-grouped), then unmapped mates and secondary/supplementary reads are not excluded from the duplication test and can be marked as duplicate reads.  If desired, duplicates can be removed using the REMOVE_DUPLICATE and REMOVE_SEQUENCING_DUPLICATES options.    input      infile:file : The bam file        output      outfile:file : The marked bam file       args      picard : The picard executable, default: \"picard\"    params : Other parameters for picard MarkDuplicates, default: \"\"    tmpdir : The tmpdir to use. Default: /tmp       requires  picard      pAddOrReplaceReadGroups    description \n    Replace read groups in a BAM file.This tool enables the user to replace all read groups in the INPUT file with a single new read group and assign all reads to this read group in the OUTPUT BAM file.  For more information about read groups, see the  GATK Dictionary entry .   This tool accepts INPUT BAM and SAM files or URLs from the Global Alliance for Genomics and Health (GA4GH) (see http://ga4gh.org/#/documentation).    input      infile:file : The bam file    rg : The read group information. For example:    \"RGID=4 RGLB=lib1 RGPL=illumina RGPU=unit1 RGSM=20\"       output      outfile:file : The bam file with read group added       args      picard : The picard executable, default: \"picard \"    params : Other parameters for picard AddOrReplaceReadGroups, default: \"\"       requires  picard      pCreateSequenceDictionary    description \n    Creates a sequence dictionary for a reference sequence. This tool creates a sequence dictionary file (with \".dict\" extension) from a reference sequence provided in FASTA format, which is required by many processing and analysis tools. The output file contains a header but no SAMRecords, and the header contains only sequence records.  The reference sequence can be gzipped (both .fasta and .fasta.gz are supported).    input      infile:file : The fasta file        output      outfile:file : The same fasta file, but with dict file created       args      picard : The picard executable, default: \"picard\"    params : Other parameters for picard CreateSequenceDictionary, default: \"\"       requires  picard      pCollectWgsMetrics    description \n    Collect metrics about coverage and performance of whole genome sequencing (WGS) experiments.  This tool collects metrics about the fractions of reads that pass base- and mapping-quality filters as well as coverage (read-depth) levels for WGS analyses. Both minimum base- and mapping-quality values as well as the maximum read depths (coverage cap) are user defined.  Note: Metrics labeled as percentages are actually expressed as fractions!    input      infile:file : The bam file        output      outfile:file : The metrics file       args      picard : The picard executable, default: \"picard\"    params : Other parameters for  picard CollectWgsMetrics , default: \"\"    reffile : The reference file, default: \"\"       requires  picard      pSortSam    description \n    Use  picard SortSam  to sort sam or bam file    input      infile:file : The sam or bam file to be sorted       output      outfile:file : The sorted sam or bam file       args      picard : The picard executable, default: \"picard\"    order : The sort order, default: coordinate. Possible: unsorted, queryname, coordinate, duplicate    outtype : The type of output file, sam or bam. Default: bam    params : Other parameters for  picard SortSam , default: \"\"    tmpdir : The tmpdir to use. Default: /tmp    javamem : The memory for java vm. Default: \"-Xms1g -Xmx8g\"       requires  picard      pIndexBam    description \n    Use  picard BuildBamIndex  to index bam file    input      infile:file : The bam file        output      outfile:file : The same bam file (link) but with .bai file in  proc.outdir        args      picard : The picard executable, default: \"picard\"    params : Other parameters for  picard BuildBamIndex , default: \"-Xms1g -Xmx8g\"       requires  picard", 
            "title": "picard"
        }, 
        {
            "location": "/processes/#plot", 
            "text": "pPlot    description \n    Use ggplot2 to generate plots    input      infile:file : The input data file       output      outfile:file : The output file       args      cnames  : Whether the input file has colnames. Default: True    rnames  : Whether the input file has rownames. Default: False    aes     : The default aes. Default: {'x':1, 'y':2} (corresponding to colnames)    helper  : Some helper codes to generate  params  and  ggs     devpars : The device parameters. Default:  Box(res = 300, height = 2000, width = 2000)     ggs     : The extra ggplot elements.         pScatter    description \n    Use ggplot2 geom_point to generate plots    infile      infile:file : The input data file       outfile      outfile:file : The output file       args      cnames  : Whether the input file has colnames. Default: True    rnames  : Whether the input file has rownames. Default: False    x       : The x aes. Default: 1 (corresponding to colnames)    y       : The y aes. Default: 2 (corresponding to colnames)    helper  : Some helper codes to generate  params  and  ggs     devpars : The device parameters. Default:  Box(res = 300, height = 2000, width = 2000)     params  : The extra params for  geom_point     ggs     : The extra ggplot elements.         pPoints   description \n    Alias for pScatter     pHisto    description \n    Use ggplot2 geom_histogram to generate histograms    infile      infile:file : The input data file       outfile      outfile:file : The output file       args      cnames  : Whether the input file has colnames. Default: True    rnames  : Whether the input file has rownames. Default: False    x       : The x aes. Default: 1 (corresponding to colnames)    helper  : Some helper codes to generate  params  and  ggs     devpars : The device parameters. Default:  Box(res = 300, height = 2000, width = 2000)     params  : The extra params for  geom_point     ggs     : The extra ggplot elements.         pFreqpoly    description \n    Use ggplot2 geom_freqpoly to generate frequency polygon plot.    infile      infile:file : The input data file       outfile      outfile:file : The output file       args      cnames  : Whether the input file has colnames. Default: True    rnames  : Whether the input file has rownames. Default: False    x       : The x aes. Default: 1 (corresponding to colnames)    helper  : Some helper codes to generate  params  and  ggs     devpars : The device parameters. Default:  Box(res = 300, height = 2000, width = 2000)     params  : The extra params for  geom_point     ggs     : The extra ggplot elements.         pBoxplot    description \n    Generate box plot    input      datafile:file : The data file       output      outpng:file : The output figure       args      inopts  : Input options to read the input file    cnames  :   Whether the input file has header. Default:  True  rnames  :   Whether the input file has row names. Default:  False  delimit :   The seperator. Defualt:  \\\\t    x       : The  ind  (index) column. Only for  args.stacked = True . Default:  2     y       : The  values  column. Only for  args.stacked = True . Default:  1     helper  : Some raw codes to help to construct the matrix and arguments.    stacked : Whether the input file is stacked    Stacked file looks like:\n   values\tind\n1.1\tcol1\n1.2\tcol1\n...\n.8\tcol2\n.9\tcol2\n...\n3.2\tcol3\n...  Unstacked file looks like:\n   col1\tcol2\tcol3\n1.1\t.8\t3.2\n1.2\t.9\t2.2    params : Other parameters for  boxplot , default:  \"\"     ggs    : Extra ggplot2 statements         pHeatmap    description \n    Plot heatmaps.    input      infile:file : The input matrix file       output      outfile:file : The heatmap       args      ggs : The ggplot items for heatmap    devpars : The parameters for device. Default:  {'res': 300, 'height': 2000, 'width': 2000}     dendro : The parameters for control of the dendrogram. Default:  {'dendro': True}     dendro :  True : plot dendros for both rows and cols;  col : only plot dendro for cols;  row : only plot dendro for rows  rows : The rownames to subset the rows and control the order of rows. Must a list. Only works when not plotting dendro for rows.  cols : The colnames to subset the cols and control the order of cols. Must a list. Only works when not plotting dendro for cols.    header : The input file has header? Default: True    rownames : The input file has rownames? Default: 1    rows : Row selector    all : All rows  top:N : Top N rows (original data ordered in descending order). N defaults to 100  bottom:N : Bottom N rows. N defaults to 100  both:N : Top N rows and bottom N rows. N defaults to 50  random:N : Random N rows. N defaults to 50  random-both:N : Random N rows from top part and N rows from bottom part. N defaults to 50    cols : Col selector (see  rows ).         pScatterCompare    description \n    Plot scatter plot to compare values of first 2 columns of input data    input      infile:file : The input file containing a matrix with at least 2 columns    Other columns are groups used to group the scatter points  Data must be normalized to [0, 1]       output      outfile:file : The output plot       args      ggs : Extra expressions for ggplot. Note if geom_point is included, original geom_point will be ignored.    devpars : The parameters for plot device. Default:  {'res': 300, 'height': 2000, 'width': 2000}     rownames : Whether the input file has row names. Default: True    regr : Whether draw the regression line. Default: False    corr : The method to calculate the correlation. Default:  pearson     Could be:  pearson ,  spearman  or  kendall  If it's neither of the three, no correlations will show.         pROC    description \n    Generate ROC curves and output AUC.    input      infile:file : The input matrix file.    Col1: rownames if args.rnames is True else label (0, 1 class)  Col2: prediction values from model1  ...         pVenn    description \n    Venn/UpsetR plots.    input      infile:file : The input matrix    format: \tcategory1\tcategory2\tcategory3\n[e1]\t0\t1\t1\n[e2]\t0\t0\t1\n...\n[eN]\t1\t0\t0 \nrownames are not necessary but colnames are.       output      outfile:file : The plot       args      tool     : Which tools to use. Default: auto (venn, upsetr, auto(n =3: venn, otherwise upsetr))    rnames   : Whether input file has rownames. Default: False    params   : Other params for  venn.diagram  or  upset . Default: {}    devpars  : The parameters for plot device. Default:  {'res': 300, 'height': 2000, 'width': 2000}        requires  r-VennDiagram \n     r-UpSetR      pPie    description \n    Plot piechart    input      infile:file : The input file. Could be either:    Direct numbers of each category. Group1\tGroup2\n50\t50  Presence of each items in the category. \tGroup1\tGroup2\nItem1\t1\t0\nItem2\t0\t1\n...       output      outfile:file : the output plot       args      rnames  : Whether the input file has row names. Default:  False     ggs     : Extra expressions for ggplot.    devpars : The parameters for plot device. Default:  {'res': 300, 'height': 2000, 'width': 2000}", 
            "title": "plot"
        }, 
        {
            "location": "/processes/#power", 
            "text": "pSurvivalPower    description \n    Do power analysis for survival analysis.\n    See http://www.sample-size.net/sample-size-survival-analysis/    input      infile:file : The input file, could be either:    detailed suvival data with [ patient , ] time ,  status ,  variable1 ,  variable2 , ...; or  ratios with  variable ,  survrate1 ,  survrate2 ,  ssratio , where  survrate1  and\n     survrate2  are survival rates in group1 and group2, respectively,\n    and  ssratio  is sample size ratio in group1/group2       output      outfile:file : The output file with columns:    Variable: the variable (including paired groups)  Alpha: the alpha value  Beta: the beta value (1-power)  SSize1: the sample size for group1  SSize2: the sample size for group2  Total: the total sample size", 
            "title": "power"
        }, 
        {
            "location": "/processes/#rank", 
            "text": "pRankProduct    description \n    Calculate the rank product of a set of ranks. Refer to  here    input      infile:file : The input file    Format: \t\t\tCase1\tCase2\t...\nFeature1\t8.2  \t10.1 \t...\nFeature2\t2.3  \t8.0  \t...\n...  Or instead of values, you can also have ranks in the input file: \t\t\tRank1\tRank2\t...\nFeature1\t2    \t1    \t...\nFeature2\t3    \t2    \t...\n...     output      outfile:file : The output file with original ranks, rank products and p-value if required       args      informat : The input format of the values. Whether they are real values (value) or ranks (rank). Default: value    pval : Whether to calculate the p-value or not. Default: True    header : Whether the input file has headers (rownames are required!). Default: True    plot : Number of rows to plot. Default: 0 (Don't plot)    cex : Font size for plotting. Default: 0.9    cnheight : Colname height. Default: 80    rnwidth : Rowname width. Default: 50    width : Width of the png file. Default: 2000    height : height of the png file. Default: 2000", 
            "title": "rank"
        }, 
        {
            "location": "/processes/#resource", 
            "text": "pTxt    description \n    Download CSV format files.    input      in : The name of the resource       output      outfile:file : The output file       args      cols : Select the columns to keep. Default: '' (all cols)    rowfilter : Filter rows. For example, to filter out rows not start with 'Chr':    \"lambda x: not x[0].startswith('Chr')\"  Note that rowfilter applied before cols filter.    urls : Available resources and their urls.    gz : Whether to gzip the output file.       requires  curl", 
            "title": "resource"
        }, 
        {
            "location": "/processes/#rnaseq", 
            "text": "pEXPRdir2Matrix    description \n    Convert expression files to expression matrix\n    File names will be used as sample names (colnames)\n    Each gene and its expression per line.\n    Suppose each expression file has the same rownames and in the same order.    input      indir:file : the directory containing the expression files, could be gzipped       output      outfile:file : the expression matrix file    outdir:dir : the directory containing expr file and plots       args      pattern  : The pattern to filter files. Default  '*'     namefunc : Transform filename (no extension) as column name. Default: \"function(fn) fn\"    header   : Whether each expression file contains header. Default:  False     exrows   : Rows to be excluded, regular expression applied. Default:  [\"^Sample\", \"^Composite\", \"^__\"]     boxplot  : Whether to plot a boxplot. Default: False    heatmap  : Whether to plot a heatmap. Default: False    histplot : Whether to plot a histgram. Default: False    devpars  : Parameters for png. Default:  {'res': 300, 'width': 2000, 'height': 2000}     boxplotggs : The ggplot parameters for boxplot. Default:  ['r:ylab(\"Expression\")']     See ggplot2 documentation.    heatmapggs : The ggplot parameters for heatmap. Default:  ['r:theme(axis.text.y = element_blank())']     histplotggs : The ggplot parameters for histgram. Default:  ['r:labs(x = \"Expression\", y = \"# Samples\")']          pBatchEffect    description \n    Remove batch effect with sva-combat.    input      expr:file : The expression file, generated by pEXPRdir2Matrix    batch:file : The batch file defines samples and batches.       output      outfile:file : the expression matrix file    outdir:dir : the directory containing expr file and plots       args      tool     : The tool used to remove batch effect. Default  'combat'     hmrows   : How many rows to be used to plot heatmap    plot : Whether to plot    boxplot    : Whether to plot a boxplot. Default: False  heatmap    : Whether to plot a heatmap. Default: False  histogram  : Whether to plot a histgram. Default: False    devpars     : Parameters for png. Default:  {'res': 300, 'width': 2000, 'height': 2000}     ggs : The ggplot parameters    boxplot   : The ggplot parameters for boxplot. Default:  Box(ylab = {0: \"Log2 Intensity\"})  heatmap   : The ggplot parameters for heatmap. Default:  Box(theme = {'axis.text.y': 'r:element_blank()'})  histogram : The ggplot parameters for histgram. Default:  Box(labs = {'x': \"Log2 Intensity\", \"y\": \"Density\"})         pRawCounts2    description \n    Convert raw counts to another unit    input      infile:file : the expression matrix    rows are genes, columns are samples       output      outfile:file : the converted expression matrix       args      transpose : transpose the input matrix? default: False    log2 : whether to take log2? default: False    unit : convert to which unit? default: cpm (or rpkm, tmm)    header : whether input file has header? default: True    rownames : the index of the column as rownames. default: 1    glenfile : the gene length file, for RPKM    no head, row names are genes, have to be exact the same order and length as the rownames of infile    boxplot  : Whether to plot a boxplot. Default: False    heatmap  : Whether to plot a heatmap. Default: False    histplot : Whether to plot a histgram. Default: False    devpars  : Parameters for png. Default:  {'res': 300, 'width': 2000, 'height': 2000}     boxplotggs : The ggplot parameters for boxplot. Default:  ['r:ylab(\"Expression\")']     See ggplot2 documentation.    heatmapggs : The ggplot parameters for heatmap. Default:  ['r:theme(axis.text.y = element_blank())']     histplotggs : The ggplot parameters for histgram. Default:  ['r:labs(x = \"Expression\", y = \"# Samples\")']        requires  edgeR  if cpm or rpkm is chosen\n     coseq  if tmm is chosen      p2RawCounts    description \n    Convert gene expression to raw counts.    input      infile:file : The expression matrix file       output      outfile:file : The output file    outdir:dir : The output directory, may contain the figures.       args      unit : The unit of input gene expression. Default: fpkm    Could also be rpkm, tpm    nreads      : Total reads approximately. Default: 30, 000, 000    refgene     : The refgene file for gene length.    boxplot     : Whether to plot boxplot after transformation. Default: False    heatmap     : Whether to plot heatmap after transformation. Default: False    heatmapn    : How many genes used to plot heatmap. Default: 500    histplot    : Whether to plot histgram after transformation. Default: False    devpars     : The device parameters for plotting. Default:  {'res': 300, 'width': 2000, 'height': 2000}     boxplotggs  : The ggplot statement for boxplot.    heatmapggs  : The ggplot statement for heatmap.    histplotggs : The ggplot statement for histgram.         pRNAseqDEG    description \n    Detect DEGs for RNA-seq data    input      efile:file : The expression matrix    gfile:file : The group information    Like: Sample1\tGroup1\nSample2\tGroup1\nSample3\tGroup1\nSample4\tgroup2\nSample5\tgroup2\nSample6\tgroup2       output      outfile:file : The DEG list    outdir:file : The output directory containing deg list and plots       args      tool       : the tool used to detect DEGs. Default: 'edger' (deseq2)    filter     : filter out low count records. Default:  \"1,2\"  (At least 2 samples have at least 2 reads)    mdsplot    : whether to plot the MDS plot, default : True    volplot    : whether to plot the volcano plot, default : True    maplot     : whether to plot MA plots within each group, default : False    heatmap    : whether to plot the heatmap using DEGs. Default : False    heatmapn   : How many genes to be used for heatmap. If  heatmapn , the number will be  heatmapn * # DEGs . Default: 100    heatmapggs : The ggplots options for heatmap. Default : []    maplotggs  : The ggplots options for maplot. Default : []    volplotggs : The ggplots options for volplot. Default : []    devpars    : Parameters for png. Default:  {'res': 300, 'width': 2000, 'height': 2000}          pCoexp   description \n    Get co-expression of gene pairs in the expression matrix.", 
            "title": "rnaseq"
        }, 
        {
            "location": "/processes/#sambam", 
            "text": "pSam2Bam    description \n    Deal with mapped sam/bam files, including sort, markdup, and/or index    input      infile:file : The input file       output      outfile:file : The output bam file    idxfile:file : The index of the output bam file    If args.index == False, it'll a link to outfile and should be never used     args      tool              : The tool used to do the sort. Default: sambamba (picard|sambamba|biobambam|samtools)    sambamba          : The path of the sambamba. Default: sambamba    picard            : The path of the picard. Default: picard    biobambam_bamsort : The path of the biobambam's bamsort. Default: bamsort    samtools          : The path of the samtools. Default: samtools    sort              : Do sorting? Default: True    If input is sam, tool is biobambam, this should be True  index             : Do indexing? Default: True    markdup           : Do duplicates marking? Default: False    rmdup  for samtools will be called  rmdup             : Do duplicates removing? Default: False    tmpdir            : The tmp dir used to store tmp files. Default:      sortby            : Sort by coordinate or queryname. Default: coordinate    nthread           : Default: 1    informat          : The format of input file. Default:   (sam|bam)    params            : Other parameters for  tool . Defaut: \"\"    mem               : The max memory to use. Default: \"16G\"    Unit could be G/g/M/m  Will be converted to -Xmx4G, and -Xms will be 1/8 of it     requires  sambamba  if  args.tool  == samtools or reference used but not indexed.\n     picard \n     biobambam \n     samtools      pBamMarkdup    description \n    Mark/remove duplicates for bam files    input      infile:file : The input file       output      outfile:file : The output bam file       args      tool              : The tool used to do the sort. Default: sambamba (picard|sambamba|biobambam|samtools|bamutil)    sambamba          : The path of sambamba. Default: sambamba    picard            : The path of picard. Default: picard    biobambam_bamsort : The path of biobambam's bamsort. Default: bamsort    samtools          : The path of samtools. Default: samtools    bamutil           : The path of bamutil. Default: bam    rmdup             : Do duplicates removing? Default: False    Samtools will anyway remove the duplicates  tmpdir            : The tmp dir used to store tmp files. Default:      nthread           : Default: 1    Not available for samtools and picard  params            : Other parameters for  tool . Defaut: \"\"    mem               : The max memory to use. Default: \"16G\"    Unit could be G/g/M/m  Will be converted to -Xmx4G, and -Xms will be 1/8 of it     requires  sambamba \n     picard \n     biobambam \n     samtools \n     bamutil      pBamRecal    description \n    Recalibrate a bam file    input      infile:file : The bam file       output      outfile:file : The output bam file       args      tool                          : The tool used to recalibrate the bam file. Default:  gatk  (gatk|bamutil)    gatk                          : The path of gatk, including java path. Default:  gatk     samtools                      : The path of samtools. Default:  samtools     bamutil                       : The path of bamutil. Default:  bam     picard                        : The path of picard. Default:  picard     paramsRealignerTargetCreator  : Other parameters for  gatk RealignerTargetCreator . Defaut: \"\"    paramsIndelRealigner          : Other parameters for  gatk IndelRealigner . Defaut: \"\"    paramsBaseRecalibrator        : Other parameters for  gatk BaseRecalibrator . Defaut: \"\"    paramsPrintReads              : Other parameters for  gatk PrintReads . Defaut: \"\"    params                        : Other parameters for  bam recab . Default: \"\"    mem                           : The max memory to use. Default: \"32G\"    knownSites                    : The known polymorphic sites to mask out. Default: \"\" (Required for GATK)    ref                           : The reference file. Required.    Will be converted to -Xmx4G, and -Xms will be 1/8 of it     requires  gatk \n     samtools  if  args.ref  is not indexed, or bamutil is used for bam index file generation.\n     picard  if  args.ref is not dicted.      pBamReadGroup    description \n    Add or replace read groups of a bam file    input      infile:file : The bam file       output      outfile:file : The output bam file       args      tool                          : The tool used. Default:  picard  (picard|bamutil)    picard                        : The path of picard. Default:  picard     bamutil                       : The path of bamutil. Default:  bam     rg                            : The read group. Default: {'id': '', 'pl': 'Illumina', 'pu': 'unit1', 'lb': 'lib1', 'sm': ''}    id  will be parsed from filename with \" LX \" in it if not given  sm  will be parsed from filename  params                        : Other parameters for  tool . Defaut: \"\"    mem                           : The max memory to use. Default: \"4G\"    Will be converted to -Xmx4G, and -Xms will be 1/8 of it  tmpdir                        : The temporary directory. Default:         requires  gatk \n     samtools  if  args.ref  is not indexed.\n     picard  if  args.ref is not dicted.      pBamReorder    description \n    Reorder a sam/bam file by a given reference file using  picard ReorderSam    input      infile:file : The sam/bam file       output      outfile:file : The output bam file       args      picard                        : The path of picard. Default:  picard     ref                           : The reference file. Required    params                        : Other parameters for  picard ReorderSam . Defaut: \"\"    mem                           : The max memory to use. Default: \"4G\"    Will be converted to -Xmx4G, and -Xms will be 1/8 of it  tmpdir                        : The temporary directory. Default:         requires  picard      pBamMerge    description \n    Merges multiple SAM and/or BAM files (must be sorted by coordinate) into a single file.    input      infiles:file : Input sam/bam files to be merged       output      outfile:file : The merged bam file       args      tool      : The tool used to merge. Default: bamutil (picard|samtools|sambamba)    picard    : The path of picard. Default:  picard     bamutil   : The path of bamutil. Default:  bam     samtools  : The path of samtools. Default:  samtools     sambamba  : The path of sambamba. Default:  sambamba     params    : Other parameters for  tool . Defaut: \"\"    mem       : The max memory to use. Default: \"4G\"    Will be converted to -Xmx4G, and -Xms will be 1/8 of it, just for picard  tmpdir    : The temporary directory. Default:      nthread   : # threads to use. Default: 1    For picard, if nthread 1, USE_THREADING=true, otherwise USE_THREADING=false     requires  picard      pBam2Gmut    description \n    Call germline (snps and indels) from a call-ready bam file.    input      infile:file : The input bam file       output      outfile:file : The vcf file containing the mutations       args      tool : The tool used to call mutations. Default: gatk (vardict, snvsniffer, platypus, strelka)    gatk : The path of gatk. Default: gatk    vardict : The path of vardict. Default: vardict    snvsniffer : The path of snvsniffer. Default: SNVSniffer    samtools : The path of samtools. Default: samtools (used to generate reference index)    platypus : The path of platypus. Default: platypus    strelka : The path of strelka. Default: configureStrelkaGermlineWorkflow.py    configParams : The params for  strelka  configuration. Default: \"\"    picard : The path of picard. Default: picard    mem : The memory to be used. Default: 32G    will be converted to -Xms4G -Xmx32G for java programs  ref : The reference file. Required.    gz : Gzip output file? Default: False    tmpdir : The temporary directory. Default:      params : Other params for  tool . Default: \"\"       requires  gatk \n     samtools  if  args.ref  is not indexed.\n     picard  if  args.ref is not dicted. \n     vardict \n     snvsniffer \n     platypus \n     strelka@2.7.1+      pBamPair2Smut    description \n    Call somatic mutations from tumor-normal bam pair.    input      tumor:file : The tumor bam file    normal:file : The normal bam file       output      outfile:file : The vcf file       args      tool : The tool used to call mutations. Default: gatk (somaticsniper, strelka, snvsniffer, virmid, varidct)    gatk : The path to gatk. Default: gatk    somaticsniper : The path to gatk. Default: bam-somaticsniper    strelka : The path to gatk. Default: configureStrelkaSomaticWorkflow.py    snvsniffer : The path to gatk. Default: SNVSniffer    virmid : The path to gatk. Default: virmid    vardict : The path to gatk. Default: vardict    samtools : The path to gatk. Default: samtools    picard : The path to gatk. Default: picard    configParams : The configuration parameters for  configureStrelkaSomaticWorkflow.py . Default:  {}     params : The parameters for main programs. Default:  {}     meme : The memory. Default: 24G    ref : The reference genom. Default:  params.ref.value     gz : Whether gzip the output vcf file. Default: False    nthread : The number of threads to use. Default: 1    tmpdir : The temporary directory. Default:  params.tmpdir.value        requires  gatk \n     samtools  if  args.ref  is not indexed.\n     picard  if  args.ref is not dicted. \n     vardict \n     snvsniffer \n     platypus \n     strelka@2.7.1+      pBam2Cnv    description \n    Detect copy number variation from bam files.    input      input:file : The bam file       output      outfile:file : The output vcf file    outdir : The output directory containing other result files       args      gz                     : Whether to gzip the output vcf file. Default: False    tool                   : The tool used to call cnv. Default: 'cnvkit'    cnvnator               : The path of cnvnator. Default: 'cnvnator'    cnvnator2vcf           : The path of cnvnator2VCF. Default: 'cnvnator2VCF.pl'    cnvkit                 : The path of cnvkit. Default: 'cnvkit.py'    wandy                  : Tha path of Wandy. Default: 'Wandy'. A  tool.info  file should be with the executable file.    ref                    : The reference file. Required by cnvkit to generate access file. Default: ''    cnvkitAccessParams     : The params for cnvkit access command. Default: '-s 5000'    cnvkitTargetParams     : The params for cnvkit target command. Default: '--split --short-names'    cnvkitCoverageParams   : The params for cnvkit coverage command. Default: ''    cnvkitReferenceParams  : The params for cnvkit reference command. Default: '--no-edge'    cnvkitFixParams        : The params for cnvkit fix command. Default: '--no-edge'    cnvkitSegmentParams    : The params for cnvkit segment command. Default: ''    cnvkitCallParams       : The params for cnvkit call command. Default: ''    cnvkitPlotParams       : The params for cnvkit plot command. Default: ''    cnvkitBreaksParams     : The params for cnvkit breaks command. Default: ''    cnvkitGainlossParams   : The params for cnvkit gainloss command. Default: ''    cnvkitMetricsParams    : The params for cnvkit metrics command. Default: ''    cnvkitSegmetricsParams : The params for cnvkit segmetrics command. Default: '--iqr'    cnvkitExportParams     : The params for cnvkit export command. Default: ''    cnvkitScatterParams    : The params for cnvkit scatter command. Default: [''] # multiple scatter plots    cnvkitHeatmapParams    : The params for cnvkit heatmap command. Default: [''] # multiple heatmap plots    cnvkitDiagramParams    : The params for cnvkit diagram command. Default: ''    cnvkitReport           : Generate cnvkit reports? Default: True    cnvkitPlot             : Generate cnvkit plots? Default: True    cnvnatorBinsize        : Bin size for cnvnator. Default: 100    cnvnatorGenome         : Genome for cnvnator. Default: 'hg19'. (NCBI36, hg18, GRCh37, hg19)    params                 : The params for  tool . Default: '-t 1' # wandy 1:hg19 solid cell/blood, 2:hg19 cell free/plamsa, 3:hg38 solid cell/blood, 4:hg38 cell free/plamsa    mem                    : The memory used. Default: '20G' # only for wandy    nthread                : The # threads to use. Default: 1     # only for cnvkit       requires  cnvkit \n     cnvnator   wandy : Inside cnv caller         pBamStats    description \n    Get read depth from bam files.    input      infile:file : The input bam file       output      outfile:file : The output statistic file    outdir:dir : The directory containing result files and figures.       args      tool : The tool used to do the job. Default: bamstats    bamstats : The path to bamstats. Default: bamstats    params : Other params to main program. Default:  {}     mem : The memory to be used. Default: 16G    plot : Whether plot the result. Default: True         pBam2Fastq    description \n    Convert sam/bam files to pair-end fastq files.    input      infile:file : The sam/bam file.    Sam files only available for biobambam, picard       output      fqfile1:file : The 1st match of paired reads    fqfile2:file : The 2nd match of paired reads       args      tool      : The tool to use. Default: biobambam (bedtools, samtools, picard)    biobambam : The path of bamtofastq of biobambam. Default: bamtofastq    bedtools  : The path of bedtools. Default: bedtools    samtools  : The path of samtools. Default: samtools    picard    : The path of picard. Default: picard    mem       : The memory to be used by picard. Default: 8G    gz        : Whether gzip the output files. Default: True    params : : Other params for  tool . Default: ''    tmpdir    : The tmpdir. Default:  __import__('tempfile').gettempdir()        requires  picard \n     biobambam \n     samtools \n     bedtools      pBam2FastqSE    description \n    Convert sam/bam files to single-end fastq files.    input      infile:file : The sam/bam file.    Sam files only available for biobambam, picard       output      fqfile:file : The fastq file       args      tool      : The tool to use. Default: biobambam (bedtools, samtools, picard)    biobambam : The path of bamtofastq of biobambam. Default: bamtofastq    bedtools  : The path of bedtools. Default: bedtools    samtools  : The path of samtools. Default: samtools    picard    : The path of picard. Default: picard    mem       : The memory to be used by picard. Default: 8G    gz        : Whether gzip the output files. Default: True    params : : Other params for  tool . Default: ''    tmpdir    : The tmpdir. Default:  __import__('tempfile').gettempdir()        requires  picard \n     biobambam \n     samtools \n     bedtools      pBam2Counts    description \n    Extract read counts from RNA-seq bam files.    input      infile:file : The input bam files       outfile      outfile:file : The count file       args      tool : The tool used to extract counts. Default: ht-seq    htseq : The path of htseq-count.    params : Other params for main program.    refgene : The reference gene in GTF format.       requires  htseq", 
            "title": "sambam"
        }, 
        {
            "location": "/processes/#seq", 
            "text": "pConsvPerm    description \n    Generate a null distribution of conservation scores.    input      seed : The seed to generate the random regions. Default: None       output      outfile:file : A file with mean conservation scores sorted descendingly.       args      len : The length of a random region. Default: 50    nperm : Number of permutations. Default: 1000    gsize : The chrom size file.    bedtools : The path of bedtools.    bwtool : The path of bwtool.    consvdir : The directory containing bigwig files of conservation scores    The bigwig file should start with chr name: chrN.*       requires  bwtool \n     bedtools      pConsv    description \n    Get the conservation scores of regions.\n    It uses wigFix to find the conservation scores.\n    But first you have to convert those wigFix.gz files to bigWig files using ucsc-wigToBigWig    input      bedfile:file : The bedfile with regions in the same chromosome    permfile:file : The permutaiton file generated by  pConsvPerm , used to calculate p-values       output      outfile:file : The output file       args      consvdir : The bigwig directory, the bigwig files must be named as \"chrN.*.bw\"    For example:  chr1.phyloP30way.bw    bwtool : The path of bwtool executable. Default:  bwtool     bedtools : The path of bedtools executable. Default:  bedtools     pval : Whether calculate pvalue of each region. Default: False    In this case, the  in.permfile  can be ignored.       requires  bwtool \n     bedtools      pPromoters    description \n    Get the promoter regions in bed format of a gene list give in infile.    input      infile:file : the gene list file       output      outfile:file : the bed file containing the promoter region       args      up : the upstream to the tss, default: 2000    down : the downstream to the tss, default: 2000    genome : the genome, default: hg19       require  python-mygene", 
            "title": "seq"
        }, 
        {
            "location": "/processes/#snp", 
            "text": "pSnp2Bedx    description \n    Find coordinates for SNPs in BEDX format.    input      snpfile:file : the snp file, each snp per line       output      outfile:file : the result file, columns are:    chrom, start(0-based), end, name, score, strand, ref, allele       args      genome : default: hg19    snpver : default: snp147    notfound : What to do if the snp is not found. Default: skip    inmeta : The metadata for input file to determine which column is rsID    xcols : The extra columns to extract and output to extra columns in output file.    indem : The input delimit. Default: '\\t'    incom : The input comment. Default: '#'    skip : The lines to skip for input file. Default: 0       requires  python-cruzdb      pSnp2Avinput    description \n    Convert SNP list to avinput to ANNOVAR.    input      snpfile:file : the snp file, each snp per line       output      outfile:file : the result avinput file       args      genome : default: hg19    snpver : default: snp147       requires  python-cruzdb", 
            "title": "snp"
        }, 
        {
            "location": "/processes/#snparray", 
            "text": "pGistic    description \n    Runing GISTIC to get CNV results.\n    see: ftp://ftp.broadinstitute.org/pub/GISTIC2.0/GISTICDocumentation_standalone.htm    input      segfile:file : Segmentation File    mkfile:file  : Markers File    alfile:file  : Array List File    cnvfile:file : CNV File       output      outdir:dir : The output directory    All Lesions File (all_lesions.conf_XX.txt, where XX is the confidence level)  Amplification Genes File (amp_genes.conf_XX.txt, where XX is the confidence level)  Deletion Genes File (del_genes.conf_XX.txt, where XX is the confidence level)  Gistic Scores File (scores.gistic)  Segmented Copy Number (raw_copy_number.pdf)       args      gistic : The path to gistic.    genome : The genome used to select refgene file from refgenefiles.    mcr : The mcr path    params : Other params for gistic         pSNP6Genotype    description \n    Call genotypes from GenomeWideSNP_6 CEL file    input      celfile:file : the CEL file       output      outfile:file : the outfile containing probe name and genotypes    format:  Probe name \\t genotype  genotype  = 0: AA, 1: AB, 2: BB     requires  bioconductor-crlmm      pGenoToAvInput    description \n    Convert the genotype called by pSNP6Genotype to  ANNOVAR input file  using dbSNP identifiers.     input      genofile:file : the genofile generated by pSNP6Genotype, must be sorted by probe names    annofile:flie : the annotation file downloaded from http://www.affymetrix.com/support/technical/annotationfilesmain.affx    Could be in .gz format       output      outfile:file : the avinput file       requires  python-read2", 
            "title": "snparray"
        }, 
        {
            "location": "/processes/#sql", 
            "text": "pCreateTable    description \n    Create tables in the database    input      dsn : The dsn to connect to the database    currently support  sqlite:file=...    schema:file : The schema file    could be a pure schema file: Field\tType\tStatement\nID\tINT\tPRIMARY KEY\n...  or a data file with header       output      dsn : The dsn       args      intype : The input file schema file or a data file. Default:  schema     drop : Force creating the table (drop the pre-existing table)    delimit : The delimit of input file. Default:  \\\\t          pImportData    description \n    Create tables and import the data    input      dsn : The dsn to connect to the database    currently support  sqlite:file=...    datafile:file : The schema file    must have header       output      dsn : The dsn       args      delimit : The delimit of input file. Default:  \\\\t          pUpdateTable    description \n    Update table using sql.    input      dsn : The dsn to connect to the database    currently support  sqlite:file=...       output      dsn : The dsn       args      sql : The sql to update the table (list)         pSelectTable    description \n    Select data from table and dump it.    input      dsn : The dsn to connect to the database    currently support  sqlite:file=...       output      outfile:file : The dumped file       args      sql : The sql to select data from the table (list)", 
            "title": "sql"
        }, 
        {
            "location": "/processes/#stats", 
            "text": "pMetaPval    description \n    Combine p-values in the files from input directory    input      indir:dir : The directory containing the input files       output      outfile:file : The output file containing the meta-pvalues       args      args.pattern : The pattern used to filter the input files. Default: '*'    args.header : Whether the input files contains a header. Default: True    Could be a list to specify it for each file.  The order should be concordant with the file names    args.pcol : Which column is the p-value. Default: -1 (last column)    args.poutonly : Only output pvalues. Default: False (output all possible information)    args.outheader : Whether output the header. Default: True    args.method : The method used to calculate the meta-pvalue. Default: sumlog (Fisher's method)    Other available methods: logitp, sumz, votep, sump, meanp and wilkinsonp  See: https://www.rdocumentation.org/packages/metap/versions/0.8       requires  r-matep      pMetaPval1    description \n    Combine p-values in a single file by rows.    input      infile:file : The input file       output      outfile:file : The output file containing the meta-pvalues       args      args.header : Whether the input files contains a header. Default: True    args.pcol : Which column is the p-value. Default: -1 (last column)    args.poutonly : Only output pvalues. Default: False (output all possible information)    args.outheader : Whether output the header. Default: True    args.method : The method used to calculate the meta-pvalue. Default: sumlog (Fisher's method)    Other available methods: logitp, sumz, votep, sump, meanp and wilkinsonp  See: https://www.rdocumentation.org/packages/metap/versions/0.8       requires  r-matep      pSurvival    description \n    Survival analysis    input      infile:file : The input file (header is required).    col1: rownames if args.inopts.rnames = True  col2: the survival time  col3: the status. 0/1 for alive/dead or 1/2 for alive dead  col4: var1.  ... other variables       output      outfile:file : The outfile containing the pvalues    outdir:dir   : The output directory containing the pval files and plots       args      inunit     : The time unit in input file. Default: days    outunit    : The output unit for plots. Default: days    nthread    : Number of threads used to perform analysis for groups. Default: 1    inopts     : The options for input file    rnames : Whether input file has row names. Default: True    combine    : Whether combine groups in the same plot. Default: True    devpars    : The device parameters for png. Default:  {res:300, height:2000, width:2000}     The height and width are for each survival plot. If args.combine is True, the width and height will be multiplied by  max(arrange.ncol, arrange.nrow)    covfile    : The covariant file. Require rownames in both this file and input file.    ngroups    : Number of curves to plot (the continuous number will divided into  ngroups  groups.    plot       : The params for plot.    params  : The params for  ggsurvplot . Default:  Box({'risk.table': True, 'conf.int': True, 'font.legend': 13, 'pval': '{method}\\np = {pval}'})  You may do  ylim.min  to set the min ylim. Or you can set it as 'auto'. Default: 0.     arrange : How to arrange multiple survival plots in one if  args.combine = True .  nrow : The number of rows. Default: 1  ncol : The number of cols. Default: 1      ggs        : Extra ggplot2 elements for main plot.  ggs.table  is for the risk table.    pval       : The method to calculate the pvalue shown on the plot. Default: True (logrank)    Could also be  waldtest ,  likeratio  (Likelihoold ratio test)    method     : The method to do survival analysis.        requires  r-survival \n     r-survminer      pChiSquare    description \n    Do chi-square test.    input      infile:file : The input file.       output      outfile:file  : The output file containing Xsquare, df, pval and method    obsvfile:file : The observation matrix    exptfile:file : The expectation matrix       args      intype : The type of the input file:    count  (default): The contingency table #         | Disease | Healthy |\n# --------+---------+---------+\n#   mut   |   40    |   12    |\n# non-mut |   23    |   98    |\n# --------+---------+---------+  raw : The raw values: # Contingency table rows: Mut, Non\n# Contingency table cols: Disease, Healthy\n#\n#         | S1 | S2 | ... | Sn |\n# --------+----+----+-----+----+\n# Disease | 1  | 0  | ... | 1  |\n# Healthy | 0  | 1  | ... | 0  |\n# --------+----+----+-----+----+\n# Mut     | 1  | 0  | ... | 1  |\n# Non     | 0  | 1  | ... | 0  |    ctcols : The colnames of contingency table if input file is raw values    You may also specify them in the head of the input file         pFisherExact    description \n    Do fisher exact test.    input      infile:file : The input file.       output      outfile:file  : The output file containing confInt1, confInt2, oddsRatio, pval, alternative and method.       args      intype : The type of the input file:    count  (default): The contingency table #         | Disease | Healthy |\n# --------+---------+---------+\n#   mut   |   40    |   12    |\n# non-mut |   23    |   98    |\n# --------+---------+---------+  raw : The raw values: # Contingency table rows: Mut, Non\n# Contingency table cols: Disease, Healthy\n#\n#         | S1 | S2 | ... | Sn |\n# --------+----+----+-----+----+\n# Disease | 1  | 0  | ... | 1  |\n# Healthy | 0  | 1  | ... | 0  |\n# --------+----+----+-----+----+\n# Mut     | 1  | 0  | ... | 1  |\n# Non     | 0  | 1  | ... | 0  |    ctcols : The colnames of contingency table if input file is raw values    You may also specify them in the head of the input file         pPWFisherExact    description \n    Do pair-wise fisher exact test.\n    Commonly used for co-occurrence/mutual-exclusivity analysis.\n    P-value indicates if the pairs are significantly co-occurred or mutually exclusive.\n    Co-occurrence: Odds ratio   1\n    Mutual-exclusivity: Odds ratio   1    input      infile:file : The input file.       output      outfile:file  : The output file containing confInt1, confInt2, oddsRatio, pval, qval, alternative and method.       args      intype : The type of the input file:    pairs : The contingency table #\n# A+\tB+\t4\n# A-\tB-\t175\n# A+\tB-\t12\n# A-\tB+\t1\n#  raw  (default): The raw values: #\n#         | S1 | S2 | ... | Sn |\n# --------+----+----+-----+----+\n# A       | 1  | 0  | ... | 1  |\n# B       | 0  | 1  | ... | 0  |\n# ...     |           ...      |\n# X       | 0  | 1  | ... | 0  |\n# --------+----+----+-----+----+\n#    padj : The p-value adjustment method, see  p.adjust.methods  in R. Default:  BH          pMediation    description \n    Do mediation analysis    input      infile:file : The input file (a matrix or data.frame).       output      outfile:file : The result file.       args      inopts : The options for input file.    cnames : Whether the input file has column names  rnames : Whether the input file has row names    medopts : The options for mediation analysis.    modelm : The model for M ~ X. Default:  lm(M ~ X)  modely : The model for Y ~ X + M. Default:  lm(Y ~ X + M)  mediator : Tell the model which column is the mediator  treat : Tell the model which column is the variable  boot : Use bootstrap?  sims : How many time simulations?         pHypergeom    description \n    Do hypergeometric test.    input      infile:file : The input file, could be raw data (presence (1) and absence (0) of elements) or number of overlapped elements and elements in each category.    Set  args.intype  as  raw  if it is raw data. The population size  args.N  is required  Set  args.intype  as  numbers  (or any string except  raw ) if it is numbers. You can specified explicit header:  k  = overlapped elements,  m  = size of set 1,  n  = size of set 2 and  N  = the population size. If  N  not included, then  args.N  is required       output      outfile:file : The output file       args      intype : the type of input file. Default:  raw . See  infile:file     inopts : The options for input file.    cnames : Whether the input file has column names  rnames : Whether the input file has row names    N : The population size. Default:  None", 
            "title": "stats"
        }, 
        {
            "location": "/processes/#tabix", 
            "text": "pTabix    description \n    Use tabix to extract information.    input      infile : a local or remote file    region : a region or a file containing regions       output      outfile:file : The information extracted from the input file       args      tabix : The path to  tabix     params : Other params for  tabix          pTabixIndex    description \n    Generate tabix index file.    input      infile:file : the input file    Could be bgzipped.       output      outfile:file : The bgzipped file    outidx:file : The tabix index file       args      tabix : The path to  tabix     params : Other params for  tabix     python : Will be used to generate command line arguments.", 
            "title": "tabix"
        }, 
        {
            "location": "/processes/#tcga", 
            "text": "pDownload    description \n    Download TCGA use  gdc-client  and a manifest file    input      manifile:file : the manifest file       output      outdir:file : the directory containing downloaded file       args      params : other params for  gdc-client , default: \"--no-related-files --no-file-md5sum -n 20\"    bin-gdc : the executable file of  gdc-client , default: \"gdc-client\"         pSample2SubmitterID    description \n    convert TCGA sample names with submitter id with metadata and sample containing folder    input      indir:file : the directory containing the samples    mdfile:file : the metadata file       output      outdir:file : the directory containing submitter-id named files         pConvertExpFiles2Matrix    description \n    convert TCGA expression files to expression matrix, and convert sample name to submitter id    input      dir:file : the directory containing the samples    mdfile:file : the metadata file       output      outfile:file : the output matrix       requires  python-mygene      pConvertMutFiles2Matrix    description \n    convert TCGA mutation files (vcf.gz) to mut matrix, and convert sample name to submitter id    input      dir:file : the directory containing the samples    mdfile:file : the metadata file       output      outfile:file : the output matrix", 
            "title": "tcga"
        }, 
        {
            "location": "/processes/#tfbs", 
            "text": "pMotifScan    description \n    Scan motif along the given sequences.    input      tffile:file : The infile containing TF name and motif name.    If only one column is give, will be used as both TF and motif name  If there are 2 columns, 1st column will be motif name, 2nd column will be TF name    sfile:file : The sequence file       output      outdir:file : The output dir       args      tools    : The tool used to scan the motif. Default: 'meme'    meme     : The path of MEME's fimo. Default: 'fimo' \n`motifs   : The motif database in MEME format.  pval     : The pvalue cutoff. Default: 1e-4    cleanmname : Whether to clean motif name. Default: True    ucsclink : The ucsc link template. Default:  https://genome.ucsc.edu/cgi-bin/hgTracks?db=hg19 position={}     nthread  : Number of threads used to scan, only available when you have multiple mids. Default: 1    params   : Other parameters for  fimo        requires  fimo  from MEME Suite", 
            "title": "tfbs"
        }, 
        {
            "location": "/processes/#tsv", 
            "text": "pMatrixR    description \n    Operate a matrix and save the new matrix to file.    input      infile:file : The input file containing the matrix       output      outfile:file : The output matrix       args      cnames : Whether the input file has cnames. Default: True    rnames : Whether the input file has rnames  . Default: 1    code : The R code to operating the matrix. (the matrix is read in variable  mat )         pCbind    description \n    Cbind the rest of files to the first file.    input      infiles:files : The input files       output      outfile:file : The output matrix       args      cnames : Whether the input file has cnames. Default: True    or [True, True, False] corresponding to the file order    rnames : Whether the input file has rnames  . Default: 1    miss : Replacement for missing values. Default:  NA          pRbind    description \n    Rbind the rest of files to the first file.    input      infiles:files : The input files       output      outfile:file : The output matrix       args      cnames : Whether the input file has cnames. Default: True    or [True, True, False] corresponding to the file order    rnames : Whether the input file has rnames  . Default: 1    miss : Replacement for missing values. Default:  NA          pCsplit    description \n    Split a matrix by columns and save them into files.    input      infile:file : The input file       output      outdir:dir : The directory containing the output column files       args      cnames : Whether the input file has cnames. Default: True    or [True, True, False] corresponding to the file order    rnames : Whether the input file has rnames  . Default: 1         pRsplit    description \n    Split a matrix by rows and save them into files.    input      infile:file : The input file       output      outdir:dir : The directory containing the output row files       args      cnames : Whether the input file has cnames. Default: True    or [True, True, False] corresponding to the file order    rnames : Whether the input file has rnames  . Default: 1         pTsv    description \n    Read, Transform, filter a TSV file.    input      infile:file : The input file       output      outfile:file : The output file       args      inopts : The input options for infile:    delimit : The delimit. Default:  \\\\t  comment : The comment sign. Default:  #  skip : First N lines to skip. Default:  0  ftype : The file type. Metadata can be assigned direct (list/OrderedDict). If not specified, metadata will be generated automatically.    outopts : The output options for outfile:    delimit : The delimit for records. Default:  \\\\t  head : Output header or not. Default:  False  headDelimit : The delimit for header. Default:  \\\\t  headPrefix : The prefix for header. Default: ``  headTransform : The transformer for header. Default:  None  ftype : The file type. Metadata can be assigned direct (list/OrderedDict, '+' as an element or key is allowed to indicate extra meta from the reader). If not specified, metadata will be borrowed from the reader.     ops : A ops function to transform the row. Argument is an instance of  readRecord     opshelper : A helper function for  args.ops          pSimRead    description \n    Read files simultaneously.\n    NOTE: only one file allows multiple lines with same value to compare, and that file should be the first one. For example: \n     File1:\n1\t1\n1\t2\n1\t3\nFile2:\n1\t1\n2\t2\n3\t3 \n    If you compare the first column, File1 has to put at the begining for input.    input      infiles:files : The input files       output      outfile:file : The output file       args      skip : argument skip for each file    delimit : argument delimit for each file    usehead : The header from which input file will be used for output file.    Default: None (Don't write header)    gzip : argument gzip for each file    match : The match function.     do : The do function. Global vaiable  fout  is available to write results to output file.       requires  python-simread", 
            "title": "tsv"
        }, 
        {
            "location": "/processes/#utils", 
            "text": "", 
            "title": "utils"
        }, 
        {
            "location": "/processes/#vcf", 
            "text": "pVcfFilter    description \n    Filter records in vcf file.    input      infile:file : The input file       output      outfile:file : The output file       args      filters : The filters, should be a string of lambda function: \n     lambda record, samples:  expression \n* ``record.CHROM`` :  chr20 \n* ``record.POS``   : 1234567\n* ``record.ID``    :  microsat1 \n* ``record.REF``   :  GTC \n* ``record.ALT``   : [G, GTCT]\n* ``record.QUAL``  : 50\n* ``record.FILTER``: [ PASS ] # NO!, PASS should be []\n* ``record.INFO``  : { AA :  G ,  NS : 3,  DP : 9}\n* samples = record.samples\n* len(samples): 3\n* samples[0].sample:  NA00001 \n* samples[0]: Call(sample=NA00001, CallData(GT=0/1, GQ=35, DP=4))\n* samples[0].data: calldata(GT= 0/1 , GQ=35, DP=4)\n* samples[0].data.GT:  0/1   see here for record and samples: https://github.com/jamescasbon/PyVCF  Remember if filters() returns True, record remained.    gz      : Whether to gzip the output file. Default: False    keep    : Whether to keep the filtered records. Default: True. (only for gatk, snpsift at filter step)       requires  pyvcf      pVcf    description \n    Use pyvcf to manipulate vcf file    input      infile:file : The input vcf file       output      outfile:file : The output vcf file       args      helper : The helper code injected to script    Since lambda function can't do assignment and manipulation so you can write some help function here    readerops : A lambda function (must be quoted) to manipulate the reader (vcf.Reader instance)    recordops : A lambda function (must be quoted) to manipulate the record (vcf.Record instance)    gz : Gzip the ouput file         pVcfAnno    description \n    Annotate the variants in vcf file.\n    You have to prepare the databases for each tool.    input      infile:file : The input vcf file       output      outfile:file : The output file (output file of annovar will also be converted to vcf)    outdir : The output directory, used to fetch some stat/summary files       args      tool : The tool used to do annotation. Default: snpeff    snpeff : The path of snpeff. Default: snpEff    vep : The path to vep. Default: vep    gz : Whether to gzip the result file. Default: False    annovar : The path of annovar. Default: annotate_variation.pl    annovar_convert : The path of convert2annovar.pl, used to convert vcf to annovar input file. Default: convert2annovar.pl    genome : The genome for annotation. Default: hg19    tmpdir : The tmpdir, mainly used by snpeff. Default:      dbpath : The path of database for each tool. Required by 'annovar' and 'vep'    params : Other params for tool. Default: ''    snpeffStats : Whether to generate stats file when use snpeff. Default: False    mem : The memory used by snpeff. Default: '4G'       requires  annovar \n     snpeff \n     vep      pVcfSplit    description \n    Split multi-sample Vcf to single-sample Vcf files.    input      infile:file : The input vcf file    samples : The samples, if not provided, will extract all samples       output      outdir:dir : The output directory containing the extracted vcfs       args      tool : The tool used to do extraction. Default: vcftools    vcftools : The path of vcftools' vcf-subset    bcftools : The path of bcftools, used to extract the sample names from input vcf file.    gatk : The path of gatk.         pVcfMerge    description \n    Merge single-sample Vcf files to multi-sample Vcf file.    input      infiles:files : The input vcf files    outfile:dir : The output multi-sample vcf.       args      tool : The tool used to do extraction. Default: vcftools    vcftools : The path of vcftools' vcf-subset    bcftools : The path of bcftools, used to extract the sample names from input vcf file.    gatk : The path of gatk.         pVcf2Maf    description \n    Convert Vcf file to Maf file    input      infile:file  : The input vcf file    see  args.somatic       output      outfile:file : The output maf file       args      tool      : Which tool to use. Default: vcf2maf    vcf2maf   : The path of vcf2maf.pl    vep       : The path of vep    vepDb     : The path of database for vep    filtervcf : The filter vcf. Something like: ExAC_nonTCGA.r0.3.1.sites.vep.vcf.gz    ref       : The reference genome    nthread   : Number of threads used to extract samples. Default: 1    tumor1st  : Whether tumor sample comes first. Default:  True     bcftools  : Path to bcftools used to extract sample names.    vcftools  : Path to vcftools used to split vcf.    samfunc   : A lambda function used to deduce sample names from file name.    somatic   : Whether input vcf file is a somatic mutation file. Default: False    somatic mutation vcf file can only have one sample TUMOR, or two samples, TUMOR and NORMAL, but will be considered as single sample.  otherwise, multiple samples are supported in the input vcf file. Tumor id will be sample name for each sample, normal id will be NORMAL.         pVcf2GTMat   description \n    Convert Vcf file to genotype matrix.", 
            "title": "vcf"
        }, 
        {
            "location": "/processes/#vcfnext", 
            "text": "pVcfStatsPlot    description \n    Convert csvstat file from snpEff to R-readable matrix and plot them.    input      indir:file : The directory containing the csv stat files from  snpEff ann        output      outdir:dir : The output directory       args      chroms : The chromsome filter. Default: \"\" (all chroms)    Note: snpEff csvstat file has no \"chr\" prefix       pCallRate    description \n    Calculate sample/snp call rate from single sample vcfs    input      indir:file : The dir containing the vcfs       output      outsample:file : The report of call rate for each sample    figsample:file : The bar chat of sample call rates    outsnp:file : The report of call rate for each snp    figsnp:file : The bar chat of snp call rates         pCepip    description \n    Run CEPIP.    input      infile:file : The input file (vcf or avinput)       output      outfile:file : The cepip result file       args      cepip : The path of cepip    cell  : The related cell line    params : Other params for cepip       requires  cepip      pMutSig    description \n    MutSig stands for \"Mutation Significance\".  MutSig analyzes lists of mutations discovered in DNA sequencing, to identify genes that were mutated more often than expected by chance given background mutation processes.\n    For more information, see Lawrence, M. et al. Mutational heterogeneity in cancer and the search for new cancer-associated genes. Nature 499, 214-218 (2013).  See  dcumentation    input      infile:file : mutation table       output      outdir:dir : The output directory       args      mutsig  : The path to  run_MutSigCV.sh , default: 'mutsig'    mcr     : The Matlab MCR path    cvrg    : coverage table    cvrt    : covariates table    mutdict : mutation_type_dictionary_file    chrdir  : chr_files_hg18 or chr_files_hg19       requires  MutSig      pMafMerge    description \n    Merge maf files.    input      indir:dir : The directory containing the maf files       output      outfile:file : The merged maf file       args      excols : How to deal with extra columns other than 34 standard columns from TCGA.    merge(default): Merge the columns, if one not exists, fill with an empty string.  discard: Just discard the extra columns, with only 34 columns left. So you can also put just one maf file in the indir with some columns missed to fill it with standard columns.         pMaftools    description \n    Use maftools to draw plots.    args      ngenes :        requires \n    [``]", 
            "title": "vcfnext"
        }, 
        {
            "location": "/processes/#web", 
            "text": "pDownloadForm    description \n    Download results by submitting a form, supporting pagination.    input      url    : the URL contains the form    data   : the data used to fill the form (JSON string or transformed from dict by json.dumps).    submit : the submit button to submit the form (use Xpath).    next   : the button for next page (use Xpath)       output      outdir:file : The directory saves the results       args      interval : seconds to wait between fetching each page. Default: 1       requires  Splinter \n     Phantomjs      pDownloadGet    description \n    Download results by urls.    input      url : the URLs to download       output      outfile:file : The output file         pDownload   description \n    Alias of  pDownloadGet     pDownloadPost    description \n    Download results by POST.    input      url  : the URLs to download    data : the POST data.       output      outfile:file : The output file", 
            "title": "web"
        }, 
        {
            "location": "/processes/#wxs", 
            "text": "", 
            "title": "wxs"
        }, 
        {
            "location": "/processes/#wxsanno", 
            "text": "pSnpEff    description \n    This is the default command. It is used for annotating variant filed (e.g. VCF files).    input      infile:file : The input file        output      outdir:file : The directory containing output anntated file, snpEff_genes.txt and snpEff_summary.html       args      snpEff : The snpEff executable, default: \"snpEff\"    params : Other parameters for  snpEff , default: \"-Xms1g -Xmx4g -v\"    genome : The genome used for annotation, default: \"hg19\"    informat : The format of input file [vcf or bed], default: \"vcf\"    outformat : The format of output file [vcf, gatk, bed, bedAnn], default: \"vcf\"    csvStats : Whether to generate csv stats file, default: True.    htmlStats : Whether to generate the html summary file, default: False.    javamem : The memory to use. Default: '-Xms1g -Xmx8g'       requires  snpEff", 
            "title": "wxsanno"
        }, 
        {
            "location": "/processes/#wxscall", 
            "text": "pCNVnator    description \n    Use  CNVnator  to call CNVs from bam file    input      infile:file : The bam file        output      outfile:file : The vcf file       args      cnvnator : The CNVnator executable, default: \"cnvnator\"    cnv2vcf : The converter executable to convert CNVnator results to vcf, default: \"cnvnator2VCF.pl\"    binsize : The bin_size, default: 100    genome : The genome: default: hg19    chrom : Chromosome names, default: \"\" (all chromosomes)    chrdir : The dir contains reference sequence of chromosomes, default: \"\" (don't specify)       requires  CNVnator", 
            "title": "wxscall"
        }, 
        {
            "location": "/processes/#wxsdown", 
            "text": "pMutSig    description \n    MutSig stands for \"Mutation Significance\".  MutSig analyzes lists of mutations discovered in DNA sequencing, to identify genes that were mutated more often than expected by chance given background mutation processes.  For more information, see Lawrence, M. et al. Mutational heterogeneity in cancer and the search for new cancer-associated genes. Nature 499, 214-218 (2013).  See  dcumentation    input      maffile:file : mutation table    cvgfile:file : coverage table    cvrfile:file : covariates table    mutdict:file : mutation_type_dictionary_file    chrdir:file : chr_files_hg18 or chr_files_hg19        output      outdir:dir : The output directory       args      mutsig : The path to  run_MutSigCV.sh , default: 'mutsig'    mcr : The Matlab MCR path       requires  MutSing      pVcf2Maf    description \n    Convert a snpEff-annotated somatic mutation vcf file (with normal and tumor samples) to  maf  file    input      infile:file : vcf file       output      outfile:file : The maf file       args  vepdata : The path of vep data. Default: \"\" (default data dir of vep)\n        vep : The path of vep excutable. Default: \"vep\"\n        vcf2maf : The path of vcf2maf excutable. Default: \"vcf2maf.pl\"\n        reffile : The reference fasta file.\n        nthread : The number of threads used by vep. Default: 1\n        filtervcf : The filter vcf   params : Other parameters for  vcf2maf.pl , default: \"\"       requires  vcf2maf.py      pMergeMafs    description \n    Merge MAF files    input      indir:file : The directory containing MAF files to be merged       output      outfile:file : The merged MAF file         pMutsig4Plot    description \n    Prepare somatic mutations for  plotting    input      msdir:file : The mutsig output directory       output      outfile:file : The file for plotting  #PANEL: Somatic mutations\n#INFO: MT|PI\n#DESC: Mutation type|Putative impact\n# could also be bordercolor, you can have up to 4 shape features\n#TYPE: shape|bgcolor\n# could also be continuous\n# expressions for set: a,b,c\n#                 norminal: no\n#                 continuous: [0,1]\n#DATA: set|norminal\n#NCOL: 2|2\n#NAME_MT: Frameshift|Missense|Nonsense|Silent|Splice_site|TSS|Nonstop\n#NAME_PI: HIGH|MODERATE|LOW|MODIFIER\n#VALUE_MT: 0|1|20|13|4|17|14\n#EXP_MT: frameshift_variant,inframe_deletion,inframe_insertion|missense_variant,initiator_codon_variant,stop_retained_variant,rare_amino_acid_variant|stop_gained|synonymous_variant|splice_acceptor_variant,splice_donor_variant|start_lost,start_retained|stop_lost\n#\nSample1\tSample2\tSample3\tSample4\tSample5\nABC\tmissense_variant|HIGH\tmissense_variant|HIGH\t...\n...     args      topn : the cutoff to select genes. If it is  = 1, top N genes will be selected, otherwise, it will be used as pvalue cutoff. Default: .05       requires  pyvcf      pMutPlot    description \n    Plot mutations\n     |           |             |           |           |---\n|- ftWidth -|  s   s   s  |- pnWidth -|- lgWidth -| snHeight\n|           |             |           |           |---\n    feature1\n\tfeature2    input      indir:file : The input directory containing plot files       output      outfile:file : The plot png file         pCepip    description \n    run CEPIP.    input      avinput:file : The avinput file    cell : The cell       output      outfile:file : The cepip result file       args      bin-cepip : The jar file path of cepip, default: /data2/junwenwang/shared/tools/cepip/cepip.jar       requires  cepip", 
            "title": "wxsdown"
        }, 
        {
            "location": "/processes/#wxsprep", 
            "text": "pTrimmomaticPE    description \n    Trimming Illumina NGS paired-end data    input      fqfile1:file : The 1st fastq file (could be in .gz format)    fqfile2:file : The 2nd fastq file       output      outfile1:file : The 1st output file    outfile2:file : The 2nd output file       args      trimmomatic : The trimmomatic executable, default: \"trimmomatic\"    phred : \"phred33\" (default) or \"phred64\"    params : Other params for trimmomatric, default: \"ILLUMINACLIP:{adapter}:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\"    have to replace  {adapter}  with the path of the adapter file    nthread : 1       requires  trimmomatic      pTrimmomaticSE    description \n    Trimming Illumina NGS single-end data    input      fqfile:file : The fastq file (could be in .gz format)       output      outfile:file : The output file       args      trimmomatic : The trimmomatic executable, default: \"trimmomatic\"    phred : \"phred33\" (default) or \"phred64\"    params : Other params for trimmomatric, default: \"ILLUMINACLIP:{adapter}:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\"    have to replace  {adapter}  with the path of the adapter file    nthread : 1       requires  trimmomatic      pAlignPEByBWA    description \n    Align paired-end reads to reference genome using bwa mem    input      infile1:file : read file 1 (fastq, or fastq gzipped)    infile2:file : read file 2 (fastq, or fastq gzipped)    reffile:file : The reference file       output      outfile:file : The output sam file       args      bwa : The bwa executable, default: bwa    params : Other params for bwa mem, default: \"-M\"    nthread : 1       requires  bwa      pAlignSEByBWA    description \n    Align paired-end reads to reference genome using bwa mem    input      infile:file : read file (fastq, or fastq gzipped)    reffile:file : The reference file       brings      reffile#bwt : \"{{reffile | bn}}.bwt\",     reffile#sa : \"{{reffile | bn}}.sa\",    reffile#ann : \"{{reffile | bn}}.ann\",    reffile#amb : \"{{reffile | bn}}.amb\",    reffile#pac : \"{{reffile | bn}}.pac\"       output      outfile:file : The output sam file       args      bwa : The bwa executable, default: bwa    params : Other params for bwa mem, default: \"-M\"    nthread : 1    reffile : The reference file, required       requires  bwa      pAlignPEByNGM    description \n    Align paired-end reads to reference genome using NextGenMap    input      infile1:file : read file 1 (fastq, or fastq gzipped)    infile2:file : read file 2 (fastq, or fastq gzipped)    reffile:file : The reference file       output      outfile:file : The output sam/bam file       args      ngm : The NextGenMap executable, default: ngm    nthread : 1    outtype : sam or bam, default: sam (only sam for now, due to bug of ngm 0.5.3 (fixed in 0.5.4))    params : Other params for ngm, default: \"--rg-id ngm --rg-sm sample\"       requires  NextGenMap      pAlignSEByNGM    description \n    Align single-end reads to reference genome using NextGenMap    input      infile1:file : read file 1 (fastq, or fastq gzipped)    infile2:file : read file 2 (fastq, or fastq gzipped)    reffile:file : The reference file       output      outfile:file : The output sam/bam file       args      ngm : The NextGenMap executable, default: ngm    nthread : 1    outtype : sam or bam, default: sam (only sam for now, due to bug of ngm 0.5.3 (fixed in 0.5.4))    params : Other params for ngm, default: \"--rg-id ngm --rg-sm sample\"       requires  NextGenMap      pMergeBams    description \n    Merge bam files    input      bamdir:dir : the dir containing bam files        output      outfile:file : the merged bam file       args      samtools : the executable path of samtools, default: \"samtools\"    nthread : Number of BAM/CRAM compression threads    params : Other parameters for  samtools merge , default: \"\"       requires  samtools", 
            "title": "wxsprep"
        }, 
        {
            "location": "/processes/#wxsstat", 
            "text": "pVcf2List    description \n    Convert vcf to stat files for pCallRate    input      vcffile:file : The vcf file       output      outfile:file : The stat file       args      chroms : SNPs on chromosomes to consider, default: \"\" (all chroms)    use \"chr1-22, chrX, chrY\" for chr1 to chr22, chrX and chrY     requires  pyvcf      pCallRate    description \n    Calculate sample/snp call rate from a matrix of snp-sample   rows are snps, columns are samples     input      infile:file : The snp-sample matrix file       output      outsample:file : The report of call rate for each sample    figsample:file : The bar chat of sample call rates    outsnp:file : The report of call rate for each snp    figsnp:file : The bar chat of snp call rates         pCoverageByBamstats    description \n    Use  bamstats  to calculate coverage for bam file    input      infile:file : The bam file       output      outfile:file : The report of coverage for the bam file       args      bin : The  bamstats  executable, default: \"bamstats\"    params : Other parameters for  bamstats , default: \"\"       requires  bamstats      pPlotBamstats    description \n    Plot coverage use output files generated by  bamstats  or  wxs.pCoverageByBamstats    input      indir:file : The directory containing bamstats output files       args      chroms : Chromosomes to plot. Default: \"\" (all chroms)    Note: Whether to have \"chr\" prefix or not depends on your reference when mapping.  You can do a scope assignment: \"chr1-chr22, chrX, chrY\"     output      outdir:file : The directory containing output figures         pSnpEff2Stat    description \n    Convert csvstat file from snpEff to R-readable matrix for plotting    input      indir:file : The directory containing the csv stat files from  snpEff ann        output      outdir:dir : The output directory       args      chroms : The chromsome filter. Default: \"\" (all chroms)    Note: snpEff csvstat file has no \"chr\" prefix       pPlotSnpEff    description \n    Plot snpEff annotation statistics    input      indir:file : The snpEff result directory containing matrix files generated by pSnpEff2Stat       output      outdir:dir : The output directory       requires  pwwang/corrplot   use  library(devtools); install.github(\"pwwang/corrplot\")  ggplot2", 
            "title": "wxsstat"
        }, 
        {
            "location": "/aggregations/", 
            "text": "Coming soon ...", 
            "title": "Aggregations"
        }, 
        {
            "location": "/binaries/", 
            "text": "Main command\n\n\n bioprocs\n\nUsage: bioprocs \ncommand\n \n[\noptions ...\n]\n\n\nMethod commands:\n  params                        - Show bioprocs.params items.\n  list                          - List the process\n                                  Use \nbioprocs list \nMOD\n to list all processes of a module.\n  \nhelp\n                          - Print this \nhelp\n information.\n                                  Use \nbioprocs help \nCMD\n to show \nhelp\n \nfor\n commands.\n\nScript commands:\n  genomeplot                    - Plot genomic elements.\n  mutcall                       - Call mutations from sequencing data.\n  pwmscan                       \n  runcmds                       - Using PyPPL to distribute and run commands.\n\nProcess commands:\n  \nmodule.proc\n                 - Use \n{prog} list\n to show all processes, or\n                                  use \n{prog} list \nmodule\n to show processes of a module.\n\n\n\n\nRun \nbioprocs help \ncommand\n to show the help information of the subcommand.\n\n\nSubcommand: params\n\n\n bioprocs \nhelp\n params\n\nShow bioprocs.params items.\n\nUsage:\n  bioprocs params\n  bioprocs params \n[\nPARAM1\n]\n \n[\nPARAM2 ...\n]\n\n  bioprocs params \n[\n-param PARAM1 PARAM2 ...\n]\n\n\nOptions:\n  param                         - The parameter names\n\n\n\n\nSubcommand: list\n\n\n bioprocs \nhelp\n list\n\nList the process\nUse \nbioprocs list \nMOD\n to list all processes of a module.\n\nUsage:\n  bioprocs list\n  bioprocs list \n[\nMOD\n]\n\n  bioprocs list \n[\n-mod MOD\n]\n\n\nOptions:\n  mod                           - The name of the module.\n\n\n\n\nScript: genomeplot\n\n\n bioprocs \nhelp\n genomeplot\nUSAGE:\n  bioprocs -inputs \nLIST\n -tracks \nLIST\n -outdir \nSTR\n -region \nSTR\n -names \nLIST\n \n[\nOPTIONS\n]\n\n\nREQUIRED OPTIONS:\n  -inputs     \nLIST\n                    - The input of the tracks.\n                                          \nucscTrack\n:\ngvizTrack\n \nfor\n ucsc track\n;\n\n                                          \ninfile\n:\nintype\n \nfor\n interaction tracks\n;\n\n                                          files \nfor\n other tracks.\n  -tracks     \nLIST\n                    - The track types. Could be data, anno, interaction or ucsc, or multiple of them.\n  -outdir     \nSTR\n                     - Output directory.\n  -region     \nSTR\n                     - The region to plot. E.g. chr1:1000000-1200000\n  -names      \nLIST\n                    - The corresponding names of the tracks.\n\nOPTIONAL OPTIONS:\n  -ideo       \nSTR\n                     - Show ideogram track? DEFAULT: \nTrue\n\n  -plotparams \nSTR\n                     - The params \nfor\n pGenomePlot. DEFAULT: \n\n  -highlights \nLIST\n                    - The highlight regions in format of \nstart-end\n\n                                          DEFAULT: \n[]\n\n  -genes      \nSTR\n                     - Show gene track?\n                                          DEFAULT: \n/data2/junwenwang/shared/reference/hg19/hg19-gene.gtf\n\n  -devpars    \nSTR\n                     - The device parameters \nfor\n plotting.\n                                          DEFAULT: \n{\nres\n: 300, \nheight\n: 300, \nwidth\n: 2000}\n\n  -params     \nLIST\n                    - The params \nfor\n each track DEFAULT: \n[]\n\n  -splitlen   \nINT\n                     - Split the plot into \n2\n \nif\n the region is longer \nthen\n splitlen.\n                                          DEFAULT: \n1000000\n\n  -genome     \nSTR\n                     - Commonly used genome assembly. DEFAULT: \nhg19\n\n  -forks      \nINT\n                     - Number of cores used to plot \nif\n split. DEFAULT: \n2\n\n  -axis       \n(\nBOOL\n)\n                    - Show axis? DEFAULT: True\n  -h, --help, -H, -?                    - Print this \nhelp\n information.\n\n\n\n\nScript: mutcall\n\n\n bioprocs \nhelp\n mutcall\nUSAGE:\n  bioprocs -exdir \nSTR\n -saminfo \nSTR\n -indir \nSTR\n \n[\nOPTIONS\n]\n\n\nREQUIRED OPTIONS:\n  -exdir    \nSTR\n                       - Where to \nexport\n the result files.\n  -saminfo  \nSTR\n                       - The sample information file:\n                                          Column \n1\n: the basename of the sample file in \n-indir\n\n                                          Column \n2\n: Group \nif\n \n-muts\n includes \nsoma\n, basically, \nTUMOR\n and \nNORMAL\n\n                                          Column \n3\n: Patient \nif\n multiple samples belong to the same patient.\n                                          Example:\n                                          Sample\tGroup\tPatient\n                                          A1.bam\tTUMOR\tA\n                                          A2.bam\tNORMAL\tA\n                                          B1.bam\tTUMOR\tA\n                                          B2.bam\tNORMAL\tA\n  -indir    \nSTR\n                       - The input directory containing input files.\n\nOPTIONAL OPTIONS:\n  -runner   \nSTR\n                       - The runner to run the processes. DEFAULT: \nlocal\n\n  -intype   \nSTR\n                       - The input file types. Either bam, ebam or fastq.\n                                          Ebam means the bam files need to reformatted into fastq files.\n                                          DEFAULT: \nbam\n\n  -compress \n(\nBOOL\n)\n                      - Use gzip and bam file to save space. DEFAULT: True\n  -muts     \nLIST\n                      - What kind of mutations to call.\n                                          Note: soma need paired information DEFAULT: \n[\ngerm\n]\n\n  -forks    \nINT\n                       - How many \njobs\n to run simultanuously. DEFAULT: \n1\n\n  -logfile  \nSTR\n                       - Where to save the logs. DEFAULT: \n\n  -h, --help, -H, -?                    - Print this \nhelp\n information.\n\n\n\n\nScript: runcmds\n\n\n bioprocs \nhelp\n runcmds\nUSAGE:\n  bioprocs -cmds \nSTR\n \n[\nOPTIONS\n]\n\n\nREQUIRED OPTIONS:\n  -cmds   \nSTR\n                         - The cmd list. If not provided, STDIN will be used.\n\nOPTIONAL OPTIONS:\n  -runner \nSTR\n                         - The runner. DEFAULT: \nlocal\n\n  -forks  \nINT\n                         - How many \njobs\n to run simultaneously. DEFAULT: \n1\n\n  -h, --help, -H, -?                    - Print this \nhelp\n information.\n\n\n\n\nProcess\n\n\nConvert a \npyppl.Proc\n to a command line interface.\n\nTry \nbioprocs \nmodule\n.\nprocess\n to show the help information of the process.", 
            "title": "Binaries"
        }, 
        {
            "location": "/binaries/#main-command", 
            "text": "bioprocs\n\nUsage: bioprocs  command   [ options ... ] \n\nMethod commands:\n  params                        - Show bioprocs.params items.\n  list                          - List the process\n                                  Use  bioprocs list  MOD  to list all processes of a module.\n   help                           - Print this  help  information.\n                                  Use  bioprocs help  CMD  to show  help   for  commands.\n\nScript commands:\n  genomeplot                    - Plot genomic elements.\n  mutcall                       - Call mutations from sequencing data.\n  pwmscan                       \n  runcmds                       - Using PyPPL to distribute and run commands.\n\nProcess commands:\n   module.proc                  - Use  {prog} list  to show all processes, or\n                                  use  {prog} list  module  to show processes of a module.  Run  bioprocs help  command  to show the help information of the subcommand.", 
            "title": "Main command"
        }, 
        {
            "location": "/binaries/#subcommand-params", 
            "text": "bioprocs  help  params\n\nShow bioprocs.params items.\n\nUsage:\n  bioprocs params\n  bioprocs params  [ PARAM1 ]   [ PARAM2 ... ] \n  bioprocs params  [ -param PARAM1 PARAM2 ... ] \n\nOptions:\n  param                         - The parameter names", 
            "title": "Subcommand: params"
        }, 
        {
            "location": "/binaries/#subcommand-list", 
            "text": "bioprocs  help  list\n\nList the process\nUse  bioprocs list  MOD  to list all processes of a module.\n\nUsage:\n  bioprocs list\n  bioprocs list  [ MOD ] \n  bioprocs list  [ -mod MOD ] \n\nOptions:\n  mod                           - The name of the module.", 
            "title": "Subcommand: list"
        }, 
        {
            "location": "/binaries/#script-genomeplot", 
            "text": "bioprocs  help  genomeplot\nUSAGE:\n  bioprocs -inputs  LIST  -tracks  LIST  -outdir  STR  -region  STR  -names  LIST   [ OPTIONS ] \n\nREQUIRED OPTIONS:\n  -inputs      LIST                     - The input of the tracks.\n                                           ucscTrack : gvizTrack   for  ucsc track ; \n                                           infile : intype   for  interaction tracks ; \n                                          files  for  other tracks.\n  -tracks      LIST                     - The track types. Could be data, anno, interaction or ucsc, or multiple of them.\n  -outdir      STR                      - Output directory.\n  -region      STR                      - The region to plot. E.g. chr1:1000000-1200000\n  -names       LIST                     - The corresponding names of the tracks.\n\nOPTIONAL OPTIONS:\n  -ideo        STR                      - Show ideogram track? DEFAULT:  True \n  -plotparams  STR                      - The params  for  pGenomePlot. DEFAULT:  \n  -highlights  LIST                     - The highlight regions in format of  start-end \n                                          DEFAULT:  [] \n  -genes       STR                      - Show gene track?\n                                          DEFAULT:  /data2/junwenwang/shared/reference/hg19/hg19-gene.gtf \n  -devpars     STR                      - The device parameters  for  plotting.\n                                          DEFAULT:  { res : 300,  height : 300,  width : 2000} \n  -params      LIST                     - The params  for  each track DEFAULT:  [] \n  -splitlen    INT                      - Split the plot into  2   if  the region is longer  then  splitlen.\n                                          DEFAULT:  1000000 \n  -genome      STR                      - Commonly used genome assembly. DEFAULT:  hg19 \n  -forks       INT                      - Number of cores used to plot  if  split. DEFAULT:  2 \n  -axis        ( BOOL )                     - Show axis? DEFAULT: True\n  -h, --help, -H, -?                    - Print this  help  information.", 
            "title": "Script: genomeplot"
        }, 
        {
            "location": "/binaries/#script-mutcall", 
            "text": "bioprocs  help  mutcall\nUSAGE:\n  bioprocs -exdir  STR  -saminfo  STR  -indir  STR   [ OPTIONS ] \n\nREQUIRED OPTIONS:\n  -exdir     STR                        - Where to  export  the result files.\n  -saminfo   STR                        - The sample information file:\n                                          Column  1 : the basename of the sample file in  -indir \n                                          Column  2 : Group  if   -muts  includes  soma , basically,  TUMOR  and  NORMAL \n                                          Column  3 : Patient  if  multiple samples belong to the same patient.\n                                          Example:\n                                          Sample\tGroup\tPatient\n                                          A1.bam\tTUMOR\tA\n                                          A2.bam\tNORMAL\tA\n                                          B1.bam\tTUMOR\tA\n                                          B2.bam\tNORMAL\tA\n  -indir     STR                        - The input directory containing input files.\n\nOPTIONAL OPTIONS:\n  -runner    STR                        - The runner to run the processes. DEFAULT:  local \n  -intype    STR                        - The input file types. Either bam, ebam or fastq.\n                                          Ebam means the bam files need to reformatted into fastq files.\n                                          DEFAULT:  bam \n  -compress  ( BOOL )                       - Use gzip and bam file to save space. DEFAULT: True\n  -muts      LIST                       - What kind of mutations to call.\n                                          Note: soma need paired information DEFAULT:  [ germ ] \n  -forks     INT                        - How many  jobs  to run simultanuously. DEFAULT:  1 \n  -logfile   STR                        - Where to save the logs. DEFAULT:  \n  -h, --help, -H, -?                    - Print this  help  information.", 
            "title": "Script: mutcall"
        }, 
        {
            "location": "/binaries/#script-runcmds", 
            "text": "bioprocs  help  runcmds\nUSAGE:\n  bioprocs -cmds  STR   [ OPTIONS ] \n\nREQUIRED OPTIONS:\n  -cmds    STR                          - The cmd list. If not provided, STDIN will be used.\n\nOPTIONAL OPTIONS:\n  -runner  STR                          - The runner. DEFAULT:  local \n  -forks   INT                          - How many  jobs  to run simultaneously. DEFAULT:  1 \n  -h, --help, -H, -?                    - Print this  help  information.", 
            "title": "Script: runcmds"
        }, 
        {
            "location": "/binaries/#process", 
            "text": "Convert a  pyppl.Proc  to a command line interface. \nTry  bioprocs  module . process  to show the help information of the process.", 
            "title": "Process"
        }
    ]
}